---
title: "OpenAI Proxy with JavaScript/TypeScript"
sidebarTitle: "JavaScript/TypeScript"
description: "Integrate OpenAI with Helicone proxy using JavaScript/TypeScript"
---

# OpenAI Proxy Integration with JavaScript/TypeScript

This guide shows you how to route your OpenAI API calls through Helicone's proxy using JavaScript or TypeScript.

## Prerequisites

- An OpenAI API key
- A Helicone API key (get one at [dashboard.helicone.ai](https://dashboard.helicone.ai))
- Node.js installed on your machine

## Installation

```bash
npm install openai
# or
yarn add openai
```

## Basic Setup

```javascript
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.hconeai.com/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
  },
});

// Your OpenAI calls will now be logged to Helicone
const completion = await openai.chat.completions.create({
  messages: [{ role: "user", content: "Hello, how are you?" }],
  model: "gpt-3.5-turbo",
});

console.log(completion.choices[0].message);
```

## Adding Custom Properties

You can add custom properties to your requests to help with filtering and analytics:

```javascript
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.hconeai.com/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
    "Helicone-Property-User-Id": "user-123",
    "Helicone-Property-Session-Id": "session-456",
    "Helicone-Property-Conversation-Id": "conv-789",
  },
});
```

## Request-Level Properties

```javascript
const completion = await openai.chat.completions.create({
  messages: [{ role: "user", content: "Hello, how are you?" }],
  model: "gpt-3.5-turbo",
  headers: {
    "Helicone-Property-Feature": "chat-support",
    "Helicone-Property-Priority": "high",
  },
});
```

## Enabling Caching

```javascript
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.hconeai.com/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
    "Helicone-Cache-Enabled": "true",
  },
});
```

## Retry on Rate Limit

```javascript
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.hconeai.com/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
    "Helicone-RateLimit-Policy": "retry", // Will retry when rate limited
    "Helicone-RateLimit-Max-Retries": "3", // Maximum number of retries
  },
});
```

## Using with Frameworks

### Next.js Example

```javascript
// pages/api/chat.js
import OpenAI from "openai";

export default async function handler(req, res) {
  try {
    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      baseURL: "https://oai.hconeai.com/v1",
      defaultHeaders: {
        "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
        "Helicone-Property-User-Id": req.session?.user?.id || "anonymous",
      },
    });

    const completion = await openai.chat.completions.create({
      messages: req.body.messages,
      model: "gpt-3.5-turbo",
    });

    res.status(200).json({ result: completion.choices[0].message });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
}
```

### React Example

```javascript
import { useState } from "react";
import OpenAI from "openai";

function ChatComponent() {
  const [input, setInput] = useState("");
  const [response, setResponse] = useState("");

  const handleSubmit = async (e) => {
    e.preventDefault();

    try {
      // Note: In real apps, you'd want to make this API call from your backend
      // This is just for demonstration purposes
      const openai = new OpenAI({
        apiKey: process.env.REACT_APP_OPENAI_API_KEY,
        baseURL: "https://oai.hconeai.com/v1",
        defaultHeaders: {
          "Helicone-Auth": `Bearer ${process.env.REACT_APP_HELICONE_API_KEY}`,
        },
      });

      const completion = await openai.chat.completions.create({
        messages: [{ role: "user", content: input }],
        model: "gpt-3.5-turbo",
      });

      setResponse(completion.choices[0].message.content);
    } catch (error) {
      console.error("Error:", error);
    }
  };

  return (
    <div>
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Ask a question..."
        />
        <button type="submit">Send</button>
      </form>
      {response && <p>{response}</p>}
    </div>
  );
}
```

## Next Steps

- [Add custom properties](/docs/features/properties) for better filtering and analytics
- [Enable caching](/docs/features/caching) to reduce costs and improve response times
- [Explore the dashboard](/docs/dashboard/overview) to analyze your OpenAI usage

<div
  style={{
    display: "flex",
    justifyContent: "center",
    marginTop: "2rem",
    marginBottom: "2rem",
  }}
>
  <a
    href="/docs/integrate/proxy/openai"
    style={{
      display: "flex",
      alignItems: "center",
      gap: "0.5rem",
      padding: "0.625rem 1rem",
      color: "#94a3b8",
      fontSize: "0.9375rem",
      textDecoration: "none",
      transition: "color 0.2s ease",
    }}
  >
    <svg
      width="16"
      height="16"
      viewBox="0 0 24 24"
      fill="none"
      xmlns="http://www.w3.org/2000/svg"
    >
      <path
        d="M19 12H5M5 12L12 19M5 12L12 5"
        stroke="currentColor"
        strokeWidth="2"
        strokeLinecap="round"
        strokeLinejoin="round"
      />
    </svg>
    Back to language selection
  </a>
</div>{" "}
