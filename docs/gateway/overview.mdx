---
title: "AI Gateway Overview"
sidebarTitle: "Overview"
description: "Use any LLM provider through a single OpenAI-compatible API with intelligent routing, fallbacks, and unified observability"
---

<Info>
**Beta**: The AI Gateway is in beta. For production observability, see our [standard integrations](/integrations/overview).
</Info>

<Accordion title="How does AI Gateway differ from standard integrations?">
  Our standard integrations provide production-ready observability by adding monitoring to your existing LLM setup. The AI Gateway goes further by replacing multiple provider SDKs with a single unified API, enabling automatic failover, intelligent routing, and seamless provider switching without code changes. We're actively developing the AI Gateway as the future of Helicone, with migration paths planned for existing users when it reaches general availability.
</Accordion>

Helicone AI Gateway provides a unified API for 100+ LLM providers through the OpenAI SDK format. Instead of learning different SDKs and APIs for each provider, use one familiar interface to access any model with intelligent routing, automatic fallbacks, and complete observability.

<Note>
Supports BYOK (Bring Your Own Keys), passthrough routing, and pass-through billing (PTB). To enable pass-through billing with Helicone's API keys, request access in Settings → Credits.
</Note>

## Why Use AI Gateway?

<CardGroup cols={2}>
<Card title="One SDK for All Models" icon="code">
  Use OpenAI SDK to access GPT, Claude, Gemini, and 100+ other models
</Card>
<Card title="Intelligent Routing" icon="route">
  Automatic model fallbacks, cost optimization, and load balancing
</Card>
<Card title="Unified Observability" icon="chart-line">
  Track usage, costs, and performance across all providers in one dashboard
</Card>
<Card title="Prompt Management" icon="wand-magic-sparkles">
  Deploy and iterate prompts without code changes
</Card>
</CardGroup>

## Quick Example

Instead of managing multiple SDKs:

```typescript
// ❌ Old way - multiple SDKs and endpoints
const openai = new OpenAI({ baseURL: "https://oai.helicone.ai/v1" });
const anthropic = new Anthropic({ baseURL: "https://anthropic.helicone.ai" });

// Switch providers = code changes
const openaiResponse = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [...]
});

const anthropicResponse = await anthropic.messages.create({
  model: "claude-3.5-sonnet",
  messages: [...] // Different message format!
});
```

Use one SDK for everything:

```typescript
// ✅ New way - one SDK, all providers
const client = new OpenAI({
  baseURL: "https://ai-gateway.helicone.ai",
  apiKey: process.env.HELICONE_API_KEY,
});

// Switch providers = change model string
const response = await client.chat.completions.create({
  model: "gpt-4o-mini",  // Works with any model: claude-sonnet-4, gemini-2.5-flash, etc.
  messages: [{ role: "user", content: "Hello!" }]
});
```

## Next Steps

<CardGroup cols={2}>
<Card title="Get Started in 5 Minutes" icon="rocket" href="/getting-started/quick-start">
  Set up AI Gateway and make your first request
</Card>
<Card title="Browse Model Registry" icon="list" href="https://helicone.ai/models">
  See all supported models and provider formats
</Card>
<Card title="Provider Routing" icon="route" href="/gateway/provider-routing">
  Configure automatic routing and fallbacks for reliability
</Card>
<Card title="Prompt Integration" icon="wand-magic-sparkles" href="/gateway/prompt-integration">
  Deploy and manage prompts through the gateway
</Card>
</CardGroup>

<CardGroup cols={2}>
<Card title="Rate Limiting" icon="gauge" href="/features/advanced-usage/custom-rate-limits">
  Control usage and prevent abuse
</Card>
<Card title="Security Features" icon="lock" href="/features/advanced-usage/llm-security">
  Protect your applications with built-in security
</Card>
</CardGroup>

<Note>
Want to integrate a new model provider to the AI Gateway? Check out our [tutorial](/references/provider-integration) for detailed instructions.
</Note>
