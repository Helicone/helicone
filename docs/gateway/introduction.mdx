---
title: "Introduction"
sidebarTitle: "Introduction"
description: "Helicone's AI Gateway is the open-source, lightweight Rust-based solution for intelligent routing to 100+ language models."
---

![Subway](./images/subway.png)

<Card title="Get started in 1 minute" icon="plug" horizontal href="/quickstart">
    Start routing to 100+ models with our quickstart guide
</Card>
# Why we're building the AI Gateway?

The AI development space is progressing at an exponential rate. We see it every day at Heliconeâ€”over 90 % of our users run 5 + LLMs in production, each with its own SDK, auth scheme, rate limits, and quirks.

Keeping up today means rewriting integrations for every new model, managing a maze of API keys, engineering custom fallbacks for provider outages, and constantly tuning traffic for cost or compliance.

Helix is our answer. It is a lightweight Rust router inspired by NGINX that removes the integration tax so you can focus on shipping features.


# What do you get with the AI Gateway?

<CardGroup cols={2}>
<Card title="One line. 100+ models" icon="plug" href="/quickstart">
  A unified interface for every LLM provider using familiar OpenAI syntax
</Card>
<Card title="Smart provider selection" icon="shuffle" href="/loadbalancing">
  Load balance to always hit the fastest, cheapest, or most reliable option
</Card>
<Card title="Spending controls" icon="shield" href="/rate-limiting">
  Rate limit to prevent runaway costs and usage abuse
</Card>
<Card title="Reduced latency" icon="clock" href="/cache">
  Cache responses to reduce costs and latency by up to 95%
</Card>
<Card title="Guaranteed uptime" icon="key" href="/secret-management">
  Fallback to a different provider or model if the primary one is down
</Card>
<Card title="Centralized API keys" icon="key" href="/secret-management">
  Store all API keys securely to end credential chaos and security risks
</Card>
<Card title="Simplified tracing" icon="eye" href="/helicone">
  Monitor your AI workflows with built-in Helicone integration
</Card>
</CardGroup>

# What sets our AI Gateway apart?

Built in Rust, the Gateway ships as one lightweight binary you can run anywhere:

- **Self-hosted by default** - needs only Redis, nothing else
- **Sidecar-friendly** - drop into Docker, Kubernetes, bare-metal, or spawn as a subprocess
- **Built with Tower** - P2C + PeakEWMA load-balancing, retries, and timeouts are just middleware layers
- **NGINX-style proxy** - local gateway to any provider, model, or region
- **Horizontally scalable** - run 1-N instances behind any load balancer
- **Open-source** - MIT licensed, no vendor lock-in

# Let's get started!
<CardGroup cols={2}>
<Card title="Quickstart" icon="plug" href="/quickstart">
  Get started in minutes with our quickstart guide
</Card>
<Card title="Deployment Options" icon="plug" href="/gateway/deployment/overview">
  Find the right setup method for your infrastructure
</Card>
<Card title="GitHub" icon="github" href="https://github.com/helicone/gateway">
  View the source code and contribute to the Gateway
</Card>
</CardGroup>
