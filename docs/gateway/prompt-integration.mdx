---
title: "Prompt Integration"
sidebarTitle: "Prompt Integration"
description: "Deploy and iterate prompts through the AI Gateway without code changes"
---

Helicone's AI Gateway integrates directly with our prompt management system without the need for custom packages or code changes.

This guide shows you how to integrate the AI Gateway with prompt management, not the actual prompt management itself. For creating and managing prompts, see [Prompt Management](/features/advanced-usage/prompts).

## Why Use Prompt Integration?

Instead of hardcoding prompts in your application, reference them by ID:

<CodeGroup>
```typescript Without Integration
// ❌ Every prompt change = code deployment
messages: [{
  role: "user",
  content: `You are a support agent...` // Hardcoded
}]
```

```typescript With Integration
// ✅ Update prompts instantly via dashboard
prompt_id: "customer_support_v2",
inputs: { customer_name, issue_type, ... }
```
</CodeGroup>

## Gateway vs SDK Integration

Without the AI Gateway, using managed prompts requires multiple steps:

<CodeGroup>
```typescript SDK Approach (Complex)
// 1. Install package
npm install @helicone/helpers

// 2. Initialize prompt manager
const promptManager = new HeliconePromptManager({
  apiKey: "your-helicone-api-key"
});

// 3. Fetch and compile prompt (separate API call)
const { body, errors } = await promptManager.getPromptBody({
  prompt_id: "abc123",
  inputs: { customer_name: "John", ... }
});

// 4. Handle errors manually
if (errors.length > 0) {
  console.warn("Validation errors:", errors);
}

// 5. Finally make the LLM call
const response = await openai.chat.completions.create(body);
```

```typescript Gateway Approach (Simple)
// Just reference the prompt - gateway handles everything
const response = await client.chat.completions.create({
  prompt_id: "abc123",
  inputs: { customer_name: "John", ... }
});
```
</CodeGroup>

<Info>
**Why the gateway is better:**
- **No extra packages** - Works with your existing OpenAI SDK
- **Single API call** - Gateway fetches and compiles automatically
- **Lower latency** - Everything happens server-side in one request
- **Automatic error handling** - Invalid inputs return clear error messages
- **Cleaner code** - No prompt management logic in your application
</Info>

## Integration Steps

<Steps>
<Step title="Create prompts in Helicone">
  [Build and test prompts](/features/advanced-usage/prompts) with variables in the dashboard
</Step>
<Step title="Use prompt_id in your code">
  Replace `messages` with `prompt_id` and `inputs` in your gateway calls
</Step>
</Steps>

## API Parameters

Use these parameters in your chat completions request to integrate with saved prompts:

<Fields>
  <Field name="prompt_id" type="string" required>
    The ID of your saved prompt from the Helicone dashboard
  </Field>
  <Field name="environment" type="string" default="production">
    Which environment version to use: `development`, `staging`, or `production`
  </Field>
  <Field name="inputs" type="object" required>
    Variables to fill in your prompt template (e.g., `{"customer_name": "John", "issue_type": "billing"}`)
  </Field>
  <Field name="model" type="string" required>
    Any supported model - works with the unified gateway format
  </Field>
</Fields>

## Example Usage

<Tabs>
<Tab title="Basic">
```typescript
const response = await client.chat.completions.create({
  model: "gpt-4o-mini",
  prompt_id: "customer_support_v2",
  environment: "production",
  inputs: {
    customer_name: "Sarah Johnson",
    issue_type: "billing",
    customer_message: "I was charged twice this month"
  }
});
```
</Tab>

<Tab title="With Model Fallbacks">
```typescript
// Combine prompts with automatic fallbacks
const response = await client.chat.completions.create({
  model: "gpt-4o-mini,claude-haiku-4", // Try GPT first, then Claude
  prompt_id: "customer_support_v2",
  environment: "production",
  inputs: {
    customer_name: "Sarah Johnson",
    issue_type: "billing",
    customer_message: "I was charged twice this month"
  }
});
```
</Tab>
</Tabs>

## Next Steps

<CardGroup cols={2}>
<Card title="Create Your First Prompt" icon="pencil" href="/features/advanced-usage/prompts">
  Learn to build prompts with variables in the dashboard
</Card>
<Card title="Provider Routing" icon="route" href="/gateway/provider-routing">
  Combine prompts with automatic routing and fallbacks for reliability
</Card>
</CardGroup>