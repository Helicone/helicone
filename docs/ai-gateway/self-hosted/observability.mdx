---
title: "Observability with Helicone"
sidebarTitle: "Enable Observability"
description: "Monitor your AI Gateway requests with Helicone"
---

<Tabs>
  <Tab title="Cloud Hosted">
    <Info>
      **Observability is built-in!** With Helicone Cloud, all requests are automatically logged and monitored. No setup required.
      
      View your requests, costs, and analytics instantly in your [Helicone dashboard](https://helicone.ai/dashboard).
    </Info>
    
    ## What's automatically tracked:
    
    - **Request logs** - Every request and response with full details
    - **Cost tracking** - Real-time costs across all providers
    - **Latency metrics** - Performance insights and bottleneck detection
    - **Token usage** - Detailed token analytics by model and user
    - **Error rates** - Monitor failures and retry patterns
    - **Custom properties** - Tag requests with metadata for filtering
    
    ## Privacy Controls
    
    Even with automatic logging, you maintain full control over sensitive data:
    
    ```bash
    curl https://gateway.helicone.ai/your-org-id/ai/chat/completions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "helicone-omit-request: true" \
      -H "helicone-omit-response: true" \
      -H "Content-Type: application/json" \
      -d '{"model": "gpt-4o-mini", "messages": [{"role": "user", "content": "Sensitive data"}]}'
    ```
  </Tab>
  
  <Tab title="Self-Hosted">
    Enable observability to automatically log all requests to your Helicone dashboard for monitoring usage, costs, and performance across all providers.

## Quick Start

<Steps>
  <Step title="Set your Helicone API key">
    Add your Helicone API key as an environment variable when deploying the Gateway:

    ```bash
    export HELICONE_CONTROL_PLANE_API_KEY=sk-helicone-your-api-key
    ```
  </Step>
  
  <Step title="Enable Helicone observability">
    Create or update your `ai-gateway-config.yaml`:

    ```yaml
    helicone:
      # also enables authentication
      features: observability
    
    routers:
      my-router:
        load-balance:
          chat:
            strategy: latency
            providers:
              - openai
              - anthropic
    ```
  </Step>
  
  <Step title="Start the gateway">
    ```bash
    npx @helicone/ai-gateway@latest --config ai-gateway-config.yaml
    ```
  </Step>
  
  <Step title="Make requests">
    <Info>
      **Authentication Required**: Observability requires Helicone authentication to be enabled,
      therefore you must include your Helicone API key in requests.
    </Info>


    ```bash
    curl -X POST http://localhost:8080/router/my-router/chat/completions \
      -H "Authorization: Bearer sk-helicone-your-api-key" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "openai/gpt-4o-mini",
        "messages": [{"role": "user", "content": "Hello!"}]
      }'
    ```
    âœ… Check your [Helicone dashboard](https://us.helicone.ai) to see requests logged automatically!
  </Step>
</Steps>

## Privacy Controls

To exclude sensitive data from logs:

```bash
curl -X POST http://localhost:8080/router/my-router/chat/completions \
  -H "Authorization: Bearer sk-helicone-your-api-key" \
  -H "helicone-omit-request: true" \
  -H "helicone-omit-response: true" \
  -H "Content-Type: application/json" \
  -d '{"model": "openai/gpt-4o-mini", "messages": [{"role": "user", "content": "Sensitive data"}]}'
```
  </Tab>
</Tabs>