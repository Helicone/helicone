---
title: "API Key & Secret Management"
sidebarTitle: "Secret Management"
description: "Secure API key management for multiple LLM providers with automatic discovery"
---

The AI Gateway securely manages API keys and sensitive credentials for all configured LLM providers using environment variables with automatic discovery and secure handling.

## Getting Started

### Why Use Secure Secret Management?

Secret management helps you:
- **Centralize credential access** so developers only need the router URL, not individual provider API keys
- **Reduce credential sprawl** by keeping all provider secrets in one secure location instead of distributing them
- **Simplify configuration** with automatic API key discovery based on configured providers
- **Enable multi-provider setups** by managing credentials for multiple LLM providers simultaneously

### How Secret Management Works

The AI Gateway automatically discovers and loads API keys based on your configuration:

**Discovery process:**
1. **Read configuration** - Identifies which providers are configured in your routers
2. **Load environment variables** - Looks for `{PROVIDER_NAME}_API_KEY` for each provider
3. **Validate at request time** - Checks for required API keys when a request is routed to a specific provider

If a required API key is missing when a request is made to that provider, the request fails with a clear error message indicating which environment variable needs to be set.

<Note>
  Cloud secret manager integrations (AWS Secrets Manager, Google Secret Manager, Azure Key Vault) are planned for v2 to support enterprise deployments.
</Note>

**Basic example:**
```yaml
routers:
  default:
    load-balance:
      chat:
        strategy: latency
        providers:
          - openai      # Requires OPENAI_API_KEY
          - anthropic   # Requires ANTHROPIC_API_KEY
          - google      # Requires GOOGLE_API_KEY
```

### Configuration Examples

<Tabs>
  <Tab title="Production API - Multi-Provider">
    **Use case:** Production environment using multiple cloud providers for reliability and cost optimization.

    ```bash
    # Set API keys for configured providers
    export OPENAI_API_KEY="sk-..."
    export ANTHROPIC_API_KEY="sk-ant-..."
    export GOOGLE_API_KEY="..."
    ```

    ```yaml
    routers:
      production:
        load-balance:
          chat:
            strategy: latency
            providers:
              - openai
              - anthropic
              - google
    ```
  </Tab>

  <Tab title="Development Environment - Local + Cloud">
    **Use case:** Development setup using local Ollama models for testing and cloud providers for comparison.

    ```bash
    # Only need keys for cloud providers
    export OPENAI_API_KEY="sk-..."
    # Ollama runs locally, no key needed
    ```

    ```yaml
    routers:
      development:
        load-balance:
          chat:
            strategy: weighted
            providers:
              - provider: ollama     # No API key required
                weight: 0.8
              - provider: openai     # Requires OPENAI_API_KEY
                weight: 0.2
    ```
  </Tab>



  <Tab title="Multi-Environment Deployment">
    **Use case:** Different environments with different provider configurations and API key management.

    ```bash
    # Production
    export OPENAI_API_KEY="sk-prod-..."
    export ANTHROPIC_API_KEY="sk-ant-prod-..."

    # Staging
    export OPENAI_API_KEY="sk-staging-..."
    export ANTHROPIC_API_KEY="sk-ant-staging-..."

    # Development - Local only
    # No API keys needed for Ollama
    ```
  </Tab>
</Tabs>

## Reference

### Supported Providers

The AI Gateway supports API key management for the following providers:

| Provider         | Environment Variable  | Required | Notes                           |
| ---------------- | -------------------- | -------- | ------------------------------- |
| **OpenAI**       | `OPENAI_API_KEY`     | Yes      | Standard OpenAI API key         |
| **Anthropic**    | `ANTHROPIC_API_KEY`  | Yes      | Claude API key                  |
| **Google** | `GOOGLE_API_KEY`     | Yes      | Google AI Studio API key        |
| **AWS Bedrock**  | `BEDROCK_API_KEY`    | Yes      | AWS access key                  |
| **VertexAI**     | `VERTEXAI_API_KEY`   | Yes      | GCP service account key         |
| **Ollama**       | N/A                  | No       | Local deployment, no key needed |

<Note>
  You only need to set environment variables for providers you actually use. If you make a request to a provider that is not configured, the request will fail with a clear error message indicating which environment variable needs to be set.
</Note>

### Error Handling

The AI Gateway provides clear error messages for secret management issues:

<AccordionGroup>
  <Accordion title="Provider Keys Not Found" icon="key">
    **Error:** No API keys loaded for the router
    
    ```
    Error: Provider keys not found for router: production
    ```
    
    **Solution:** Ensure environment variables are set for all providers used in your router configuration.
  </Accordion>

  <Accordion title="Authentication Failures" icon="x">
    **Error:** Provider rejects the API key during request
    
    ```
    HTTP 401 Unauthorized from provider
    ```
    
    **Solution:** Verify your API key is valid and has the required permissions with the provider. Authentication errors come directly from the provider's API, not the gateway.
  </Accordion>

  <Accordion title="Missing Environment Variables" icon="gear">
    **Behavior:** Requests to providers without API keys will fail
    
    If you configure a provider in your router but don't set the corresponding environment variable, requests to that provider will fail when attempted.
    
    **Solution:** Set the required environment variables:
    - OpenAI: `OPENAI_API_KEY`
    - Anthropic: `ANTHROPIC_API_KEY` 
    - Google: `GOOGLE_API_KEY`
    - AWS Bedrock: `AWS_ACCESS_KEY` + `AWS_SECRET_KEY`
  </Accordion>
</AccordionGroup>
### Security Best Practices

<AccordionGroup>
  <Accordion title="Credential Isolation" icon="shield-halved">
    **Keep provider keys in the router infrastructure only**
    - Developers and applications never handle actual provider API keys
    - Only the router instances need access to `{PROVIDER_NAME}_API_KEY` environment variables
    - Applications authenticate with the router URL instead of individual providers
    - Optionally, enable [Helicone authentication](/ai-gateway/config#helicone-observability) to require Helicone API keys for router access
  </Accordion>

  <Accordion title="Observability & Monitoring" icon="chart-line">
    **Track usage through Helicone integration**
    - Monitor API key usage, costs, and request traces in [Helicone Observability](/ai-gateway/helicone-integration)
    - Get audit logs of which requests used which provider keys
    - Set up cost alerts and usage monitoring per provider
  </Accordion>
</AccordionGroup>

## Coming Soon

### Cloud Secret Managers _(v2)_

**Enterprise-grade secret management integrations**

Native integration with cloud provider secret management services including AWS Secrets Manager, Google Secret Manager, Azure Key Vault, and HashiCorp Vault for automatic rotation, cross-region replication, and enterprise governance.