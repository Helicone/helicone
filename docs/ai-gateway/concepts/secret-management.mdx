---
title: "API Key & Secret Management"
sidebarTitle: "Secret Management"
description: "Secure API key management for multiple LLM providers with automatic discovery"
---

The AI Gateway securely manages API keys and sensitive credentials for all configured LLM providers using environment variables with automatic discovery and secure handling.

API keys are automatically discovered based on your router configuration and wrapped in `Secret<T>` types to prevent accidental logging or serialization.

## Getting Started

### Why Use Secure Secret Management?

Secret management helps you:
- **Centralize credential access** so developers only need the router URL, not individual provider API keys
- **Reduce credential sprawl** by keeping all provider secrets in one secure location instead of distributing them
- **Simplify configuration** with automatic API key discovery based on configured providers
- **Enable multi-provider setups** by managing credentials for multiple LLM providers simultaneously

### How Secret Management Works

The AI Gateway automatically discovers and loads API keys based on your configuration:

**Discovery process:**
1. **Read configuration** - Identifies which providers are configured in your routers
2. **Load environment variables** - Looks for `{PROVIDER_NAME}_API_KEY` for each provider
3. **Validate at startup** - Ensures all required keys are present before accepting requests

If any required keys are missing, the system fails to start with clear error messages indicating which environment variables need to be set.

<Note>
  Cloud secret manager integrations (AWS Secrets Manager, Google Secret Manager, Azure Key Vault) are planned for v2 to support enterprise deployments.
</Note>

**Basic example:**
```yaml
routers:
  default:
    load-balance:
      chat:
        strategy: latency
        providers:
          - openai      # Requires OPENAI_API_KEY
          - anthropic   # Requires ANTHROPIC_API_KEY
          - gemini      # Requires GEMINI_API_KEY
```

### Configuration Examples

<Tabs>
  <Tab title="Production API - Multi-Provider">
    **Use case:** Production environment using multiple cloud providers for reliability and cost optimization.

    ```bash
    # Set API keys for configured providers
    export OPENAI_API_KEY="sk-..."
    export ANTHROPIC_API_KEY="sk-ant-..."
    export GEMINI_API_KEY="..."
    ```

    ```yaml
    routers:
      production:
        load-balance:
          chat:
            strategy: latency
            providers:
              - openai
              - anthropic
              - gemini
    ```
  </Tab>

  <Tab title="Development Environment - Local + Cloud">
    **Use case:** Development setup using local Ollama models for testing and cloud providers for comparison.

    ```bash
    # Only need keys for cloud providers
    export OPENAI_API_KEY="sk-..."
    # Ollama runs locally, no key needed
    ```

    ```yaml
    routers:
      development:
        load-balance:
          chat:
            strategy: weighted
            providers:
              - provider: ollama     # No API key required
                weight: 0.8
              - provider: openai     # Requires OPENAI_API_KEY
                weight: 0.2
    ```
  </Tab>



  <Tab title="Multi-Environment Deployment">
    **Use case:** Different environments with different provider configurations and API key management.

    ```bash
    # Production
    export OPENAI_API_KEY="sk-prod-..."
    export ANTHROPIC_API_KEY="sk-ant-prod-..."

    # Staging
    export OPENAI_API_KEY="sk-staging-..."
    export ANTHROPIC_API_KEY="sk-ant-staging-..."

    # Development - Local only
    # No API keys needed for Ollama
    ```
  </Tab>
</Tabs>

## Reference

### Supported Providers

The AI Gateway supports API key management for the following providers:

| Provider         | Environment Variable  | Required | Notes                           |
| ---------------- | -------------------- | -------- | ------------------------------- |
| **OpenAI**       | `OPENAI_API_KEY`     | Yes      | Standard OpenAI API key         |
| **Anthropic**    | `ANTHROPIC_API_KEY`  | Yes      | Claude API key                  |
| **Google Gemini** | `GEMINI_API_KEY`     | Yes      | Google AI Studio API key        |
| **AWS Bedrock**  | `BEDROCK_API_KEY`    | Yes      | AWS access key                  |
| **VertexAI**     | `VERTEXAI_API_KEY`   | Yes      | GCP service account key         |
| **Ollama**       | N/A                  | No       | Local deployment, no key needed |

<Note>
  The system automatically determines which API keys are required based on your router configuration. You only need to set environment variables for providers you actually use.
</Note>

### Error Handling

The AI Gateway provides clear error messages for secret management issues:

<AccordionGroup>
  <Accordion title="Missing API Key" icon="exclamation-triangle">
    **Error:** Provider configured but API key not found
    
    ```
    Error: API key not found for provider 'openai'
    Expected environment variable: OPENAI_API_KEY
    ```
    
    **Solution:** Set the required environment variable for all configured providers.
  </Accordion>

  <Accordion title="Invalid API Key Format" icon="warning">
    **Error:** Provider rejects the provided API key
    
    ```
    Error: Authentication failed for provider 'anthropic'
    Check that ANTHROPIC_API_KEY is valid and has required permissions
    ```
    
    **Solution:** Verify the API key format and permissions with the provider.
  </Accordion>

  <Accordion title="Provider Configuration Mismatch" icon="gear">
    **Error:** Keys provided for unconfigured providers
    
    ```
    Warning: Environment variable GEMINI_API_KEY found but provider not configured
    ```
    
    **Solution:** This is just a warning. Extra keys are ignored safely.
  </Accordion>
</AccordionGroup>

## Advanced Configuration

### Security Best Practices

<AccordionGroup>
  <Accordion title="Credential Isolation" icon="shield-halved">
    **Keep provider keys in the router infrastructure only**
    - Developers and applications never handle actual provider API keys
    - Only the router instances need access to `{PROVIDER_NAME}_API_KEY` environment variables
    - Applications authenticate with the router URL instead of individual providers
    - Optionally, enable [Helicone authentication](/ai-gateway/config#helicone-integration) to require Helicone API keys for router access
  </Accordion>

  <Accordion title="Observability & Monitoring" icon="chart-line">
    **Track usage through Helicone integration**
    - Monitor API key usage, costs, and request traces in [Helicone Observability](/ai-gateway/helicone)
    - Get audit logs of which requests used which provider keys
    - Set up cost alerts and usage monitoring per provider
  </Accordion>
</AccordionGroup>

### Deployment Considerations

<Tabs>
  <Tab title="Docker Containers">
    **Environment variables in containerized deployments**

    ```dockerfile
    # Dockerfile
    ENV OPENAI_API_KEY=""
    ENV ANTHROPIC_API_KEY=""

    # Runtime
    docker run -e OPENAI_API_KEY="sk-..." \
               -e ANTHROPIC_API_KEY="sk-ant-..." \
               helicone-router
    ```
  </Tab>

  <Tab title="Kubernetes">
    **Secret management in Kubernetes**

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: llm-provider-keys
    type: Opaque
    data:
      OPENAI_API_KEY: <base64-encoded-key>
      ANTHROPIC_API_KEY: <base64-encoded-key>
    
    ---
    apiVersion: apps/v1
    kind: Deployment
    spec:
      template:
        spec:
          containers:
          - name: router
            envFrom:
            - secretRef:
                name: llm-provider-keys
    ```
  </Tab>

  <Tab title="Cloud Platforms">
    **Managed secret services**

    ```bash
    # AWS Systems Manager Parameter Store
    aws ssm put-parameter --name "/router/openai-key" \
                         --value "sk-..." --type "SecureString"
    
    # Google Secret Manager
    gcloud secrets create openai-key --data-file=key.txt
    
    # Azure Key Vault
    az keyvault secret set --vault-name MyKeyVault \
                          --name openai-key --value "sk-..."
    ```
  </Tab>
</Tabs>

## Coming Soon

### Cloud Secret Managers _(v2)_

**Enterprise-grade secret management integrations**

Native integration with cloud provider secret management services including AWS Secrets Manager, Google Secret Manager, Azure Key Vault, and HashiCorp Vault for automatic rotation, cross-region replication, and enterprise governance.

---

<Info>
  **Need help with secret management?** Check our [deployment guides](/deployment) or reach out on [GitHub](https://github.com/helicone/helicone-router) for assistance with your specific environment.
</Info>
