---
title: "OpenAI Realtime Integration"
sidebarTitle: "Realtime"
description: "Integrate OpenAI's Realtime API with Helicone to monitor and analyze your real-time conversations."
"twitter:title": "OpenAI Realtime API Integration - Helicone OSS LLM Observability"
icon: "microphone"
iconType: "solid"
---

## Introduction

OpenAI's Realtime API enables low-latency, multi-modal conversational experiences with support for text and audio as both input and output. By integrating with Helicone, you can monitor performance, analyze interactions, and gain valuable insights into your real-time conversations.

## Integration Steps

<Steps>
  <Step title="Create an Account and Generate an API Key">
    Log into [Helicone](https://www.helicone.ai) or create a new account. Once logged in, generate a [Helicone API key](https://helicone.ai/developer).

    <Note>
      Keep your API keys secure and do not expose them publicly.
    </Note>

  </Step>

  <Step title="Set Environment Variables">
    Set your API keys as environment variables:

    ```bash
    # For OpenAI
    export OPENAI_API_KEY=<your-openai-api-key>
    export HELICONE_API_KEY=<your-helicone-api-key>

    # For Azure
    export AZURE_API_KEY=<your-azure-api-key>
    export AZURE_RESOURCE=<your-azure-resource>
    export AZURE_DEPLOYMENT=<your-azure-deployment>
    export HELICONE_API_KEY=<your-helicone-api-key>
    ```

  </Step>

  <Step title="Install Required Dependencies">
    Install the required dependencies:

    ```bash
    npm install ws dotenv
    ```

  </Step>

  <Step title="Configure WebSocket Connection">
    You can connect to the Realtime API through Helicone using either OpenAI or Azure as your provider. Here are examples for both:

    ### OpenAI Provider
    ```typescript
    import WebSocket from "ws";
    import { config } from "dotenv";

    config();

    const url = "wss://api.helicone.ai/v1/gateway/oai/realtime?model=gpt-4o-realtime-preview-2024-12-17";

    const ws = new WebSocket(url, {
      headers: {
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
        "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
        // Optional Helicone properties
        "Helicone-Session-Id": `session_${Date.now()}`,
        "Helicone-User-Id": "user_123",
      },
    });

    ws.on("open", function open() {
      console.log("Connected to server");
      // Initialize session with desired configuration
      ws.send(JSON.stringify({
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions: "You are a helpful AI assistant...",
          voice: "alloy",
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
        }
      }));
    });
    ```

    ### Azure Provider
    ```typescript
    import WebSocket from "ws";
    import { config } from "dotenv";

    config();

    const url = `wss://api.helicone.ai/v1/gateway/oai/realtime?resource=${process.env.AZURE_RESOURCE}&deployment=${process.env.AZURE_DEPLOYMENT}`;

    const ws = new WebSocket(url, {
      headers: {
        "Authorization": `Bearer ${process.env.AZURE_API_KEY}`,
        "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
        // Optional Helicone properties
        "Helicone-Session-Id": `session_${Date.now()}`,
        "Helicone-User-Id": "user_123",
      },
    });

    ws.on("open", function open() {
      console.log("Connected to server");
      // Initialize session with desired configuration
      ws.send(JSON.stringify({
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions: "You are a helpful AI assistant...",
          voice: "alloy",
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
        }
      }));
    });
    ```

  </Step>

  <Step title="Handle WebSocket Events">
    Add event handlers for the WebSocket connection:

    ```typescript
    ws.on("message", function incoming(message) {
      try {
        const response = JSON.parse(message.toString());
        console.log("Received:", response);

        // Handle specific event types
        switch (response.type) {
          case "input_audio_buffer.speech_started":
            console.log("Speech detected!");
            break;
          case "input_audio_buffer.speech_stopped":
            console.log("Speech ended. Processing...");
            break;
          case "conversation.item.input_audio_transcription.completed":
            console.log("Transcription:", response.transcript);
            break;
          case "error":
            console.error("Error:", response.error.message);
            break;
        }
      } catch (error) {
        console.error("Error parsing message:", error);
      }
    });

    ws.on("error", function error(err) {
      console.error("WebSocket error:", err);
    });

    // Handle cleanup
    process.on("SIGINT", () => {
      console.log("\nClosing connection...");
      ws.close();
      process.exit(0);
    });
    ```

  </Step>
</Steps>

## Audio Requirements

When working with audio in the Realtime API, ensure your audio meets these requirements:

- Format: PCM with 16-bit integer samples (Int16Array)
- Mono audio (single channel)
- Sample rate: 24000 Hz (24 kHz)
- Base64 encoded audio chunks

## Session Management

Helicone provides additional headers to help you manage and analyze your sessions:

```typescript
const headers = {
  // Required headers
  Authorization: `Bearer ${apiKey}`,
  "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,

  // Optional headers for better analytics
  "Helicone-Session-Id": `session_${Date.now()}`,
  "Helicone-User-Id": "user_123",
  "Helicone-Session-Name": "VoiceAssistant",
  "Helicone-Session-Path": "/voice-assistant/conversation",
};
```

These headers help you:

- Group related API calls
- Track user sessions
- Analyze conversation patterns
- Monitor usage and performance

<Note>
  The Realtime API is stateful and maintains the conversation state throughout
  the WebSocket connection. If the connection is lost, you'll need to recreate
  the session and reinitialize the conversation state.
</Note>

### Related Guides

<CardGroup cols={1}>
  <Card
    title="Building a chatbot with OpenAI structured outputs"
    icon="lightbulb"
    href="/guides/cookbooks/openai-structured-outputs"
    iconType="light"
    vertical
  >
    This step-by-step guide covers function calling, response formatting and
    monitoring with Helicone.
  </Card>
</CardGroup>
