---
title: "OpenAI  with Async Logging"
sidebarTitle: "Async Logging"
description: "Use Async Logging to integrate OpenAI with Helicone to log your OpenAI usage without using the Helicone Proxy."
"twitter:title": "OpenAI Async Logging Integration - Helicone OSS LLM Observability"
icon: "arrows-rotate"
iconType: "solid"
---

This does not use the Helicone Proxy.
For more information on Async Logging, see the [Proxy vs Async](/getting-started/proxy-vs-async) page.

<Steps>
  <Step title="Create an account + Generate an API Key">
    Log into [helicone](https://www.helicone.ai) or create an account. Once you have an account, you
    can generate an [API key](https://helicone.ai/developer).
  </Step>
  <Step title="Set HELICONE_API_KEY as an environment variable">
```typescript
export HELICONE_API_KEY=<your API key>
```
  </Step>
   <Step title="Install Helicone">

```typescript
npm install @helicone/helicone
```

  </Step>
  <Step title="Replace the imports and add Helicone authorizations">
<CodeGroup>

```typescript example.ts
const { HeliconeAsyncOpenAI as OpenAI,
  IHeliconeAsyncClientOptions as ClientOptions } = require("helicone");


const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  heliconeMeta: {
    apiKey: process.env.HELICONE_API_KEY, // Can be set as env variable
    // ... additional helicone meta fields
  },
});

const chatCompletion = await openai.chat.completion.create({
  model: "gpt-3.5-turbo",
  messages: [{ role: "user", content: "Hello world" }],
});

console.log(chatCompletion.data.choices[0].message);
```

```python example.py
from helicone.openai_async import openai, Meta

chatResponse = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[{
    "role": "system",
    "content": "This will be logged"
  }],
  max_tokens=512,
  helicone_meta=Meta(
    custom_properties={
      "age": 25
    }
  )
)


```

</CodeGroup>

  </Step>
</Steps>
