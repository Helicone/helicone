---
title: "Load Balancing Strategies"
sidebarTitle: "Load Balancing"
description: "Intelligent request routing across providers with P2C, weighted, and cost-optimized algorithms"
---

# Load Balancing Strategies

Conduit automatically distributes requests across multiple providers using sophisticated algorithms that consider latency, provider health, and your custom preferences. All strategies are **rate-limit aware** and **health-monitored**—unhealthy providers are automatically removed and re-added when they recover.

## Available Strategies

<AccordionGroup>
  <Accordion title="P2C + PeakEWMA (Default)" icon="bolt">
    **Latency-based Power-of-Two-Choices with Peak EWMA** *(Available in v0)*
    
    Maintains a moving average of each provider's RTT latency, weighted by the number of outstanding requests, to distribute traffic to providers with the least load in order to optimize latency.
    
    **Best for:** Production workloads where latency matters most
    
    **How it works:**
    1. Randomly selects 2 providers from the healthy pool
    2. Calculates load using RTT weighted by outstanding requests
    3. Routes to the provider with lower load score
    4. Updates moving averages with actual response times
  </Accordion>

{" "}

<Accordion title="Weighted Strategy over Providers" icon="chart-pie">
  **Custom traffic percentages across providers** *(Available in v0)* Based on
  arbitrary weights given. E.g., if there are providers [A, B, C] with weights
  [0.80, 0.15, 0.05], then A gets 80% of traffic, B gets 15%, etc. **Best for:**
  Cost optimization, gradual provider migrations, or compliance requirements
</Accordion>

{" "}

<Accordion title="Cost Usage Strategy" icon="dollar-sign">
  **Route to the cheapest equivalent model** *(Coming in v2)* For a given model,
  pick the provider that offers that same model or any allowed configured
  equivalent models for the lowest price. **Best for:** Cost-sensitive workloads
  where minor latency differences are acceptable
</Accordion>

{" "}

<Accordion title="Weighted Strategy over Model Instances" icon="bullseye">
  **Provider + model specific weighting** *(Coming in v2)* Same as Weighted
  Strategy over providers, except configurable for provider+model pairs. E.g.,
  [openai/o3, bedrock/claude-3-7-sonnet] with weights [0.90, 0.10], then openai
  gets 90% of traffic using o3 as the model and bedrock gets 10% with
  claude-3-7-sonnet. **Best for:** Fine-grained control over specific model
  routing
</Accordion>

  <Accordion title="Forced Routing / Tag-based" icon="tag">
    **Header-driven routing decisions** *(Coming in v3)*
    
    Route requests to specific providers and models based on tags passed via request headers.
    
    **Best for:** A/B testing, user-specific routing, compliance requirements
  </Accordion>
</AccordionGroup>

## Load Balancing Levels

Conduit supports load balancing at multiple levels of granularity:

| Level                   | Availability | Description                                                                                                                 | Example                                          |
| ----------------------- | ------------ | --------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ |
| **Providers**           | v0           | Balance across different AI companies                                                                                       | OpenAI vs Anthropic vs Bedrock                   |
| **Deployments/Regions** | v0           | Latency-based load balancing across all regions for providers that support them                                             | `us-east-1` vs `us-west-2` vs `eu-west-1`        |
| **Models**              | v2           | Balance over (provider, model) pairs. Enables rate limit aware, cost usage load balancing, and specific weighted strategies | `openai/gpt-4o` vs `anthropic/claude-3-5-sonnet` |

## Configuration Examples

<Tabs>
  <Tab title="P2C + PeakEWMA">
    ```yaml
    balance:
      chat:
        strategy: "p2c"
        targets:
          - openai
          - anthropic
          - bedrock
    ```
    
    <Callout type="info">
      P2C requires at least 2 providers. With more providers, it becomes more effective at finding the optimal choice.
    </Callout>
  </Tab>

{" "}

<Tab title="Weighted (Providers)">
  ```yaml balance: chat: strategy: "weighted" targets: - provider: openai
  weight: 0.80 - provider: anthropic weight: 0.15 - provider: bedrock weight:
  0.05 ```
  <Callout type="warning">
    Weights must sum to exactly 1.0, or Conduit will reject the configuration.
  </Callout>
</Tab>

{" "}

<Tab title="Weighted (Model Instances)">
  ```yaml balance: chat: strategy: "weighted-models" # v2 targets: - provider:
  openai model: "o3" weight: 0.90 - provider: bedrock model: "claude-3-7-sonnet"
  weight: 0.10 ```
  <Callout type="note">
    Model-level weighting is coming in v2, enabling precise control over
    provider+model combinations.
  </Callout>
</Tab>

  <Tab title="Cost-Optimized">
    ```yaml
    balance:
      chat:
        strategy: "cost"  # v2
        targets:
          - openai
          - anthropic
          - bedrock
        # Conduit automatically picks cheapest for each model
    ```
    
    <Callout type="note">
      Cost optimization is coming in v2. Conduit will maintain real-time pricing data for automatic decisions.
    </Callout>
  </Tab>
</Tabs>

## Health Monitoring

All load balancing strategies automatically handle provider failures:

- **Rate limit detection** → Provider temporarily removed when rate-limited
- **Error rate monitoring** → Providers with high error rates are de-prioritized
- **Automatic recovery** → Unhealthy providers are periodically retested
- **Circuit breaking** → Fast-fail for consistently unavailable providers

<Callout type="tip">
  Conduit monitors provider health every 30 seconds by default. You can adjust
  this interval in your configuration.
</Callout>

## Choosing the Right Strategy

| Use Case                 | Recommended Strategy       | Availability |
| ------------------------ | -------------------------- | ------------ |
| **Production APIs**      | P2C + PeakEWMA             | v0           |
| **Cost optimization**    | Weighted → Cost            | v0 → v2      |
| **Provider migration**   | Weighted (Providers)       | v0           |
| **A/B testing**          | Weighted → Tag-based       | v0 → v3      |
| **Fine-grained control** | Weighted (Model Instances) | v2           |
| **Compliance routing**   | Tag-based                  | v3           |

## Regional Load Balancing _(v0)_

For providers that support multiple regions (like OpenAI's `us-east-1`, `us-west-2`, etc.), Conduit automatically load balances across regions using latency-based routing:

```yaml
# Conduit automatically discovers and balances across regions
providers:
  openai:
    regions: auto  # Discovers all available regions
    # OR specify explicit regions
    regions: ["us-east-1", "us-west-2", "eu-west-1"]
```

<Callout type="info">
  Regional load balancing works with all strategies—P2C will consider region
  latency, weighted will distribute across regions proportionally.
</Callout>

## Best Practices

1. **Start with P2C** for most production workloads—it's battle-tested and self-optimizing
2. **Use weighted routing** when you need predictable traffic distribution
3. **Leverage regional balancing** for global applications to minimize latency
4. **Monitor provider performance** in Conduit's dashboard to optimize your strategy
5. **Test with low traffic** when adding new providers to your load balancer pool
6. **Plan for v2 features** if you need fine-grained model-level control

<Callout type="warning">
  Load balancing works best with at least 2 providers. Single-provider
  configurations will route all traffic to that provider (no balancing occurs).
</Callout>
