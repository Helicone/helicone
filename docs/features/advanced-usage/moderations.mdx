---
title: "Moderations"
sidebarTitle: "Moderations"
description: "Enable OpenAI's moderation feature in your LLM applications to automatically detect and filter harmful content in user messages."
"twitter:title": "Moderations - Helicone OSS LLM Observability"
---

import QuestionsSection from "/snippets/questions-section.mdx";

By integrating with OpenAI's moderation endpoint, Helicone helps you check whether the user message is potentially harmful.

## Why Moderations

- Identifying harmful requests and take action, for example, by filtering it.
- Ensuring any inappropriate or harmful content in user messages is flagged and prevented from being processed.
- Maintaining the safety of the interactions with your application.

## Getting Started

<Warning>
Moderations currently work with **OpenAI models only** (gpt-4, gpt-3.5-turbo, etc.) as it uses OpenAI's moderation endpoint.
</Warning>

To enable moderation, set `Helicone-Moderations-Enabled` to `true`.

<CodeGroup>
```bash cURL
curl https://ai-gateway.helicone.ai/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $HELICONE_API_KEY" \
  -H "Helicone-Moderations-Enabled: true" \ # Add this header and set to true
  -d '{
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "user",
        "content": "How do I enable moderations?"
      }
    ]
}'
```

```python Python
from openai import OpenAI
import os

client = OpenAI(
    base_url="https://ai-gateway.helicone.ai",
    api_key=os.getenv("HELICONE_API_KEY"),
)

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "How do I enable moderations?"}],
    extra_headers={
      "Helicone-Moderations-Enabled": "true", # Add this header and set to true
    }
)
```

```typescript Node.js
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://ai-gateway.helicone.ai",
  apiKey: process.env.HELICONE_API_KEY,
});

const response = await client.chat.completions.create(
  {
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: "How do I enable moderations?" }]
  },
  {
    headers: {
      "Helicone-Moderations-Enabled": "true", // Add this header and set to true
    }
  }
);
```

</CodeGroup>

<Note>
  The moderation call to the OpenAI endpoint will utilize your OpenAI API key configured in Helicone.
</Note>

<Accordion title="A Deep-Dive of the Moderation Process">
  1. **Activation:** When `Helicone-Moderations-Enabled` is true and the provider is OpenAI, the user's latest message is prepared for moderation before any chat completion request.
  2. **Moderation Check:** Our proxy sends the message to the OpenAI Moderation endpoint to assess its content.
  3. **Flag Evaluation:** If the moderation endpoint flags the message as inappropriate or harmful, an error response is generated.

</Accordion>

### Error Repsonse

If the message is flagged, the response will have a `400 status code`. **It's crucial to handle this response appropriately.**

If the message is not flagged, the proxy forwards it to the chat completion endpoint, and the process continues as normal.

Here's an example of the error response when flagged:

```json
{
  "success": false,
  "error": {
    "code": "PROMPT_FLAGGED_FOR_MODERATION",
    "message": "The given prompt was flagged by the OpenAI Moderation endpoint.",
    "details": "See your Helicone request page for more info: https://www.helicone.ai/requests?[REQUEST_ID]"
  }
}
```

## Coming Soon

We're continually expanding our moderation features. Upcoming updates include:

- Customizable moderation criteria

<QuestionsSection />
