---
title: "User Metrics"
sidebarTitle: "User Metrics"
"twitter:title": "User Metrics - Helicone OSS LLM Observability"
---

import QuestionsSection from "/snippets/questions-section.mdx";

When building AI applications with multiple users, you need to track costs, usage patterns, and performance per individual user for billing, optimization, and abuse detection. User Metrics automatically aggregates all requests by user ID, giving you detailed analytics on each user's AI usage across your entire application.

<Frame caption="See user metrics such as the number of requests, costs, and activities.">
  <img
    src="/images/user-metrics/example-user-metric.png"
    alt="User metrics overview: Requests, costs, and activities tracked in Helicone"
  />
</Frame>

## Why use User Metrics

- **Track billing and costs**: Calculate exact costs per user for accurate billing and profitability analysis
- **Detect abuse and anomalies**: Identify users with unusual usage patterns or potential API abuse
- **Optimize user experience**: Find performance bottlenecks and high-cost operations affecting specific users

## Quick Start

<Steps>
<Step title="Add user identification">
Include a `Helicone-User-Id` header in your LLM requests:

```typescript
{
  "Helicone-User-Id": "user-123" // Or email: "user@example.com"
}
```
</Step>

<Step title="Make your request">
Execute your LLM request with the user ID header:

```typescript
const response = await openai.chat.completions.create(
  {
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: "Hello!" }]
  },
  {
    headers: {
      "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
      "Helicone-User-Id": "user-123"
    }
  }
);
```
</Step>

<Step title="View user analytics">
Access detailed per-user metrics in the Users tab of your Helicone dashboard, including costs, request volumes, and usage patterns.
</Step>
</Steps>

## Configuration Options

### Basic Settings

User identification can be set through multiple methods:

| Method | Header/Parameter | Type | Description | Example |
|--------|------------------|------|-------------|----------|
| **Helicone Header** | `Helicone-User-Id` | `string` | Recommended approach for user tracking | `"user-123"` |
| **OpenAI Parameter** | `user` in request body | `string` | OpenAI's built-in user parameter | `"user-123"` |

### Advanced Settings

<AccordionGroup>
<Accordion title="User ID Best Practices">
Choose appropriate user identifiers for your use case:

```typescript
// ✅ Good - consistent and identifiable
{
  "Helicone-User-Id": "user-12345",        // Internal user ID
  "Helicone-User-Id": "user@example.com",  // Email address
  "Helicone-User-Id": "org-123-user-456"   // Hierarchical ID
}

// ❌ Avoid - inconsistent or non-identifiable
{
  "Helicone-User-Id": "session-abc123",    // Session ID, not user ID
  "Helicone-User-Id": "anonymous",         // Generic identifier
  "Helicone-User-Id": "123"                // Too simple, potential conflicts
}
```
</Accordion>

<Accordion title="Multiple Identification Methods">
You can use both OpenAI's user parameter and Helicone's header:

```typescript
const response = await openai.chat.completions.create(
  {
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: "Hello!" }],
    user: "user-123" // OpenAI's user parameter
  },
  {
    headers: {
      "Helicone-User-Id": "user-123" // Helicone's header (takes precedence)
    }
  }
);
```

<Note>If both are provided, `Helicone-User-Id` takes precedence for user metrics.</Note>
</Accordion>
</AccordionGroup>

## Use Cases

<Tabs>
<Tab title="SaaS Billing & Analytics">
Track costs per user for accurate billing and profitability analysis:

<CodeGroup>
```typescript Node.js
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.helicone.ai/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
  },
});

// Track AI costs per customer for billing
async function handleUserRequest(userId, prompt) {
  const response = await openai.chat.completions.create(
    {
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }]
    },
    {
      headers: {
        "Helicone-User-Id": userId,
        "Helicone-Property-Plan": "premium", // Track by plan type
        "Helicone-Property-Feature": "chat" // Track by feature
      }
    }
  );
  
  // Use response...
  return response;
}

// Now analyze:
// - Total cost per user this month
// - Average cost per user by plan type  
// - Which users are most/least profitable
```

```python Python
import openai

client = openai.OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    base_url="https://oai.helicone.ai/v1",
    default_headers={
        "Helicone-Auth": f"Bearer {os.environ.get('HELICONE_API_KEY')}",
    }
)

def handle_user_request(user_id, prompt):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        extra_headers={
            "Helicone-User-Id": user_id,
            "Helicone-Property-Plan": "premium",
            "Helicone-Property-Feature": "chat"
        }
    )
    return response
```
</CodeGroup>
</Tab>

<Tab title="Abuse Detection & Rate Limiting">
Monitor user behavior patterns to detect abuse and implement smart rate limiting:

```typescript
import OpenAI from "openai";

class AIService {
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      baseURL: "https://oai.helicone.ai/v1",
      defaultHeaders: {
        "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
      },
    });
  }

  async processRequest(userId, prompt, userTier = "free") {
    const response = await this.openai.chat.completions.create(
      {
        model: userTier === "premium" ? "gpt-4o-mini" : "gpt-3.5-turbo",
        messages: [{ role: "user", content: prompt }]
      },
      {
        headers: {
          "Helicone-User-Id": userId,
          "Helicone-Property-Tier": userTier,
          "Helicone-Property-RequestType": this.classifyRequest(prompt)
        }
      }
    );

    return response;
  }

  classifyRequest(prompt) {
    if (prompt.length > 1000) return "long-form";
    if (prompt.includes("code")) return "code-generation";
    return "general";
  }
}

// In Helicone dashboard, monitor:
// - Users with sudden usage spikes
// - High-cost requests by user
// - Request patterns that indicate abuse
```
</Tab>

<Tab title="Multi-Tenant Application Analytics">
Analyze usage patterns across different organizations and teams:

```typescript
// For a B2B SaaS with multiple organizations
async function handleOrgUserRequest(orgId, userId, prompt) {
  const response = await openai.chat.completions.create(
    {
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }]
    },
    {
      headers: {
        "Helicone-User-Id": `${orgId}-${userId}`, // Hierarchical user ID
        "Helicone-Property-Organization": orgId,
        "Helicone-Property-Department": "engineering",
        "Helicone-Property-Role": "developer"
      }
    }
  );

  return response;
}

// Analytics you can now track:
// - AI costs per organization
// - Usage by department within orgs
// - Most active users per organization
// - Feature adoption across different user roles
```
</Tab>
</Tabs>

## Related Features

<CardGroup cols={2}>
<Card title="Custom Properties" icon="tag" href="/features/advanced-usage/custom-properties">
Combine user tracking with custom properties for deeper segmentation
</Card>

<Card title="Sessions" icon="link" href="/features/sessions">
Track user sessions and multi-step workflows per user
</Card>

<Card title="Webhooks" icon="webhook" href="/features/webhooks">
Get real-time notifications about user activity and usage patterns
</Card>

<Card title="Alerts" icon="bell" href="/features/alerts">
Set up alerts for unusual user behavior or usage spikes
</Card>
</CardGroup>

<QuestionsSection />
