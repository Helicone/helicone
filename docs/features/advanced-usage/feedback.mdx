---
title: "User Feedback"
sidebarTitle: "User Feedback"
description: "Collect and analyze user feedback on LLM responses. Evaluate output quality, identify trends, and optimize your AI application's performance based on user satisfaction."
"twitter:title": "User Feedback - Helicone OSS LLM Observability"
---

import QuestionsSection from "/snippets/questions-section.mdx";

## Introduction

User feedback is a feature that allows users to evaluate the responses generated by the LLM. This feedback can be either `positive` or `negative`, offering crucial insights into the effectiveness and relevance of the LLM's outputs based on user's satisfaction.

### Why User Feedback

User feedback allows you to:

- Gauge the efficacy of the LLM's responses.
- Optimize the user experience of your LLM app as you modify your prompts or models based on the received feedback.
- Identify trends in feedback to make informed decisions about model training or fine-tuning.

## Quick Start

### Option 1: Logging Feedback using Helicone's Node Package

If you're using Helicone's Node package, here's a simplified example to log feedback:

<CodeGroup>

```js Node.js
const {
  HeliconeProxyOpenAIApi,
  HeliconeProxyConfiguration,
  HeliconeFeedbackRating,
} = require("helicone"); // Replace with the actual package name

// Configuration for the OpenAI client
const config = new HeliconeProxyConfiguration({
  apiKey: process.env.OPENAI_API_KEY,
  heliconeMeta: {
    apiKey: process.env.MY_HELICONE_API_KEY,
  },
});

// Instantiate the OpenAI client
const openAi = new HeliconeProxyOpenAIApi(config);

// Generate a chat completion and log feedback
const result = await openAi.createChatCompletion({
  model: "gpt-3.5-turbo",
  messages: [{ role: "user", content: "Say hi!" }],
});

const heliconeId = result.headers[openAi.helicone.heliconeIdHeader];

// Log feedback (either Positive or Negative)
const rating = HeliconeFeedbackRating.Positive; // or HeliconeFeedbackRating.Negative
await openAi.helicone.logFeedback(heliconeId, rating);
```

```python LangChain
import uuid
from langchain.chat_models.openai import ChatOpenAI
import requests
import json
HELICONE_AUTH = "Bearer <API_KEY>"

def provide_feedback(heliconeId, rating):
    url = f"https://api.helicone.ai/v1/request/{heliconeId}/feedback"
    headers = {
        "Helicone-Auth": HELICONE_AUTH,
        "Content-Type": "application/json",
    }
    data = {
        "rating": rating  // True for positive, False for negative
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))


request_id = str(uuid.uuid4())
ChatOpenAI.openai_api_base = "https://oai.helicone.ai/v1"
llm = ChatOpenAI(
    openai_api_base="https://oai.helicone.ai/v1",
    headers={
        "Helicone-Auth": HELICONE_AUTH,
        "Helicone-Request-Id": request_id
    }
)

llm_result = llm.predict("What is a Helicone")
provide_feedback(request_id, True)
```

</CodeGroup>

### Option 2: Logging Feedback using Fetch

Without Helicone's Node package, you can still log feedback using the Fetch API. For detailed documentation, refer to:

<Card
  title="Fetch API for Feedback"
  href="https://docs.helicone.ai/rest/request/post-v1request-feedback"
  icon="link"
>
  Not using Helicone's Node Package? We got you, too.
</Card>

<Note>
  In some packages or scenarios, you may not be able to retrieve headers to get
  the `helicone-id`. However, you can still log feedback by supplying a UUID as
  the `helicone-id`.
</Note>

Here's a simple example:

```js
import OpenAI from "openai";

// Initialize the OpenAI client with Helicone integration
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.helicone.ai/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
  },
});

// Generate a chat completion
const {
  data: completions,
  response,
}: { data: ChatCompletion, response: Response } = await openai.chat
  .completions({
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: "Say hi!" }],
  })
  .withResponse();

// Retrieve the heliconeId header
const heliconeId = response.headers.get("helicone-id");

// Log feedback
const options = {
  method: "POST",
  headers: {
    "Helicone-Auth": "YOUR_HELICONE_AUTH_HEADER",
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    rating: true, // true for positive, false for negative
  }),
};

const response = await fetch(
  `https://api.helicone.ai/v1/request/${heliconeId}/feedback`,
  options
);
```

<QuestionsSection />
