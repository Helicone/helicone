---
title: "Feedback"
description: "Helicone now allows users to provide feedback on LLM responses, indicating whether they found the response helpful or not."
---

### What is User Feedback?

User feedback is a mechanism that allows users to rate the responses from the LLM. This feedback can be either positive or negative, providing valuable insights into the performance and relevance of the LLM's outputs.

### Using User Feedback

With user feedback, you can:

- Understand the effectiveness of the LLM's responses.
- Improve the quality of interactions by adjusting prompts or models based on feedback.
- Analyze trends in feedback to make informed decisions about model training or fine-tuning.

### Logging Feedback using the Node Package

Here's a simplified example of how to log feedback using our Node package:

<CodeGroup>

```js Node.js
const {
  HeliconeProxyOpenAIApi,
  HeliconeProxyConfiguration,
  HeliconeFeedbackRating,
} = require("helicone"); // Replace with the actual package name

// Configuration for the OpenAI client
const config = new HeliconeProxyConfiguration({
  apiKey: process.env.OPENAI_API_KEY,
  heliconeMeta: {
    apiKey: process.env.MY_HELICONE_API_KEY,
  },
});

// Create the OpenAI client
const openAi = new HeliconeProxyOpenAIApi(config);

// Create a chat completion and log feedback
const result = await openAi.createChatCompletion({
  model: "gpt-3.5-turbo",
  messages: [{ role: "user", content: "Say hi!" }],
});

const heliconeId = result.headers[openAi.helicone.heliconeIdHeader];

// Log feedback (either Positive or Negative)
const rating = HeliconeFeedbackRating.Positive; // or HeliconeFeedbackRating.Negative
await openAi.helicone.logFeedback(heliconeId, rating);
```

```python LangChain
import uuid
from langchain.chat_models.openai import ChatOpenAI
import requests
import json
HELICONE_AUTH = "Bearer <API_KEY>"

def provide_feedback(heliconeId, rating):
    url = "https://api.hconeai.com/v1/feedback"
    headers = {
        "Helicone-Auth": HELICONE_AUTH,
        "Content-Type": "application/json",
    }
    data = {
        "helicone-id": heliconeId,
        "rating": rating  # True for positive, False for negative
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))


request_id = str(uuid.uuid4())
ChatOpenAI.openai_api_base = "https://oai.hconeai.com/v1"
llm = ChatOpenAI(
    openai_api_base="https://oai.hconeai.com/v1",
    headers={
        "Helicone-Auth": HELICONE_AUTH,
        "Helicone-Request-Id": request_id
    }
)

llm_result = llm.predict("What is a Helicone")
provide_feedback(request_id, True)
```

</CodeGroup>

### Logging Feedback using Fetch

<Note>
In some pacakges or cases you may not be able to retrieve headers to get the `helicone-id`. You can still log feedback by supplying a UUID as the `helicone-id`.

See the [Helicone API docs](/docs/helicone-headers/intro.mdx) for more information.

</Note>
If you're not using our package, you can still log feedback using the Fetch API. Here's a simple example:

```js
import OpenAI from "openai";

// Initialize the OpenAI client with Helicone integration
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: "https://oai.hconeai.com/v1",
  defaultHeaders: {
    "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
  },
});

// Create a chat completion
const {
  data: completions,
  response,
}: { data: ChatCompletion, response: Response } = await openai.chat
  .completions({
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: "Say hi!" }],
  })
  .withResponse();

// Get the heliconeId header
const heliconeId = response.headers.get("helicone-id");

// Log feedback
const options = {
  method: "POST",
  headers: {
    "Helicone-Auth": "YOUR_HELICONE_AUTH_HEADER",
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    "helicone-id": heliconeId,
    rating: true, // true for positive, false for negative
  }),
};

const response = await fetch("https://api.hconeai.com/v1/feedback", options);
```
