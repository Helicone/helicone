---
title: "LiteLLM Integration with OpenLLmetry"
sidebarTitle: "OpenLLmetry"
description: "Easily log your LiteLLM API calls to Helicone using OpenLLmetry."
"twitter:title": "LiteLLM Integration with OpenLLmetry - Helicone OSS LLM Observability"
---

# Overview

Helicone's OpenLLmetry integration allows you to log your LiteLLM API calls to Helicone without modifying your code.


<Tabs>
  <Tab title="Python">
  <Steps>
  <Step title="Install Helicone Async">
  ```bash
  pip install helicone-async
  ```
  </Step>
  <Step title="Initialize Logger">

```python

from helicone_async import HeliconeAsyncLogger
from openai import OpenAI
from litellm import completion

logger = HeliconeAsyncLogger(
    api_key=HELICONE_API_KEY,
)

logger.init()

client = OpenAI(api_key=OPENAI_API_KEY)

#openai call
response = completion(
  model="gpt-3.5-turbo",
  messages=[{"role": "user", "content": "Hi ðŸ‘‹ - i'm openai"}],
  metadata={
    "Helicone-Property-Hello": "World"
  }
)

#cohere call
response = completion(
  model="command-r",
  messages=[{"role": "user", "content": "Hi ðŸ‘‹ - i'm cohere"}],
  metadata={
    "Helicone-Property-Hello": "World"
  }
)
print(response.choices[0])

```

</Step>
</Steps>
</Tab>

</Tabs>

Read more about [OpenLLmetry](/getting-started/integration-method/openllmetry)