---
title: "OpenRouter Integration"
sidebarTitle: "OpenRouter"
description: "Integrate Helicone with OpenRouter, a unified API for accessing multiple LLM providers. Monitor and analyze AI interactions across various models through a single, streamlined interface."
"twitter:title": "OpenRouter Integration - Helicone OSS LLM Observability"
icon: "cloud"
iconType: "solid"
---

[OpenRouter](https://openrouter.ai/) is a tool that helps you integrate multiple NLP APIs in your application. It provides a single API endpoint that you can use to call multiple NLP APIs.

You can follow their documentation here: [https://openrouter.ai/docs#quick-start](https://openrouter.ai/docs#quick-start)

# Gateway Integration

<Steps>
  <Step title="Create a Helicone account">
    Log into [helicone](https://www.helicone.ai) or create an account. Once you have an account, you
    can generate an [API key](https://helicone.ai/developer).
  </Step>
  <Step title="Create an OpenRouter account">
    Log into www.openrouter.ai or create an account. Once you have an account, you
    can generate an [API key](https://openrouter.ai/docs#api-keys).
  </Step>
  <Step title="Set HELICONE_API_KEY and OPENROUTER_API_KEY as environment variable">
```javascript
HELICONE_API_KEY=<your API key>
OPENROUTER_API_KEY=<your API key>
```
  </Step>
  <Step title="Modify the base URL and add Auth headers">

Replace the following OpenRouter URL with the Helicone Gateway URL:

`https://openrouter.ai/api/v1/chat/completions` -> `https://openrouter.helicone.ai/api/v1/chat/completions`

and then add the following authentication headers.

```
Helicone-Auth: `Bearer ${HELICONE_API_KEY}`
Authorization: `Bearer ${OPENROUTER_API_KEY}`
```

</Step>
</Steps>

Now you can access all the models on OpenRouter with a simple fetch call:

## Example

```typescript
fetch("https://openrouter.helicone.ai/api/v1/chat/completions", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${OPENROUTER_API_KEY}`,
    "Helicone-Auth": `Bearer ${HELICONE_API_KEY}`,
    "HTTP-Referer": `${YOUR_SITE_URL}`, // Optional, for including your app on openrouter.ai rankings.
    "X-Title": `${YOUR_SITE_NAME}`, // Optional. Shows in rankings on openrouter.ai.
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    model: "openai/gpt-3.5-turbo", // Optional (user controls the default),
    messages: [{ role: "user", content: "What is the meaning of life?" }],
    stream: true,
  }),
});
```

We now also support streaming in responses from OpenRouter.

<Info>
  **Note:** usage data and cost calculations _while streaming_ are only offered
  for OpenAI and Anthropic models. For non-stream requests, usage data and cost
  calculations are available for all models.
</Info>

For more information on how to use headers, see [Helicone Headers](https://docs.helicone.ai/helicone-headers/header-directory#utilizing-headers) docs.
And for more information on how to use OpenRouter, see [OpenRouter Docs](https://openrouter.ai/docs).
