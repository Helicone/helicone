---
title: "Gateway Integration"
description: "The optimal method to integrate with Helicone is through our Gateway. This API provides a seamless interface for sending requests and responses to Helicone."
---

# Overview

The Gateway serves as a unified entry point for all traffic, regardless of your provider. It enables you to dispatch requests to any provider through a single endpoint. This provides you with the advantage of utilizing all of Helicone's features such as [Caching](/features/advanced-usage/caching), [Monitoring](https://helicone.ai), [Rate Limiting](/features/advanced-usage/custom-rate-limits), [Vaults](/features/advanced-usage/vaults), [Feedback](/features/advanced-usage/feedback), and many more for any provider.

## Simple Integration

This is achieved by allowing you to determine the destination of your request by specifying the provider in the URL path. For instance, if you wish to send a request to LemonFox, you would send a request to `https://gateway.helicone.ai` instead of `https://api.lemonfox.ai`, but you would specify the provider and the endpoint in the URL path within the headers of your request.

## Ex 1

`api.groq.com/openai/v1"` -> `gateway.helicone.ai/openai/v1`

- Header: `Helicone-Target-Url: https://api.groq.com`

## Ex 2

`api.lemonfox.ai/v1` -> `gateway.helicone.ai/v1`

- Header: `Helicone-Target-Url: https://api.lemonfox.ai`

# How to Use the Gateway

<Tabs>
  <Tab title="Python">
    ```python
    import openai

    openai.api_base = "https://gateway.helicone.ai"

    # Create the completion request

    openai.ChatCompletion.create(
      model="[DEPLOYMENT]",
      messages=[{"role": "User", "content": "Say hi!"}],
      headers={
        "Helicone-Auth": "Bearer [HELICONE_API_KEY]",
        "Helicone-Target-Url": "https://api.lemonfox.ai",
        "Helicone-Target-Provider": "LemonFox",
      }
    )
    ```

  </Tab>

  <Tab title="Node.js">
  <Note>Ensure you include api-version in all of your requests</Note>
  <AccordionGroup>

    <Accordion title="OpenAI v4+">
      ```typescript
      const openai = new OpenAI({
        baseURL: "https://gateway.helicone.ai",
        defaultHeaders: {
          "Helicone-Auth": `Bearer [HELICONE_API_KEY]`,
          "Helicone-Target-Url": "https://api.lemonfox.ai",
        },
      });
      ```
    </Accordion>

    <Accordion title="OpenAI <v4">
      ```typescript
      import { Configuration, OpenAIApi } from "openai";

      const configuration = new Configuration({
        apiKey: "[AZURE_OPENAI_API_KEY]",
        basePath: "https://gateway.helicone.ai/",
        baseOptions: {
          headers: {
            "Helicone-Auth": `Bearer [HELICONE_API_KEY]`,
            "api-key": "[AZURE_OPENAI_API_KEY]",
            "Helicone-Target-Url": "https://[AZURE_DOMAIN].openai.azure.com",
          },
          params: {
            "api-version": "[API_VERSION]",
          },
        },
      });

      const openai = new OpenAIApi(configuration);
      ```

    </Accordion>
    <Accordion title="Vertex AI SDK">
    <Note>
      ENSURE YOU ARE USING VERTEX AI SDK **1.1.0** OR HIGHER.
    </Note>
      ```typescript
      import {
        VertexAI,
        RequestOptions,
      } from "@google-cloud/vertexai";
      const vertex_ai = new VertexAI({
        project: project,
        location: location,
        apiEndpoint: "gateway.helicone.ai",
      });

      const customHeaders = new Headers({
        "Helicone-Auth": `Bearer ${process.env.HELICONE_API_KEY}`,
        "Helicone-Target-URL": "https://[LOCATION]-aiplatform.googleapis.com",
      });

      const requestOptions = {
        customHeaders: customHeaders,
      } as RequestOptions;

      const generativeModel = vertex_ai.getGenerativeModel(
        {
          model: "gemini-pro-vision",
        },
        requestOptions
      );
      ```
    </Accordion>

  </AccordionGroup>

  </Tab>
  <Tab title="Python w/package">

```python
from helicone.openai_proxy import openai

openai.api_base = "https://gateway.helicone.ai"

response = openai.ChatCompletion.create(
  engine = 'gpt-35-turbo',
  messages = [{
      'role': 'user',
      'content': "Hello World!"
  }],
  max_tokens=15,
)

```

</Tab>

  <Tab title="LangChain JS">

```javascript
const model = new ChatOpenAI({
  azureOpenAIBasePath: "https://gateway.helicone.ai",
  configuration: {
    organization: "[organization]",
    defaultHeaders: {
      "Helicone-Auth": `Bearer ${heliconeApiKey}`,
      "Helicone-Target-Url": "https://api.lemonfox.ai",
      "Helicone-Target-Provider": "LemonFox",
    },
  },
});
```

  </Tab>

  <Tab title="LangChain">

```python
from langchain.chat_models import AzureChatOpenAI
llm = ChatOpenAI(
    openai_api_key='<OPENAI_API_KEY>',
    headers={
        "Helicone-Auth": f"Bearer {env.HELICONE_API_KEY}"
        "Helicone-Target-Url": "https://api.lemonfox.ai",
        "Helicone-Target-Provider": "LemonFox",
    },
    openai_api_base="https://gateway.helicone.ai/v1",
)
```

  </Tab>
  <Tab title="cURL">
  ```bash
    curl --request POST \
    --url https://gateway.helicone.ai/v1/chat/completetions \
    --header 'Helicone-Auth: Bearer [HELICONE_KEY]' \
    --header 'Helicone-Target-Url: https://api.lemonfox.ai' \
    --header 'Helicone-Target-Provider: LemonFox' \
    --header 'content-type: application/json' \
    --data '{
      "messages": [
        {
          "role": "user",
          "content": "Answer in one word"
        }],
      "max_tokens": 800,
      "temperature": 1,
      "model": "gpt-3.5-turbo-0613"
    }'
  ```
</Tab>
</Tabs>

# Examples

<Accordion title="Cloudflare gateway example">

Current gateway request

```bash
curl --request POST \
  --url https://gateway.ai.cloudflare.com/v1/[ACCOUNT-ID]/[GATEWAY-ID]/openai/chat/completions \
  --header 'Authorization: Bearer <API_KEY>' \
  --header 'Content-Type: application/json' \
  -d ' {
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "What is Cloudflare?"
      }
    ]
  }
'
```

Simply change `gateway.ai.cloudflare.com` to `gateway.helicone.ai` and add the following headers

```bash
curl --request POST \
  --url https://gateway.helicone.ai/v1/[ACCOUNT-ID]/[GATEWAY-ID]/openai/chat/completions \
  --header 'Helicone-Auth: Bearer <Helicone_Auth>' \
  --header 'Helicone-Target-Url: https://gateway.ai.cloudflare.com' \
  --header 'Authorization: Bearer <API_KEY>' \
  --header 'content-type: application/json' \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "What is Cloudflare?"
      }
    ]
  }
'
```

</Accordion>

<Accordion title="TogetherAI example">
```bash
curl --request POST \
  --url https://gateway.helicone.ai/v1/chat/completions \
  --header 'Authorization: Bearer <TOGETHERAI_API_KEY>' \
  --header 'Content-Type: application/json' \
  --header 'Helicone-Auth: Bearer <HELICONE_API_KEY>' \
  --header 'Helicone-Target-Provider: Together-AI' \
  --header 'Helicone-Target-Url: https://api.together.xyz' \
  --data '{
  "model": "meta-llama/Llama-2-70b-chat-hf",
  "max_tokens": 512,
  "messages": [
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ]
}'
```
</Accordion>

<Accordion title="Gemini Vertex Examples">
Gemini Pro

```bash
curl --request POST \
  --url https://gateway.helicone.ai/v1/projects/<PROJECT_ID>/locations/<LOCATION>/publishers/google/models/gemini-pro:streamGenerateContent \
  --header 'Authorization: Bearer <GEMINI_API_KEY>' \
  --header 'Content-Type: application/json' \
  --header 'Helicone-Auth: Bearer <HELICONE_API_KEY>' \
  --header 'Helicone-Target-Url: https://<LOCATION>-aiplatform.googleapis.com' \
  --data '{
  "contents": {
    "role": "user",
    "parts": {
      "text": "Which theaters in Mountain View show Barbie movie?"
    }
  },
}'
```

Gemini Pro Vision

```bash
curl --request POST \
  --url https://gateway.helicone.ai/v1/projects/<PROJECT_ID>/locations/<LOCATION>/publishers/google/models/gemini-pro-vision:streamGenerateContent \
  --header 'Authorization: Bearer <GEMINI_API_KEY>' \
  --header 'Content-Type: application/json' \
  --header 'Helicone-Auth: Bearer <HELICONE_API_KEY>' \
  --header 'Helicone-Target-Url: https://<LOCATION>-aiplatform.googleapis.com' \
  --data '{
  "contents": {
    "role": "user",
    "parts": [
      {
        "text": "What is the capital of France?"
      }
    ]
  }
}'
```

</Accordion>

# Approved Domains

| Provider    | Domain Name                  | Cost Support | Dedicated Domain         |
| ----------- | ---------------------------- | ------------ | ------------------------ |
| OpenAI      | `api.openai.com`             | ✅           | `oai.helicone.ai`        |
| Anthropic   | `api.anthropic.com`          | ✅           | `anthropic.helicone.ai`  |
| Together-AI | `api.together.xyz`           | ✅           | `together.helicone.ai`   |
| OpenRouter  | `openrouter.ai`              | ✅           | `openrouter.helicone.ai` |
| Fireworks   | `api.fireworks.ai`           | ✅           | `fireworks.helicone.ai`  |
| Azure       | `openai.azure.com`           | ✅           | ❌                       |
| Groq        | `api.groq.com`               | ❌           | `groq.helicone.ai`       |
| Deepinfra   | `api.deepinfra.com`          | ❌           | `deepinfra.helicone.ai`  |
| Anyscale    | `api.endpoints.anyscale.com` | ❌           | ❌                       |
| Cloudflare  | `gateway.ai.cloudflare.com`  | ❌           | ❌                       |
| LemonFox    | `api.lemonfox.ai`            | ❌           | ❌                       |
| Perplexity  | `api.perplexity.ai`          | ❌           | ❌                       |
| Mistral     | `api.mistral.ai`             | ❌           | ❌                       |

## Unapproved Domains

To protect our community from potential threats, we have certain restrictions for unapproved domains. To ensure a safe internet environment, you can use any unapproved domain, but you will be limited to the following:

- 10,000 requests per day
- 1 request per second

The integration is the same as the approved domains, but you will need to add the following header:

```bash
--header 'Helicone-Target-Url: https://[DOMAIN_NAME]'
```

## Automated Mappers ("Model is pending mapping")

<Frame>![Helicone will automatically determine how to map any unsupported model that you throw at it using our automated mapper.](/images/integrations/model-is-pending-mapping.png)</Frame>

Helicone will automatically determine how to map any unsupported model that you throw at it using our automated mapper. Helicone intelligently determines the schema of the model and maps it to the appropriate schema for the provider. This allows you to use any model you want without having to wait for us to manually map it.

Mappings are on a specialized job that runs every 24 hours, so your UI may not be mapped immediately. If you would like to expedite the mapping, please contact us at engineering@helicone.ai or connect with us on [Discord](https://discord.gg/zsSTcH2qhG)!

## How to Get a Domain Approved or Mapper Expedited

To get a domain approved, please contact us at engineering@helicone.ai or connect with us on [Discord](https://discord.gg/zsSTcH2qhG)!

> Subject: Domain Approval Request
>
> Body: Is this a personal deployment? If not, what is the name of the company? What is the domain name?
>
> If it is a personal deployment, please provide proof you own the domain by updating a text record
> with the following value: `hconeai-verification=true`
