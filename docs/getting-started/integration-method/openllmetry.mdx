---
title: "OpenLLMetry Async Integration"
sidebarTitle: "OpenLLMetry"
description: "Log LLM traces directly to Helicone, bypassing our proxy, with OpenLLMetry. Supports OpenAI, Anthropic, Azure OpenAI, Cohere, Bedrock, Google AI Platform, and more."
"twitter:title": "OpenLLMetry Async Integration - Helicone OSS LLM Observability"
icon: "code"
iconType: "solid"
---

# Overview

Async Integration let's you log events and calls without placing Helicone in your app's critical
path. This ensures that an issue with Helicone will not cause an outage to your app.

<Tabs>
  <Tab title="Node.js">
  <Steps>
  <Step title="Install Helicone Async">
  ```bash
  npm install @helicone/async
  ```
  </Step>
  <Step title="Initialize Logger">
  ```typescript
import { HeliconeAsyncLogger } from "@helicone/async";
import OpenAI from "openai";

const logger = new HeliconeAsyncLogger({
    apiKey: process.env.HELICONE_API_KEY,
    // pass in the providers you want logged
    providers: {
      openAI: OpenAI,
      //anthropic: Anthropic,
      //cohere: Cohere
      // ...
    }
});
logger.init();

const openai = new OpenAI();

async function main() {
    const completion = await openai.chat.completions.create({
      messages: [{"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}],
      model: "gpt-3.5-turbo",
    });

    console.log(completion.choices[0]);
}

main();
```
</Step>
<Step title="Properties">

You can set properties on the logger to be used in Helicone using the `withProperties` method. (These can be used for [Sessions](/features/sessions), [User Metrics](/features/advanced-usage/user-metrics), and more.)

```typescript
const sessionId = randomUUID();

logger.withProperties({
    "Helicone-Session-Id": sessionId,
    "Helicone-Session-Path": "/abstract",
    "Helicone-Session-Name": "Course Plan",
}, () => {
    const completion = await openai.chat.completions.create({
        ...
    })
})
```
</Step>
</Steps>

</Tab>
  <Tab title="Python">
  <Steps>
  <Step title="Install Helicone Async">
  ```bash
  pip install helicone-async
````

  </Step>
  <Step title="Initialize Logger">
  ```python
from helicone_async import HeliconeAsyncLogger
from openai import OpenAI

logger = HeliconeAsyncLogger(
    api_key=HELICONE_API_KEY,
)

logger.init()

client = OpenAI(api_key=OPENAI_API_KEY)

# Make the OpenAI call

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Who won the world series in 2020?"},
      {"role": "assistant",
      "content": "The Los Angeles Dodgers won the World Series in 2020."},
      {"role": "user", "content": "Where was it played?"}]
)

print(response.choices[0])

```
</Step>
<Step title="Properties">
You can set properties on the logger to be used in Helicone using the `set_properties` method. (These can be used for [Sessions](/features/sessions), [User Metrics](/features/advanced-usage/user-metrics), and more.)

```python
session_id = str(uuid.uuid4())

logger.set_properties({
    "Helicone-Session-Id": session_id,
    "Helicone-Session-Path": "/abstract",
    "Helicone-Session-Name": "Course Plan",
})

response = client.chat.completions.create(
    ...
)
```
</Step>
</Steps>
</Tab>

</Tabs>

# Supported Providers

- [x] OpenAI
- [x] Anthropic
- [x] Azure OpenAI
- [x] Cohere
- [x] Bedrock
- [x] Google AI Platform

# Other Integrations

- [Comparing Proxy vs Async Integration](/references/proxy-vs-async)
- [Gateway Integration](/getting-started/integration-method/gateway)
```
