---
title: "OpenAI"
---

This page will show you how to log requests in Helicone when using OpenAI. This does not use the Helicone Proxy.
For more information on Async Logging, see the [Proxy vs Async](/getting-started/proxy-vs-asyn) page.

<Tabs>
  <Tab title="Python">

## 1 line integration

Add `HELICONE_API_KEY` to your environment variables.

```bash
export HELICONE_API_KEY=sk-<your-api-key>
# You can also set it in your code (See below)
```

Replace

```python
from openai import openai
```

with

```python
from helicone.openai_async import openai
```

## More complex example

```python
from helicone.openai_async import openai, Meta

# export HELICONE_API_KEY=sk-<your-api-key>

# or ...

# from helicone.globals import helicone_global

# helicone_global.api_key = "sk-<your-api-key>"

x = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[{
  "role": "system",
  "content": "This will be logged"
  }],
  max_tokens=512,
  helicone_meta=Meta(
    custom_properties={
    "age": 25
    }
  )
)

```

  </Tab>
  <Tab title="NodeJS">
## 1 line integration

Add `HELICONE_API_KEY` to your environment variables.

```bash
export HELICONE_API_KEY=sk-<your-api-key>
# You can also set it in your code (See below)
```

Replace

```typescript
const { Configuration, OpenAIApi } = require("openai");
```

with

```typescript
const { HeliconeAsyncConfiguration as Configuration, HeliconeAsyncOpenAIApi as OpenAIApi } = require("helicone");
```

## More complex example

```typescript
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
  heliconeMeta: {
    apiKey: process.env.HELICONE_API_KEY,
  },
});
const openai = new OpenAIApi(configuration);

const chatCompletion = await openai.createChatCompletion({
  model: "gpt-3.5-turbo",
  messages: [{ role: "user", content: "Hello world" }],
  heliconeMeta: {
    properties: {
      customId: "1234",
    },
    user: "test-user",
  },
});
console.log(chatCompletion.data.choices[0].message);
```

  </Tab>
  <Tab title="Raw">
  The Helicone Async Log Request API is used for logging requests and responses that
go through an endpoint. This is highly useful for auditing, debugging and observing
the behavior of your interactions with the system.

## Request Structure

A typical request will have the following structure:

### Endpoint

```

POST https://api.hconeai.com/oai/v1/log

```

### Headers

| Name          | Value            |
| ------------- | ---------------- |
| Authorization | Bearer {API_KEY} |

Replace `{API_KEY}` with your actual API Key.

### Body

The body of the request should follow the `HeliconeAyncLogRequest` structure:

```ts
export type HeliconeAyncLogRequest = {
  providerRequest: ProviderRequest;
  providerResponse: ProviderResponse;
  timing: Timing;
};

export type ProviderRequest = {
  url: string;
  json: {
    [key: string]: any;
  };
  meta: Record<string, string>;
};

export type ProviderResponse = {
  json: {
    [key: string]: any;
  };
  status: number;
  headers: Record<string, string>;
};

export type Timing = {
  // From Unix epoch in Milliseconds
  startTime: {
    seconds: number;
    milliseconds: number;
  };
  endTime: {
    seconds: number;
    milliseconds: number;
  };
};
```

## Example Usage

Here's an example using curl:

```sh
curl -X POST https://api.hconeai.com/oai/v1/log \
-H 'Authorization: Bearer your_api_key' \
-H 'Content-Type: application/json' \
-d '{
  "providerRequest": {
    "url": "https://example.com",
    "json": {
      "key1": "value1",
      "key2": "value2"
    },
    "meta": {
      "metaKey1": "metaValue1",
      "metaKey2": "metaValue2"
    }
  },
  "providerResponse": {
    "json": {
      "responseKey1": "responseValue1",
      "responseKey2": "responseValue2"
    },
    "status": 200,
    "headers": {
      "headerKey1": "headerValue1",
      "headerKey2": "headerValue2"
    }
  },
  "timing": {
    "startTime": {
      "seconds": 1625686222,
      "milliseconds": 500
    },
    "endTime": {
      "seconds": 1625686244,
      "milliseconds": 750
    }
  }
}'
```

In the curl command above, replace `your_api_key` with your actual API key, and adjust the values in the JSON to fit your actual request and response data and timing.

The response body is a JSON object of the entire response returned by OpenAI, unless it is a streamed request. In that case, it is a JSON object with a key called "streamed_data", which is an array of every single chunk.

</Tab>
</Tabs>
