---
title: "Manual Self-Hosting"
sidebarTitle: "Manual"
description: "Deploy your own instance of Helicone. Follow our step-by-step guide to set up a local, self-hosted version of the LLM observability platform."
"twitter:title": "Self-Hosted Helicone Deployment - Open Source LLM Observability"
---

<Warning>
  **Deploy with Docker Compose!** We recommend deploying with [Docker
  Compose](https://docs.helicone.ai/getting-started/self-deploy-docker), as it
  works easily with just **one line**.
</Warning>

At Helicone we believe that open-source software makes the world a better place. We are committed to open-source and we made a guide to make it easy for you to deploy your own instance of Helicone.

## Running locally

Running Helicone locally should be super easy. Just a few scripts.

Please clone our Repo and follow the instructions below.

```bash
git clone git@github.com:Helicone/helicone.git
cd helicone
```

## Step 1 - Install all the things

Requirements

- Docker

### Install [Supabase](https://supabase.com/docs/guides/cli)

```bash
brew install supabase/tap/supabase
```

### Install Wrangler and Yarn

```bash
nvm install 18.11.0
nvm use 18.11.0
npm install -g wrangler
npm install -g yarn
```

## Step 2 - Start all the services

### Start Supabase

```bash
supabase start
```

### Start Clickhouse + Minio

```bash
python3 -m venv env
source env/bin/activate
pip install tabulate requests minio
# This will start clickhouse locally
python3 clickhouse/ch_hcone.py --restart
python3 minio_hcone.py --restart
```

### Start Workers

```bash
# Install worker dependencies
cd worker
yarn
```

```bash
# Start OpenAI Proxy Worker
npx wrangler dev --local --var WORKER_TYPE:OPENAI_PROXY --port 8787 --test-scheduled
```

### Start Jawn (Serves Web)

I a new terminal tab, run the following:

```bash
cd valhalla/jawn
cp .env.example .env
yarn && yarn dev
```

### Start Web

I a new terminal tab, run the following:

```bash
cp .env.example web/.env
cd web
yarn
yarn dev:local -p 3000
```

## Step 3 - Setup your instance

You are done!

```bash
export OPENAI_API_KEY="sk-"
export HELICONE_API_KEY="sk-helicone-aizk36y-5yue2my-qmy5tza-n7x3aqa"
curl --request POST \
  --url http://127.0.0.1:8787/v1/chat/completions \
  --header "Authorization: Bearer $OPENAI_API_KEY" \
  --header "Helicone-Auth: Bearer $HELICONE_API_KEY" \
  --header 'Content-Type: application/json' \
  --header 'Accept-Encoding: identity' \
  --header 'helicone-property-hello: world' \
  --data '{
    "model": "gpt-4o-mini",
    "messages": [
        {
            "role": "system",
            "content": "generate a prompt for stable diffusion using this article.\n The prompt should instruct the image generation model to generate a image that would be suitable for the main image of the article.\n Therefore, the image should be relevant to the article, while being photorealistic, and safe for work.\n Only include the prompt, and do not include a introduction to the prompt. The entire prompt should be 90 characters or less. Make it as relevant to the image as possible, but do not include people or faces in the prompt."
        }
    ]
}'
```

You can login to Helicone at http://localhost:3000
with the following credentials:

User: `test@helicone.ai`
Password: `password`

Change the Org to `Organization for Test` and then you should be able to see your requests!

Please do not hesitate to reach out on discord if you have any questions.
