---
title: "Manual Self-Hosting"
sidebarTitle: "Manual"
description: "Deploy your own instance of Helicone. Follow our step-by-step guide to set up a local, self-hosted version of the LLM observability platform."
"twitter:title": "Self-Hosted Helicone Deployment - Open Source LLM Observability"
---

<Warning>
  **Deploy with Docker Compose!** We recommend deploying with [Docker
  Compose](https://docs.helicone.ai/getting-started/self-deploy-docker), as it
  works easily with just **one line**.
</Warning>

<i>
  Note we moved the old manual setup with [Supabase
  here](https://docs.helicone.ai/getting-started/self-host/manual-old)
</i>

At Helicone we believe that open-source software makes the world a better place. We are committed to open-source and we made a guide to make it easy for you to deploy your own instance of Helicone.

## Running locally

Running Helicone locally should be super easy. Just a few scripts.

Please clone our Repo and follow the instructions below.

```bash
git clone git@github.com:Helicone/helicone.git
cd helicone
```

## Step 1 - Install all the things

Requirements

- Docker

### Install Yarn

```bash
nvm install 20
nvm use 20
npm install -g yarn
```

## Step 2 - Start all the services

### Start Databases

```bash
python3 -m venv env
source env/bin/activate
pip install tabulate requests minio yarl

# Start Clickhouse (time-series database)
python3 clickhouse/ch_hcone.py --restart --no-password --url http://localhost:18123

# Start Minio (S3 compatible object storage)
python3 minio_hcone.py --restart

# Start Postgres
docker run -d --name helicone-postgres-flyway-test -e POSTGRES_DB=helicone_test -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=testpassword -p 54388:5432 -v postgres_flyway_data:/var/lib/postgresql/data postgres:17.4
flyway migrate -configFiles=supabase/flyway.conf
```

### Start mailhog server (local email testing)

```bash
docker run -p 1025:1025 -p 8025:8025 mailhog/mailhog
```

### Start Jawn (Backend + Main Proxy)

In a new terminal tab, run the following:

```bash
nvm use 20
cd valhalla/jawn
cp .env.example .env
yarn && yarn dev
```

### Start Web

In a new terminal tab, run the following:

```bash
nvm use 20
cp .env.example web/.env
cd web
yarn
yarn dev:local -p 3000
```

## Step 3 - Setup your instance

You are done!

```bash
export OPENAI_API_KEY="sk-"
export HELICONE_API_KEY="sk-helicone-aizk36y-5yue2my-qmy5tza-n7x3aqa"
curl --request POST \
  --url http://localhost:8585/v1/gateway/oai/v1/chat/completions \
  --header "Authorization: Bearer $OPENAI_API_KEY" \
  --header "Helicone-Auth: Bearer $HELICONE_API_KEY" \
  --header "Content-Type: application/json" \
  --header "Accept-Encoding: identity" \
  --header "helicone-property-hello: world" \
  --data '{
    "model": "gpt-4o-mini",
    "messages": [
        {
            "role": "system",
            "content": "generate a prompt for stable diffusion using this article.\n The prompt should instruct the image generation model to generate a image that would be suitable for the main image of the article.\n Therefore, the image should be relevant to the article, while being photorealistic, and safe for work.\n Only include the prompt, and do not include a introduction to the prompt. The entire prompt should be 90 characters or less. Make it as relevant to the image as possible, but do not include people or faces in the prompt."
        }
    ]
}'
```

You can login to Helicone at http://localhost:3000
with the following credentials:

User: `test@helicone.ai`
Password: `password`

Change the Org to `Organization for Test` and then you should be able to see your requests!

Please do not hesitate to reach out on discord if you have any questions.
