---
title: "Docker Compose Self-Hosting"
sidebarTitle: "Docker Compose"
description: "Deploy Helicone using Docker Compose. Quick setup guide for running a containerized instance of the LLM observability platform on your local machine or server."
"twitter:title": "Docker Compose Deployment - Helicone OSS LLM Observability"
---

## Running via Docker Compose
### Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### Clone the Repository
```bash
git clone https://github.com/Helicone/helicone.git
cd helicone
```

### Copy all environment variables
Copy the `.env.example` file within the docker directory to `.env` and modify as needed.

### Running as Docker File
To run all services in a single Docker container, you can use the `helicone-all` image. This is useful for quick testing or development purposes.

1. Build the all-in-one image:

```bash
cd docker
docker build -t helicone-all -f docker/dockerfiles/dockerfile_all .
```

2. Run the container:

```bash
docker run -d --name helicone-all -p 3000:3000 -p 8585:8585 -p 5432:5432 -p 8123:8123 -p 9000:9000 helicone-all
```

### Running via Docker Compose
```bash
cd docker
./helicone-compose.sh helicone up # NOTE: the initial build will take a while ~5 minutes, but subsequent builds will be a lot faster
```

## Running Services

- Helicone Webpage (frontend): localhost:3000
- Jawn (backend): localhost:8585/v1/gateway/oai/v1/chat/completions
- Postgres (database): localhost:5432
- Clickhouse (analytics): localhost:8123
- Minio (object storage): localhost:9000

## Example to test the Jawn service
```bash
curl --location 'https://localhost:8585/jawn/v1/gateway/oai/v1/completions' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer {{OPENAI_API_KEY}}' \
--header 'Helicone-Auth: Bearer {{HELICONE_API_KEY}}' \
--data '{
    "model": "gpt-4o-mini",
    "prompt": "Count to 5",
    "stream": false
  }'
```
