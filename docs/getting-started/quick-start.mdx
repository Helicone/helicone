---
title: "Quickstart"
sidebarTitle: "Quickstart"
description: "Get your first LLM request logged with Helicone in under 2 minutes using the AI Gateway."
"twitter:title": "Quickstart - Helicone Open Source LLM Observability"
---

Use the OpenAI SDK to access 100+ LLM models with automatic logging and observability.

<Accordion title="Using a third-party SDK?">
  The AI Gateway is our **recommended integration**, you get automatic fallbacks, 100+ models through one SDK, and seamless model switching.
  
  However, we understand you might already be deeply integrated with a third-party SDK.
  
  We support [direct integrations](/integrations/overview) for OpenAI, Anthropic, Azure, and 20+ other providers. You'll still get full observability, just without the unified API benefits.
</Accordion>

## Quick Integration

Two steps to your first logged request:

<Steps>

  <Step title="Set up your keys">
  1. **Create an account**: [Sign up for free](https://helicone.ai/signup)
  2. **Helicone API Key**: Go to [API Keys](https://us.helicone.ai/settings/api-keys) and generate a new key
  3. **Provider Keys**: Add your LLM API keys (OpenAI, Anthropic, etc.) at [Provider Keys](https://us.helicone.ai/providers)
    
    <Note>
      The Helicone key authenticates with our gateway. Provider keys let you access the actual LLMs.
    </Note>
  </Step>

  <Step title="Send your first request">

    Helicone's AI Gateway is an OpenAI-compatible, unified API with access to 100+ models, including OpenAI, Anthropic, Vertex, Groq, and more.

    **Bring your own key:** Go to [Provider Keys](https://us.helicone.ai/providers) to securely store API keys for the providers you want to use.

    <Tabs>
      <Tab title="TypeScript">
        ```typescript
        import { OpenAI } from "openai";

        const client = new OpenAI({
          baseURL: "https://ai-gateway.helicone.ai",
          apiKey: process.env.HELICONE_API_KEY,
        });

        const response = await client.chat.completions.create({
          model: "gpt-4o-mini", // Or 100+ other models
          messages: [{ role: "user", content: "Hello, world!" }],
        });
        ```
      </Tab>
      
      <Tab title="Python">
        ```python
        from openai import OpenAI

        client = OpenAI(
            base_url="https://ai-gateway.helicone.ai",
            api_key=os.getenv("HELICONE_API_KEY")
        )

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Hello, world!"}]
        )
        ```
      </Tab>

      <Tab title="cURL">
        ```bash
        curl https://ai-gateway.helicone.ai/chat/completions \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer $HELICONE_API_KEY" \
          -d '{
            "model": "gpt-4o-mini",
            "messages": [
              { "role": "user", "content": "Hello, world!" }
            ]
          }'
        ```
      </Tab>
    </Tabs>
    
    Once you run this code, you'll see your request appear in the [Requests](https://us.helicone.ai/requests) tab within seconds.
    
    <Note>
      See [all supported models](https://helicone.ai/models) or configure [provider routing](/gateway/provider-routing) for reliability.
    </Note>

  </Step>

</Steps>

## What's Next?

Now that data is flowing, explore what Helicone can do for you:
<Card
    title="Explore The Platform" 
    href="/getting-started/platform-overview"
    icon="rocket"
    horizontal
  >
    Understand how Helicone solves common LLM development challenges.
</Card>

## Questions?

Although we designed the docs to be as self-serving as possible, you are
welcome to join our [Discord](https://discord.com/invite/HwUbV3Q8qz) or
contact [help@helicone.ai](mailto:help@helicone.ai) with any questions or feedback
you have.