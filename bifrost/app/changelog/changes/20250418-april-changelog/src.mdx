Helicone is the first observability platform to support OpenAI's Realtime API, the 4.1 model family, and more.

### What's New? 
- Added cost support for gpt-4.1, gpt-4.1-mini, and gpt-4.1-nano, including detailed token pricing (prompt, completion, and cache read).
- Redesigned the [Request Drawer](http://helicone.ai/requests) for better viewing of requests, responses, and key metrics.
- Added support for gpt-4.1 model family in Prompts.
- Added support for streaming tool use with Anthropic models.
- Added stop sequences parameter support in the Parameters panel.
- Added Tools Editor with streaming support when creating new tools.
- Enabled evaluation runs for free tier users!
- Added ability to delete datasets with confirmation modals and user notifications.
- Added support for streaming tool use with Anthropic models.

### Improvements
- Improved overall page load and view performance.
- Improved dataset page loading and reliability for request/response fetching.
- Improved datetime filtering with a calendar and time picker input.
- Updated backend logging for smarter and more traceable logs.
- Updated cache strategy to reduce database load during property filtering.
- Updated the API cost calculator and model comparison pages with better design and more consistent pricing information.
- Added a "Response Format Editor" component to allow users to specify JSON schema formats for responses.

### Bug Fixes 
- Fixed streamed requests for Claude to see the entire response.
- Fixed loading prompts from requests with tool calls.
- Fixed table responsiveness issues in blogs.
- Fixed an issue with member invites for certain organization tiers.
- Fixed an issue where member invites didnâ€™t properly check organization tiers.
