The release of DeepSeek R1 model, a new class of language models designed to reason more effectively than their predecessors, has sparked significant interest in thinking models.

These models effectively internalize the <a href="https://www.helicone.ai/blog/chain-of-thought-prompting" target="_blank" rel="noopener">Chain-of-Thought</a> prompting process that was first popularized by Google researchers in a 2022 <a href="https://arxiv.org/pdf/2201.11903" target="_blank" rel="noopener">paper</a>. Unlike traditional LLMs‚Äîwhich require CoT to "reason"‚Äîthey handle reasoning natively, which often leads to better results.

![How to Prompt Thinking Models like DeepSeek R1 and OpenAI o1](/static/blog/prompt-thinking-models/cover.webp)

However, their reasoning ability also means you need to prompt them differently for the best results, and **most people get it wrong**.

Here's how to do it.

## Key Takeaways

Thinking models require a different approach compared to standard LLMs. Here‚Äôs a quick summary before diving into details:

### ‚úÖ DOs

- Use minimal prompting to let the model think independently.
- Encourage more reasoning for better performance at complex tasks by prompting for additional processing time.
  {/* - **Use structured prompts** when necessary for consistency. */}
- Use ensembling for highly complex tasks requiring high accuracy.

### ‚ùå DON‚ÄôTs

- Avoid <a href="https://docs.helicone.ai/guides/prompt-engineering/implement-few-shot-learning" target="_blank" rel="noopener">few-shot</a> and CoT prompting. Unlike traditional LLMs, thinking models perform worse when overloaded with examples or asked to "reason" step-by-step.
- Don‚Äôt use thinking models for structured outputs unless absolutely necessary. They perform worse with structured outputs than traditional models.
- Avoid overloading the model with unnecessary details. More context isn‚Äôt always better.

**Disclaimer:** The insights come from <a href="https://arxiv.org/pdf/2411.03590" target="_blank" rel="noopener">research carried out by OpenAI and Microsoft</a> and our own personal experience.

Let's get into the details!

## 1. Use Minimal Prompting

Thinking models work best when given **concise, direct, and structured** prompts.

Too much information can actually reduce accuracy. Unlike previous models where more context helped, thinking models already structure their reasoning internally. The best approach is to state the problem clearly and let the model figure out the steps.

Fewer instructions allow the model to **engage its reasoning process naturally**.

## 2. Encourage More Reasoning for Complex Tasks

More complex problems benefit from additional reasoning time.

Thinking models use **reasoning tokens**, which allow them to internally process a problem before outputting an answer. By **prompting the model to take its time**, you can improve the quality of the response. However, this also increases token usage, impacting cost.

Encouraging longer reasoning helps for **multi-step problems**, improving accuracy significantly.

<BottomLine
  title="Tip üí°"
  description='Say something like "Take your time and think carefully and deliberately about the problem."'
/>

## 3. Avoid Few-Shot and Chain-of-Thought Prompting

Traditional few-shot (where you give a bunch of examples) and CoT prompting strategies **reduce performance** for thinking models.

According to the paper, openAI's <a href="https://arxiv.org/pdf/2411.03590" target="_blank" rel="noopener">o1-preview model performed worse</a> when given few-shot examples. This contrasts with older models, where few-shot learning improved results. Thinking models are already designed to break down problems internally, so explicit step-by-step guidance can interfere with their reasoning.

**Zero-shot prompts work better than few-shot prompts.**

## 4. Use Thinking Models for Complex Multi-Step Tasks

Thinking models perform best on tasks that require **five or more steps**.

When solving problems with three to five steps, they offer only a **slight improvement** over standard models. For simpler tasks (fewer than three steps), performance **may actually degrade** compared to traditional LLMs, because they "overthink."

If a task is highly structured or simple, a regular LLM like GPT-4 may be a better choice.

<BottomLine
  title="Tip üí°"
  description="To check how many steps a problem requires, you can prompt the web version of a reasoning model to see how many reasoning steps it takes."
/>

## 5. Structure Prompts for Consistent Outputs

Thinking models struggle with structured outputs but can be guided to maintain consistency.

If you need a structured response (e.g., JSON, tables, fixed formats), structure your prompt carefully. However, if <a href="https://www.helicone.ai/blog/openai-structured-outputs" target="_blank" rel="noopener">structured output</a> is critical, you‚Äôre better off using a standard LLM instead of a thinking model.

Thinking models are **not optimized for structured output** but can approximate it with carefully designed prompts.

## 6. Use Ensembling for Highly Complex Tasks

For high-stakes or complex problems, <a href="https://www.promptlayer.com/glossary/prompt-ensembling" target="_blank" rel="noopener">ensembling</a> improves performance.

Ensembling involves **running multiple prompts** (either the same prompt multiple times or variations of the prompt) and aggregating the results. This approach increases accuracy but **raises costs** because multiple queries are required.

While ensembling boosts performance, it‚Äôs expensive and should only be used when high accuracy is critical.

<CallToAction
  title="Observe your Thinking Models with Helicone"
  description="If you'd like full visibility into what your models have been thinking about, you need Helicone. Get started in as little as 5 minutes."
  primaryButtonText="Get Started for Free"
  primaryButtonLink="https://helicone.ai/signup"
  secondaryButtonText="Contact Us"
  secondaryButtonLink="https://helicone.ai/contact"
/>

## Conclusion

Prompting thinking models like DeepSeek R1 and OpenAI o1 requires a different mindset and approach.

- Minimal, clear prompts work best, while forcing few-shot examples or step-by-step reasoning reduces effectiveness.
- When you must get a structured output, use standard LLMs instead.
- For even better responses, ensembling remains a powerful, though costly, technique.

With these guidelines, you can optimize your interactions with thinking models and get the best possible responses.

Enjoy!

### You might find these useful:

- **<a href="https://www.helicone.ai/blog/deepseek-v3" target="_blank" rel="noopener">DeepSeek-V3 Release: New Open-Source MoE Model</a>**
- **<a href="https://www.helicone.ai/blog/prompt-evaluation-frameworks" target="_blank" rel="noopener">Top Prompt Evaluation Frameworks in 2025: Helicone, OpenAI Eval, and More</a>**
- **<a href="https://www.helicone.ai/blog/tree-of-thought-prompting" target="_blank" rel="noopener">Tree-of-Thought Prompting: Key Techniques and Use Cases</a>**

<Questions />
