<<<<<<< HEAD
**Time to complete: ~30 minutes**

Your AI agent worked perfectly in testing, but now in production it's making bizarre recommendations and you have no idea why. Sound familiar? As AI agents grow increasingly complex, the black box problem is becoming the number one obstacle to reliable deployment.
=======
Complex AI agents are transforming how users interact with data and services, with increasing complexity and sophistication.

As AI agents become more common and more complex, it's essential to understand how they behave to deploy them reliably in production.

AI agent observability tools like Helicone have stepped up to meet this complex challenge, providing comprehensive visibility into every step of an agent's workflow, from the initial user query to the final response.
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)

In this first part of our two-part series on AI agent observability, we'll build a financial research assistant that demonstrates the key components of a modern AI agent. In part two, we'll explore how to effectively monitor it with Helicone's agentic AI observability features.

Let's get started!

## Prerequisites

Before we dive in, you'll need:

- **<a href="https://nodejs.org/" target="_blank" rel="noopener">Node.js 16+</a>** installed on your machine
- **<a href="https://platform.openai.com/api-keys" target="_blank" rel="noopener">OpenAI API</a>** key
- **<a href="https://www.alphavantage.co/support/#api-key" target="_blank" rel="noopener">Alpha Vantage API key</a>** (free tier available)

<<<<<<< HEAD
## Quick Start
=======
### Quick Start
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)

Want to skip ahead and try the code immediately? Clone the GitHub repository and run the code:

```bash
git clone https://github.com/Yusu-f/helicone-agent-tutorial.git
cd financial-assistant-example
npm install
```

Create a `.env` file with your API keys

```bash
<<<<<<< HEAD
OPENAI_API_KEY=your_openai_key_here
=======
OPENAI_API_KEY=your_openai_key_here 
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here
```

Run the assistant

```bash
npm start
```

This gives you the basic version of the financial assistant. 

<<<<<<< HEAD
In part 2, we'll show you how to add comprehensive monitoring to your AI agent with Helicone's Sessions feature.

## How We'll Build Our Financial Assistant
=======
In Part 2, we'll show you how to add comprehensive monitoring to your AI agent with Helicone's Sessions feature.

## What We're Building
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)

Our financial assistant does two things:

1. Fetches real-time price information and news for specific tickers
2. Uses RAG to answer questions about financial concepts

<<<<<<< HEAD
The agent intelligently determines which approach to take for each query - a pattern applicable to many domains beyond finance, including customer support, healthcare, and legal applications.
=======
The agent intelligently determines which approach to take for each query.
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)

## Key Components of Our AI Agent

### 1. LLM-Based Router

The heart of our agent is the router function that determines the intent of each query:

```javascript
async function routeQuery(query) {
  const response = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [
      {
        role: "system",
        content: `You are a financial query router that determines whether a query requires real-time stock data or a financial term definition.
        
        If the query is about a specific stock's price, performance, or news, categorize it as "STOCK_DATA" and extract the ticker symbol.
        If the query is about a financial term, concept, or definition, categorize it as "FINANCIAL_TERM".
        
        Respond with a JSON object with two fields:
        - routeTo: Either "STOCK_DATA" or "FINANCIAL_TERM"
        - ticker: The ticker symbol if routeTo is "STOCK_DATA" (omit this field otherwise)
        `
      },
      {
        role: "user",
        content: query
      }
    ],
    temperature: 0.1,
    response_format: { type: "json_object" }
  });
  
  ...
}
```

This router is responsible for determining whether we need to fetch stock data or search our knowledge base for financial terms.

### 2. RAG for Financial Concepts

For popular financial term queries, we use a vector store to retrieve relevant information:

```javascript
// Initialize vector store
async function initializeVectorStore() {
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: process.env.OPENAI_API_KEY,
  });
  
  const docs = financialTerms.map(
    (text) => new Document({ pageContent: text })
  );
  
  return MemoryVectorStore.fromDocuments(docs, embeddings);
}

// In the query handler
const results = await vectorStore.similaritySearch(query, 2);
```

<<<<<<< HEAD
This RAG implementation provides domain-specific knowledge to the agent. However, as we'll see later, without proper monitoring, detecting when the system operates outside its knowledge boundaries can be difficult.

=======
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)
### 3. External API Integration

For stock queries, such as real-time price information or news, we connect to the Alpha Vantage API:

```javascript
async function getStockData(ticker) {
  try {
    const url = `https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=${ticker}&apikey=${ALPHA_VANTAGE_API_KEY}`;
    const response = await axios.get(url);
    
    if (response.data['Global Quote'] && Object.keys(response.data['Global Quote']).length > 0) {
      const quote = response.data['Global Quote'];
      return {
        symbol: ticker.toUpperCase(),
        price: parseFloat(quote['05. price']),
        change: parseFloat(quote['09. change']),
        changePercent: quote['10. change percent'],
        volume: parseInt(quote['06. volume']),
        latestTradingDay: quote['07. latest trading day']
      };
    } else {
      return { error: `No data found for ticker ${ticker}` };
    }
  } catch (error) {
    console.error('Error fetching stock data:', error);
    return { error: `Failed to get stock data for ${ticker}` };
  }
}
```

<<<<<<< HEAD
By connecting to external APIs, we can access real-time data that the underlying LLM doesn't have access to.

=======
>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)
### 4. Multi-Step Processing

The main `processQuery` function orchestrates the entire workflow:

```javascript
async function processQuery(query, vectorStore) {
  // Use LLM to route the query
  console.log("Routing query...");
  const routingDecision = await routeQuery(query);
  console.log(`Query routed to: ${routingDecision.routeTo}${routingDecision.ticker ? `, Ticker: ${routingDecision.ticker}` : ''}`);
  
  // Handle based on routing decision
  if (routingDecision.routeTo === "STOCK_DATA" && routingDecision.ticker) {
    // Get stock data and news
    console.log(`Fetching data for ${routingDecision.ticker}...`);
    const stockData = await getStockData(routingDecision.ticker);
    const newsData = await getStockNews(routingDecision.ticker);
    
    // Generate response using OpenAI with stock data
    // ...
  } else {
    // This is a financial term query - use RAG
    console.log("Searching for financial term definitions...");
    
    // Get relevant documents from vector store
    const results = await vectorStore.similaritySearch(query, 2);
    
    // Generate response using OpenAI with RAG context
    // ...
  }
}
```

## Testing our Financial Assistant

Now, let's take our financial assistant for a spin!

Run the following command to start the assistant:

```bash
npm start
```

> Prompt: "What is tesla's stock price?"

![What is Tesla's stock price?](/static/blog/ai-agent-monitoring-tutorial/tesla-stock-price.webp)

> Prompt: "What is halal investing"

![What is halal investing?](/static/blog/ai-agent-monitoring-tutorial/halal-investing.webp)

<<<<<<< HEAD
It looks like our financial assistant successfully fetched Tesla's stock data... or did it? 

There's an issue with the second query. 

The term "halal investing" is not in our knowledge base, yet the agent confidently responded with a detailed answer. This is a perfect example of <a href="https://www.helicone.ai/blog/how-to-reduce-llm-hallucination" target="_blank" rel="noopener">hallucination</a> that would be nearly impossible to detect without proper monitoring.

## Debugging our Financial Assistant 

Looking at our implementation, there are several blind spots that could potentially cause issues:

- **Hallucinations**: Our agent provided information about halal investing despite not having this in its knowledge base - how do we detect this?
- **Cost Visibility**: How many tokens is each component of our agent consuming? Which queries are most expensive?
- **Latency Issues**: If the agent becomes slow, which step is causing the bottleneck?
- **Error Patterns**: Are certain types of queries consistently failing? Where in the pipeline do these failures occur?

In Part 2, we'll add Helicone to our financial assistant to gain comprehensive visibility into every step of the process. Here's a preview of what you can see:

![Using Helicone Sessions to Debug AI Agents](/static/blog/ai-agent-monitoring-tutorial/sessions-ai-agent.webp)

We'll monitor each step of the agent's workflow, resolve bugs, and gain insights into useful metrics like cost, latency, and error rates.

Stay tuned!

<CallToAction
  title="Observe Your AI Agents with Helicone ⚡️"
  description="Stop building AI in the dark. Get complete visibility into every step of your AI workflows, track costs down to the penny, and debug complex issues in minutes instead of days."
  primaryButtonText="Start Monitoring for Free"
  primaryButtonLink="https://helicone.ai/signup"
  secondaryButtonText="How Debugging Works"
  secondaryButtonLink="https://docs.helicone.ai/features/sessions"
/>

=======
Looks like our financial assistant is working as expected...or is it?

The second prompt's term "halal investing" is not in our knowledge base—so the agent is responding with information it shouldn't really "have"—in effect, **hallucinating**.

## Debugging our Financial Assistant 

To debug our financial assistant, we need to understand what's going on inside it—and we can achieve this with proper AI agent observability.

And Helicone is an excellent tool for that!

In Part 2, we'll add Helicone to our financial assistant to gain comprehensive visibility into every step of the process and resolve the issues in our current implementation.

We'll monitor each step of the agent's workflow, resolve the bugs, and gain insights into other useful metrics such as cost, latency, and error rates.

Stay tuned for Part 2!

<CallToAction
  title="Take Control of Your AI Agents with Helicone ⚡️"
  description="Stop building in the dark with AI. Get complete visibility into every step of your AI workflows, track costs down to the penny, and debug complex issues in minutes instead of days."
  primaryButtonText="Start Monitoring for Free"
  primaryButtonLink="https://helicone.ai/signup"
  secondaryButtonText="Explore Advanced Features"
  secondaryButtonLink="https://docs.helicone.ai/features/sessions"
/>

---

>>>>>>> 0c6dc4438 (add ai-agent-monitoring-tutorial-part-1)
### You might also like:

- **<a href="https://www.helicone.ai/blog/debugging-chatbots-and-ai-agents-with-sessions" target="_blank" rel="noopener">Debugging RAG Chatbots and AI Agents with Sessions</a>**
- **<a href="https://www.helicone.ai/blog/full-guide-to-improving-ai-agents" target="_blank" rel="noopener">The Full Developer's Guide to Building Effective AI Agents</a>**
- **<a href="https://www.helicone.ai/blog/agentic-rag-full-developer-guide" target="_blank" rel="noopener">Building Agentic RAG Systems: A Developer's Guide to Smarter Information Retrieval</a>**

<FAQ 
  items={[
    {
      question: "Why do AI agents need specialized observability tools?",
      answer: "AI agents have unique monitoring challenges including non-deterministic execution paths, multi-step LLM calls, complex branching logic, and dependencies on external systems. Unlike traditional applications with fixed flows, agents' decision trees vary with each request. Standard monitoring tools can't track these dynamic workflows or evaluate response quality across interconnected steps, which is why specialized tools like Helicone's session-based tracing are essential for AI agent observability."
    },
    {
      question: "What are the biggest blind spots when deploying AI agents to production?",
      answer: "The most dangerous blind spots include: undetected hallucinations in responses, hidden cost escalations from inefficient prompts, silent failures in multi-step reasoning chains, data leakage in RAG implementations, inconsistent performance across different user segments, and degrading accuracy over time as data or usage patterns change. Without proper observability, these issues can persist for weeks before being discovered, potentially causing significant business impact."
    },
    {
      question: "What metrics should I monitor for any AI agent?",
      answer: "Critical metrics for all AI agents include: end-to-end latency of complete workflows, token usage per step and total cost per request, step completion rates showing where agents get stuck, retrieval quality for RAG implementations, routing accuracy between different processing pathways, error rates for external API calls, and user satisfaction with responses. Tracking these metrics helps identify bottlenecks, optimize costs, and ensure reliable agent performance."
    },
    {
      question: "How do I implement observability across different AI agent frameworks?",
      answer: "Helicone offers flexible integration options for all major AI frameworks. For LangChain, CrewAI, and LlamaIndex, direct integrations are available. For custom agents or other frameworks, you can typically use either Helicone's proxy approach (changing just the base URL) or the SDK integration. The Sessions feature works consistently across most major frameworks to trace multi-step agent workflows regardless of your technology choices, giving you a unified view of all AI operations."
    }
  ]}
/>

<Questions />