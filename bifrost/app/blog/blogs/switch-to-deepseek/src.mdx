DeepSeek is the hot new kid on the block, and people can't get enough of it.

The recent release of DeepSeek R1â€”a [thinking model](link-to-other-article)â€”sent shockwaves through the AI industry. Investors panicked, fearing that the incredibly low training and inference costs of the DeepSeek models would undercut similar offerings from big tech.

![Switch to DeepSeek R1 Safely](/static/blog/switch-to-deepseek/cover.webp)

This caused big tech companies to lose hundreds of billions in market cap with NVIDIA experiencing <a href="https://www.datacenterdynamics.com/en/news/nvidia-records-largest-market-cap-loss-in-us-history-as-deepseek-wipes-out-600bn/#:~:text=Nvidia's%20share%20price%20fell%20some,off%20the%20GPU%20company's%20valuation." target="_blank" rel="noopener">the worst single-day market cap loss</a> in stock market history. Even Sam Altman, CEO of OpenAI, began to <a href="https://x.com/sama/status/1883185690508488934" target="_blank" rel="noopener">wax poetic on X</a>.

Given its open-source nature and how cheap it is, you're not alone in considering switching to DeepSeek, and we can help with that.

Using Helicone, you can test and transition to `DeepSeek V3` or `DeepSeek R1` safely without disrupting your users. This article will walk you through the process.

## DeepSeek R1 vs. the Competition

| Model                             | Input Cost (per 1M)         | Output Cost (per 1M)        | Max Context Tokens | Max Output Tokens | Performance                                            |
| --------------------------------- | --------------------------- | --------------------------- | ------------------ | ----------------- | ------------------------------------------------------ |
| **DeepSeek-R1**                   | $0.55                       | $2.19                       | 124,000            | 32,000            | Slightly outperforms ChatGPT-o1 Mini on benchmarks     |
| **ChatGPT-o1 Mini**               | $3 - $5                     | $12 - $15                   | 124,000            | 65,500            | Comparable to DeepSeek-R1, but more expensive          |
| **Grok (xAI)**                    | Similar to OpenAI           | Similar to OpenAI           | 128,000            | 4,096             | Slightly underperforms DeepSeek-R1 on benchmarks       |
| **Google Gemini**                 | More expensive than R1      | More expensive than R1      | Up to 2,000,000    | Up to 8,192       | Similar to DeepSeek R1                                 |
| **Nvidia Llama 3.1 Nemotron 70B** | Cheapest open-source option | Cheapest open-source option | 128,000            | 4,000             | Similar performance to DeepSeek R1, but less efficient |

## Prerequisites

- Have a Helicone account. Sign up for free <a href="https://us.helicone.ai/signup" target="_blank" rel="noopener">here</a>.
- Have at least 10 logs in your Helicone project.
- Set up your prompts in Helicone. Learn more <a href="https://docs.helicone.ai/features/prompts" target="_blank" rel="noopener">here</a>.

## Steps

We'll be using a simple Node.js project to manage `GPT-4o` prompts in Helicone (simulating a production setup) and compare them with `DeepSeek R1` and `V3`'s output in our Helicone dashboard.

<BottomLine
  title="Tip ðŸ’¡"
  description="If you already have a live project with Helicone set up, you can skip to the third step and go directly to comparing model outputs."
/>

### 1. Set up and log your first request with GPT-4o in Helicone

To begin logging prompts, Weâ€™ll set up a simple Node.js project to run **RapMaster**, a chatbot that provides cool rap lyrics.

Let's get into it!

#### Install dependencies

```sh
mkdir rapmaster && cd rapmaster
npm init -y
npm install openai dotenv @helicone/prompts
```

#### Create a `.env` file and add your API keys

```
OPENAI_API_KEY=your_openai_api_key
HELICONE_API_KEY=your_helicone_api_key
```

#### Log a prompt to Helicone

Create a file `index.js` and paste the following code:

```javascript
import { hprompt } from "@helicone/prompts";
import OpenAI from "openai";
import dotenv from "dotenv";

dotenv.config();

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function runRapMaster() {
  const chatCompletion = await openai.chat.completions.create(
    {
      model: "gpt-4o",
      max_tokens: 700,
      messages: [
        {
          role: "user",
          content:
            "You are a veteran rapper that can write entire rap verses on anything.",
        },
        {
          role: "assistant",
          content: "Great! What do you want me to rap about?",
        },
        {
          role: "user",
          // Add hprompt to any string, and nest any variable in additional brackets `{}`
          content: hprompt`Rap about ${{ thing }}`,
        },
      ],
    },
    // Add a Prompt Id Header
    {
      headers: {
        "Helicone-Prompt-Id": "RapMaster",
      },
    }
  );
  console.log(chatCompletion);
}

runRapMaster();
```

Run the script with:

```sh
node index.js
```

### 2. View Your Prompts in Helicone

Go to your Helicone dashboard and navigate to the `/prompts` page.

There you can easily manage and finetune your prompts. You should see your `GPT-4o` prompts logged there.

![Visualize prompt in Helicone UI](/static/blog/experiments/prompt-page.webp)

### Step 3. Start a New Experiment with DeepSeek

Use Heliconeâ€™s `Experiments` feature to test `DeepSeek R1` or `V3`'s output for the same prompts.

- Select the dataset you want to test.
- Choose a DeepSeek model.
- Compare the responses side by side.

![Create a new experiment](/static/blog/experiments/new-experiment.webp)

### Step 4. Analyze and Compare Outputs

You can now view and compare responses side by side. Helicone even lets you score the responses based on your criteria.

![Helicone experiment output](/static/blog/experiments/output.webp)

If DeepSeek meets your requirements, youâ€™re ready to switch!

<CallToAction
  title="Compare your model performance with Helicone"
  description="Helicone supports DeepSeek and most other models. Get started today"
  primaryButtonText="Get Started for Free"
  primaryButtonLink="https://helicone.ai/signup"
  secondaryButtonText="Contact Us"
  secondaryButtonLink="https://helicone.ai/contact"
/>

With this guide, you should now know how to use Helicone to:

- Benchmark and compare new models before production deployment.
- Test different prompt strategies and optimize results.
- Ensure a seamless transition between models with minimal downtime.

Try Helicone's experiments feature today and see if DeepSeek's offerings are the right fit for you.

<Questions />
