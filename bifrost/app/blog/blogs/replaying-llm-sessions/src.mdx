Experimenting with prompts in isolation, disconnected from real workflows, offers limited benefits. To **<span style={{color: '#0ea5e9'}}>truly understand how a prompt change impacts an entire session</span>**, you need to apply the changes directly and replay the session. This reveals how modifications affect subsequent interactions and the entire flow, providing insights that isolated testing can't offer.

In this guide, we'll **<span style={{color: '#0ea5e9'}}>walk through the process</span>** of setting up an initial session, querying Helicone for session data, and replaying the session with improvements. Along the way, we'll share insights on tailoring this approach to suit your unique use cases.

---

## Replaying LLM Sessions

Imagine running an AI agent that plans and executes tasks. Adjusting a single prompt might seem minor, but without **<span style={{color: '#0ea5e9'}}>replaying the session</span>**, you'd miss how that tweak alters the agent's decisions downstream.

By replaying sessions with modified prompts, models, and parameters, you can observe the **<span style={{color: '#0ea5e9'}}>real-world implications of your changes</span>**. You'll see how the AI's responses evolve, how it interacts differently, and whether those changes align with your goals. This approach provides a powerful feedback loop for more informed iterations.

### The Importance of Context

**<span style={{color: '#0ea5e9'}}>Testing prompts in isolation can be misleading</span>**. A prompt that works well on its own might not integrate smoothly with the broader system. Conversely, a prompt that seems less effective in isolation could enhance the overall workflow when applied in context.

By integrating prompt changes and replaying sessions, you capture the nuanced interplay between components. **<span style={{color: '#0ea5e9'}}>You understand not just if a prompt works, but why it works within the system</span>**. This leads to more effective optimizations and a deeper understanding of your AI's behavior.

---

## Overview of the Replay Process With Helicone

The process of replaying LLM sessions with Helicone involves three main steps:

1. **<span style={{color: '#0ea5e9'}}>Setting Up the Initial Session</span>**: Instrument your LLM calls to include Helicone session metadata so that they can be tracked and logged.
2. **<span style={{color: '#0ea5e9'}}>Querying Helicone for Session Data</span>**: Use Helicone's API to retrieve the logs of past sessions that you want to replay.
3. **<span style={{color: '#0ea5e9'}}>Replaying the Session with Modifications</span>**: Programmatically modify the retrieved session data as needed and send requests to the LLM to observe the effects.

Let's explore each of these steps in detail by following an example.

---

# Example: Debate Session

We'll walk through an example of a debate session between a user and an assistant. Between each argument, the assistant scores the user's argument from 1 to 10.

## Step 1: Setting Up the Initial Session

Before you can replay sessions, you need to log them properly in Helicone. By adding **<span style={{color: '#0ea5e9'}}>only 3 headers</span>** to your LLM API requests, you can tag and group them into sessions.

_Read more about how to implement Helicone sessions [here](https://docs.helicone.ai/features/sessions)._

### Instrumenting Your LLM Calls

1. **Set up the session headers**

   This session is for a debate on climate change.

   ```javascript
   const sessionId = randomUUID();
   const sessionName = "AI Debate";
   const sessionPath = "/debate/climate-change";
   ```

2. **Initialize the conversation with the assistant**

   ```javascript
   const conversation = [
     {
       role: "system",
       content:
         "You're a debating professional. You're engaging in a structured debate with the user. Each of you will present arguments for or against the topic. Keep responses concise and to the point.",
     },
     {
       role: "assistant",
       content: `Welcome to our debate! Today's topic is: "${topic}". I will argue in favor, and you will argue against. Please present your opening argument.`,
     },
   ];
   ```

3. **Loop through the debate turns**

   ```javascript
   while (true) {
     // Get user's argument
     const userArgument = await promptUser("Your argument: ");
     conversation.push({ role: "user", content: userArgument });

     // Score the user's argument
     await evaluateArgument(
       userArgument,
       sessionId,
       sessionName,
       sessionPath,
       "Your Argument"
     );

     // Assistant responds with a counter-argument
     const assistantResponse = await generateAssistantResponse(
       conversation,
       sessionId,
       sessionName,
       sessionPath
     );
     conversation.push(assistantResponse);

     // Score the assistant's argument
     await evaluateArgument(
       assistantResponse.content,
       sessionId,
       sessionName,
       sessionPath,
       "Assistant's Argument"
     );

     turn++;
   }
   ```

   **Note:** The functions `promptUser`, `evaluateArgument`, and `generateAssistantResponse` handle user input, argument evaluation, and generating assistant responses, respectively.

**After setting up and running your session through Helicone, you can view it in Helicone:**

_Go fullscreen for the best experience._

<video width="100%" controls>
  <source
    src="https://marketing-assets-helicone.s3.us-west-2.amazonaws.com/session_debate.mp4"
    type="video/mp4"
  />
  Your browser does not support the video tag.
</video>

## Step 2: Querying the Session Data from Helicone

Read more about Helicone's API [here](https://docs.helicone.ai/rest/request/post-v1requestquery).

```javascript
const response = await fetch("https://api.helicone.ai/v1/request/query", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    Authorization: `Bearer ${HELICONE_API_KEY}`,
  },
  body: JSON.stringify({
    filter: {
      properties: {
        "Helicone-Session-Id": {
          equals: SESSION_ID_TO_REPLAY,
        },
      },
    },
  }),
});
const data = await response.json();
```

## Step 3: Processing and Modifying the Session Data

Now that you have the session data, you'll need to process it.

1. **Parse and sort the requests**

   **<span style={{ color: "#0ea5e9" }}>Sorting session data can be complex</span>** because
   each use case is unique and may require custom logic. For our debate session example,
   we simply sort the requests by their `created_at` timestamp.

   ```javascript
   const requests = data.data.map((request) => ({
     created_at: request.request_created_at,
     session: request.request_properties["Helicone-Session-Id"],
     signed_body_url: request.signed_body_url,
     path: request.request_properties["Helicone-Session-Path"],
     prompt_id: request.request_properties["Helicone-Prompt-Id"],
     body: request.body,
   }));
   requests.sort((a, b) => new Date(a.created_at) - new Date(b.created_at));
   ```

2. **Modify the request bodies as needed**

   For example, we can adjust the system prompts to change the assistants argument or argument evaluation response.

   ```javascript
   function modifyRequestBody(request) {
     if (request.prompt_id === "argument-evaluation") {
       const systemMessage = request.body.messages.find(
         (msg) => msg.role === "system"
       );
       if (systemMessage) {
         systemMessage.content += " Keep the feedback short and concise.";
       }
     } else if (request.prompt_id === "assistant-argument") {
       const systemMessage = request.body.messages.find(
         (msg) => msg.role === "system"
       );
       if (systemMessage) {
         systemMessage.content +=
           " Take the persona of a genius in this field when responding.";
       }
     }
     return request;
   }
   ```

3. **Replay the modified session**

   ```javascript
   // Create a new session for the replay
   const replaySessionId = randomUUID();
   for (const request of requests) {
     const modifiedRequest = modifyRequestBody(request);

     // Reuse session metadata from the original request
     await handleChatCompletion(modifiedRequest);
   }

   async function handleChatCompletion(request) {
     const { body, path, prompt_id } = request;

     // Send the modified request to the LLM
     const response = await fetch(
       "https://api.openai.com/v1/chat/completions",
       {
         method: "POST",
         headers: {
           "Content-Type": "application/json",
           Authorization: `Bearer ${OPENAI_API_KEY}`,
           // Reuse the session metadata for logging
           "Helicone-Session-Id": replaySessionId,
           "Helicone-Session-Name": sessionName,
           "Helicone-Session-Path": path,
           "Helicone-Prompt-Id": prompt_id,
         },
         body: JSON.stringify(body),
       }
     );

     const responseData = await response.json();
     console.log(`Response for ${path}:`, responseData);
   }
   ```

   **Note:** In the `handleChatCompletion` function, we send the modified request to the LLM. By reusing the same `session-name`, `session-path`, `prompt-id`, and `request path` from the original requests, we ensure that the replayed session is logged in Helicone under the same session metadata. This allows you to see the replayed requests in Helicone, grouped under the same session, making it easier to compare and analyze the effects of your modifications.

## After running the replay, you can view it in Helicone:

_Go fullscreen for the best experience._

<video width="100%" controls>
  <source
    src="https://marketing-assets-helicone.s3.us-west-2.amazonaws.com/session_debate_replay.mp4"
    type="video/mp4"
  />
  Your browser does not support the video tag.
</video>

With the replayed session now visible in Helicone, you can observe how the modifications impact the AI's responses throughout the session. This visualization shows how changes in prompts or configurations affect subsequent interactions.

To assess the impact of your changes quantitatively, use Helicone's [evaluation features](https://docs.helicone.ai/features/evaluation) to assign scores to both the original and replayed sessions. **<span style={{ color: "#0ea5e9" }}>Comparing these scores helps you understand the effects of your modifications</span>** and refine your prompts more effectively.

Additionally, leverage Helicone's [prompt versioning](https://docs.helicone.ai/features/prompt-versioning) to manage and compare different versions of your prompts. Retrieve specific versions via Helicone's [Prompt API](https://docs.helicone.ai/rest/prompt/post-v1prompt-query) and replay them for side-by-side comparison.

---

## Conclusion

By replaying and modifying LLM sessions with Helicone, you gain deeper insights into how changes affect the entire workflow. This method allows for more effective optimization and understanding of your AI's behavior in context.

You can view the full code and further details on [GitHub](#).

---

Feel free to experiment with this approach and tailor it to your specific needs. By integrating Helicone into your development workflow, you enhance your ability to fine-tune and optimize AI interactions in a meaningful way.
