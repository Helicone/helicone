{
  "llama-guard-4-12b": [
    {
      "name": "DeepInfra | meta-llama/llama-guard-4-12b",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.049999999999999996,
        "completion": 0.049999999999999996,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 163840,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-guard-4-12b",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 1024,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    }
  ],
  "llama-4-maverick": [
    {
      "name": "DeepInfra | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/base",
      "status": 0,
      "pricing": {
        "prompt": 0.15,
        "completion": 0.6,
        "image": 0.0006684,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Parasail | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Parasail",
      "tag": "parasail/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.15,
        "completion": 0.85,
        "image": 0.00070182,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": 1048576,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "frequency_penalty",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "top_k"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Novita",
      "tag": "novita/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.16999999999999998,
        "completion": 0.85,
        "image": 0.0006684,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": 1048576,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Lambda",
      "tag": "lambda/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.18,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": 1048576,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k"
      ]
    },
    {
      "name": "BaseTen | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "BaseTen",
      "tag": "baseten/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.19,
        "completion": 0.72,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1000000,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Friendli | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Friendli",
      "tag": "friendli",
      "status": -5,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8000,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Cerebras | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Cerebras",
      "tag": "cerebras",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "seed",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Fireworks",
      "tag": "fireworks",
      "status": 0,
      "pricing": {
        "prompt": 0.22,
        "completion": 0.88,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "GMICloud | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "GMICloud",
      "tag": "gmicloud/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.25,
        "completion": 0.7999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "seed"
      ]
    },
    {
      "name": "Together | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.27,
        "completion": 0.85,
        "image": 0.00090234,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Google | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "Google",
      "tag": "google-vertex",
      "status": 0,
      "pricing": {
        "prompt": 0.35,
        "completion": 1.15,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 524288,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "seed",
        "stop",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/turbo",
      "status": 0,
      "pricing": {
        "prompt": 0.5,
        "completion": 0.5,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "SambaNova | meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "SambaNova",
      "tag": "sambanova",
      "status": 0,
      "pricing": {
        "prompt": 0.63,
        "completion": 1.7999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 4096,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "stop"
      ]
    }
  ],
  "llama-4-scout": [
    {
      "name": "Lambda | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Lambda",
      "tag": "lambda/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.08,
        "completion": 0.3,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": 1048576,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.08,
        "completion": 0.3,
        "image": 0.0003342,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 327680,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "GMICloud | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "GMICloud",
      "tag": "gmicloud/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.08,
        "completion": 0.5,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "seed"
      ]
    },
    {
      "name": "Parasail | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Parasail",
      "tag": "parasail/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.09,
        "completion": 0.48,
        "image": 0.00046788,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 158000,
      "maxCompletionTokens": 158000,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "frequency_penalty",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "top_k"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Novita",
      "tag": "novita",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.5,
        "image": 0.0003342,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Friendli | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Friendli",
      "tag": "friendli",
      "status": -5,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8000,
      "supportedParameters": [
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": -2,
      "pricing": {
        "prompt": 0.11,
        "completion": 0.33999999999999997,
        "image": 0.00036762,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "BaseTen | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "BaseTen",
      "tag": "baseten/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.13,
        "completion": 0.5,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1000000,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Fireworks",
      "tag": "fireworks",
      "status": 0,
      "pricing": {
        "prompt": 0.15,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Together | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Together",
      "tag": "together",
      "status": 0,
      "pricing": {
        "prompt": 0.18,
        "completion": 0.59,
        "image": 0.00090234,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1048576,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Google | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Google",
      "tag": "google-vertex",
      "status": 0,
      "pricing": {
        "prompt": 0.25,
        "completion": 0.7,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 1310720,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "seed",
        "response_format",
        "stop",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Cerebras | meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "Cerebras",
      "tag": "cerebras",
      "status": 0,
      "pricing": {
        "prompt": 0.65,
        "completion": 0.85,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32000,
      "maxCompletionTokens": 32000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "seed",
        "logprobs",
        "top_logprobs"
      ]
    }
  ],
  "llama-guard-3-8b": [
    {
      "name": "Nebius | meta-llama/llama-guard-3-8b",
      "provider": "Nebius",
      "tag": "nebius",
      "status": 0,
      "pricing": {
        "prompt": 0.02,
        "completion": 0.06,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-guard-3-8b",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.055,
        "completion": 0.055,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Together | meta-llama/llama-guard-3-8b",
      "provider": "Together",
      "tag": "together",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-guard-3-8b",
      "provider": "Cloudflare",
      "tag": "cloudflare",
      "status": 0,
      "pricing": {
        "prompt": 0.48,
        "completion": 0.03,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 0,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    }
  ],
  "llama-3.3-70b-instruct:free": [
    {
      "name": "Venice | meta-llama/llama-3.3-70b-instruct:free",
      "provider": "Venice",
      "tag": "venice/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 65536,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.3-70b-instruct:free",
      "provider": "Together",
      "tag": "together/fp8",
      "status": -5,
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 2048,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    }
  ],
  "llama-3.3-70b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.3-70b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/turbo",
      "status": 0,
      "pricing": {
        "prompt": 0.038000000000000006,
        "completion": 0.12,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Crusoe | meta-llama/llama-3.3-70b-instruct",
      "provider": "Crusoe",
      "tag": "crusoe/int8",
      "status": 0,
      "pricing": {
        "prompt": 0.039,
        "completion": 0.12,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "logit_bias"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.3-70b-instruct",
      "provider": "Lambda",
      "tag": "lambda/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.12,
        "completion": 0.3,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "Phala | meta-llama/llama-3.3-70b-instruct",
      "provider": "Phala",
      "tag": "phala",
      "status": 0,
      "pricing": {
        "prompt": 0.12,
        "completion": 0.35,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-3.3-70b-instruct",
      "provider": "Novita",
      "tag": "novita/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.13,
        "completion": 0.39,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 120000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Nebius | meta-llama/llama-3.3-70b-instruct",
      "provider": "Nebius",
      "tag": "nebius/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.13,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Parasail | meta-llama/llama-3.3-70b-instruct",
      "provider": "Parasail",
      "tag": "parasail/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.15,
        "completion": 0.5,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "frequency_penalty",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "top_k"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-3.3-70b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/base",
      "status": 0,
      "pricing": {
        "prompt": 0.22999999999999998,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "GMICloud | meta-llama/llama-3.3-70b-instruct",
      "provider": "GMICloud",
      "tag": "gmicloud/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.25,
        "completion": 0.75,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "seed"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3.3-70b-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.29,
        "completion": 2.25,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 24000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.3-70b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.39999999999999997,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-3.3-70b-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.59,
        "completion": 0.7899999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": 32768,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "Friendli | meta-llama/llama-3.3-70b-instruct",
      "provider": "Friendli",
      "tag": "friendli",
      "status": 0,
      "pricing": {
        "prompt": 0.6,
        "completion": 0.6,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "SambaNova | meta-llama/llama-3.3-70b-instruct",
      "provider": "SambaNova",
      "tag": "sambanova/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.6,
        "completion": 1.2,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 3072,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "stop"
      ]
    },
    {
      "name": "Google | meta-llama/llama-3.3-70b-instruct",
      "provider": "Google",
      "tag": "google-vertex",
      "status": 0,
      "pricing": {
        "prompt": 0.72,
        "completion": 0.72,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 128000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "seed",
        "response_format",
        "stop",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Cerebras | meta-llama/llama-3.3-70b-instruct",
      "provider": "Cerebras",
      "tag": "cerebras/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.85,
        "completion": 1.2,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 32000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "seed",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.3-70b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.88,
        "completion": 0.88,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 2048,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-3.3-70b-instruct",
      "provider": "Fireworks",
      "tag": "fireworks/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.8999999999999999,
        "completion": 0.8999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    }
  ],
  "llama-3.2-3b-instruct:free": [
    {
      "name": "Venice | meta-llama/llama-3.2-3b-instruct:free",
      "provider": "Venice",
      "tag": "venice/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k"
      ]
    }
  ],
  "llama-3.2-3b-instruct": [
    {
      "name": "Nineteen | meta-llama/llama-3.2-3b-instruct",
      "provider": "Nineteen",
      "tag": "nineteen/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.003,
        "completion": 0.006,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 20000,
      "maxCompletionTokens": 20000,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-3.2-3b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.012,
        "completion": 0.024,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.2-3b-instruct",
      "provider": "Lambda",
      "tag": "lambda/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.015,
        "completion": 0.024999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "InferenceNet | meta-llama/llama-3.2-3b-instruct",
      "provider": "InferenceNet",
      "tag": "inference-net/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.02,
        "completion": 0.02,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "logit_bias",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-3.2-3b-instruct",
      "provider": "Novita",
      "tag": "novita/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.03,
        "completion": 0.049999999999999996,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": 32000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3.2-3b-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare",
      "status": 0,
      "pricing": {
        "prompt": 0.051,
        "completion": 0.33999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 128000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.2-3b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.06,
        "completion": 0.06,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.2-3b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.09999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    }
  ],
  "llama-3.2-11b-vision-instruct:free": [
    {
      "name": "Together | meta-llama/llama-3.2-11b-vision-instruct:free",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 2048,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    }
  ],
  "llama-3.2-11b-vision-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": -5,
      "pricing": {
        "prompt": 0.049,
        "completion": 0.049,
        "image": 0.00007948,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare",
      "status": 0,
      "pricing": {
        "prompt": 0.049,
        "completion": 0.6799999999999999,
        "image": 0.001281,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 128000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "Lambda",
      "tag": "lambda/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.049999999999999996,
        "completion": 0.049999999999999996,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "InferenceNet | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "InferenceNet",
      "tag": "inference-net/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.055,
        "completion": 0.055,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "logit_bias",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "Together",
      "tag": "together/turbo",
      "status": 0,
      "pricing": {
        "prompt": 0.18,
        "completion": 0.18,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.18,
        "completion": 0.18,
        "image": 0.001156,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    }
  ],
  "llama-3.2-90b-vision-instruct": [
    {
      "name": "Together | meta-llama/llama-3.2-90b-vision-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 1.2,
        "completion": 1.2,
        "image": 0.001734,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 2048,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-3.2-90b-vision-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.35,
        "completion": 0.39999999999999997,
        "image": 0.0005058,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    }
  ],
  "llama-3.2-1b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.2-1b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.005,
        "completion": 0.01,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "InferenceNet | meta-llama/llama-3.2-1b-instruct",
      "provider": "InferenceNet",
      "tag": "inference-net/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.01,
        "completion": 0.01,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "logit_bias",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3.2-1b-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare",
      "status": 0,
      "pricing": {
        "prompt": 0.027,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 60000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    }
  ],
  "llama-3.1-405b": [
    {
      "name": "Hyperbolic | meta-llama/llama-3.1-405b",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/fp8",
      "status": 0,
      "pricing": {
        "prompt": 2,
        "completion": 2,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.1-405b",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/bf16",
      "status": 0,
      "pricing": {
        "prompt": 4,
        "completion": 4,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": 32768,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    }
  ],
  "llama-3.1-405b-instruct:free": [
    {
      "name": "Venice | meta-llama/llama-3.1-405b-instruct:free",
      "provider": "Venice",
      "tag": "venice/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 65536,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k"
      ]
    }
  ],
  "llama-3.1-405b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.1-405b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.7999999999999999,
        "completion": 0.7999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32768,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.1-405b-instruct",
      "provider": "Lambda",
      "tag": "lambda/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.7999999999999999,
        "completion": 0.7999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "Nebius | meta-llama/llama-3.1-405b-instruct",
      "provider": "Nebius",
      "tag": "nebius/fp8",
      "status": 0,
      "pricing": {
        "prompt": 1,
        "completion": 3,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-3.1-405b-instruct",
      "provider": "Fireworks",
      "tag": "fireworks/fp8",
      "status": 0,
      "pricing": {
        "prompt": 3,
        "completion": 3,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.1-405b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 3.5,
        "completion": 3.5,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 130815,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.1-405b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/bf16",
      "status": 0,
      "pricing": {
        "prompt": 4,
        "completion": 4,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    }
  ],
  "llama-3.1-8b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.1-8b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.015,
        "completion": 0.02,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "InferenceNet | meta-llama/llama-3.1-8b-instruct",
      "provider": "InferenceNet",
      "tag": "inference-net/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.02,
        "completion": 0.03,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "logit_bias",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-3.1-8b-instruct",
      "provider": "Novita",
      "tag": "novita/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.02,
        "completion": 0.049999999999999996,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Nebius | meta-llama/llama-3.1-8b-instruct",
      "provider": "Nebius",
      "tag": "nebius/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.02,
        "completion": 0.06,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.1-8b-instruct",
      "provider": "Lambda",
      "tag": "lambda/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.024999999999999998,
        "completion": 0.04,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-3.1-8b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.03,
        "completion": 0.049999999999999996,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "structured_outputs",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3.1-8b-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.045,
        "completion": 0.384,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32000,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-3.1-8b-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.049999999999999996,
        "completion": 0.08,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.1-8b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.09999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Cerebras | meta-llama/llama-3.1-8b-instruct",
      "provider": "Cerebras",
      "tag": "cerebras/fp16",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.09999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 32000,
      "maxCompletionTokens": 32000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "seed",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "Friendli | meta-llama/llama-3.1-8b-instruct",
      "provider": "Friendli",
      "tag": "friendli",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.09999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 8000,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "SambaNova | meta-llama/llama-3.1-8b-instruct",
      "provider": "SambaNova",
      "tag": "sambanova/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 16384,
      "maxCompletionTokens": 4096,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "stop"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.1-8b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.18,
        "completion": 0.18,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-3.1-8b-instruct",
      "provider": "Fireworks",
      "tag": "fireworks",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    },
    {
      "name": "Avian | meta-llama/llama-3.1-8b-instruct",
      "provider": "Avian",
      "tag": "avian/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "seed",
        "response_format"
      ]
    }
  ],
  "llama-3.1-70b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3.1-70b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/turbo",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.28,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p"
      ]
    },
    {
      "name": "Lambda | meta-llama/llama-3.1-70b-instruct",
      "provider": "Lambda",
      "tag": "lambda/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.12,
        "completion": 0.3,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "repetition_penalty",
        "top_k",
        "response_format"
      ]
    },
    {
      "name": "Nebius | meta-llama/llama-3.1-70b-instruct",
      "provider": "Nebius",
      "tag": "nebius/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.13,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ]
    },
    {
      "name": "DeepInfra | meta-llama/llama-3.1-70b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/base",
      "status": 0,
      "pricing": {
        "prompt": 0.22999999999999998,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "response_format",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3.1-70b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.39999999999999997,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3.1-70b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.88,
        "completion": 0.88,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Phala | meta-llama/llama-3.1-70b-instruct",
      "provider": "Phala",
      "tag": "phala",
      "status": 0,
      "pricing": {
        "prompt": 0.8899999999999999,
        "completion": 0.8899999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Fireworks | meta-llama/llama-3.1-70b-instruct",
      "provider": "Fireworks",
      "tag": "fireworks",
      "status": 0,
      "pricing": {
        "prompt": 0.8999999999999999,
        "completion": 0.8999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format",
        "structured_outputs"
      ]
    }
  ],
  "llama-guard-2-8b": [
    {
      "name": "Together | meta-llama/llama-guard-2-8b",
      "provider": "Together",
      "tag": "together",
      "status": 0,
      "pricing": {
        "prompt": 0.19999999999999998,
        "completion": 0.19999999999999998,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    }
  ],
  "llama-3-70b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3-70b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.3,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Hyperbolic | meta-llama/llama-3-70b-instruct",
      "provider": "Hyperbolic",
      "tag": "hyperbolic",
      "status": 0,
      "pricing": {
        "prompt": 0.39999999999999997,
        "completion": 0.39999999999999997,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "seed",
        "logit_bias",
        "top_k",
        "min_p",
        "repetition_penalty"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-3-70b-instruct",
      "provider": "Novita",
      "tag": "novita",
      "status": 0,
      "pricing": {
        "prompt": 0.51,
        "completion": 0.74,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 8000,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-3-70b-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.59,
        "completion": 0.7899999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3-70b-instruct",
      "provider": "Together",
      "tag": "together/fp8",
      "status": 0,
      "pricing": {
        "prompt": 0.88,
        "completion": 0.88,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    }
  ],
  "llama-3-8b-instruct": [
    {
      "name": "DeepInfra | meta-llama/llama-3-8b-instruct",
      "provider": "DeepInfra",
      "tag": "deepinfra/bf16",
      "status": 0,
      "pricing": {
        "prompt": 0.03,
        "completion": 0.06,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 16384,
      "supportedParameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "top_k",
        "seed",
        "min_p",
        "response_format"
      ]
    },
    {
      "name": "Novita | meta-llama/llama-3-8b-instruct",
      "provider": "Novita",
      "tag": "novita",
      "status": 0,
      "pricing": {
        "prompt": 0.04,
        "completion": 0.04,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ]
    },
    {
      "name": "Groq | meta-llama/llama-3-8b-instruct",
      "provider": "Groq",
      "tag": "groq",
      "status": 0,
      "pricing": {
        "prompt": 0.049999999999999996,
        "completion": 0.08,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": 8192,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "logprobs",
        "top_logprobs",
        "logit_bias",
        "seed",
        "response_format"
      ]
    },
    {
      "name": "Together | meta-llama/llama-3-8b-instruct",
      "provider": "Together",
      "tag": "together/int4",
      "status": 0,
      "pricing": {
        "prompt": 0.09999999999999999,
        "completion": 0.09999999999999999,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p"
      ]
    },
    {
      "name": "Cloudflare | meta-llama/llama-3-8b-instruct",
      "provider": "Cloudflare",
      "tag": "cloudflare",
      "status": 0,
      "pricing": {
        "prompt": 0.28,
        "completion": 0.83,
        "cacheRead": null,
        "cacheWrite": null
      },
      "contextLength": 7968,
      "maxCompletionTokens": null,
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "top_k",
        "seed",
        "repetition_penalty",
        "frequency_penalty",
        "presence_penalty"
      ]
    }
  ]
}