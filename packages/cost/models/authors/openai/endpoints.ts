/**
 * OpenAI endpoint configurations
 */

import type { Endpoint } from "../../types";
import type { OpenAIModelName } from "./models";

/**
 * OpenAI endpoint IDs
 */
export type OpenAIEndpointId = `${OpenAIModelName}:openai`;

export const openaiEndpoints = {
  "o3-pro:openai": {
    modelId: "o3-pro",
    provider: "openai",
    providerModelId: "o3-pro-2025-06-10",
    pricing: {
      prompt: 20,
      completion: 80,
      image: 0.0153,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o4-mini-high:openai": {
    modelId: "o4-mini-high",
    provider: "openai",
    providerModelId: "o4-mini-high-2025-04-16",
    pricing: {
      prompt: 1.1,
      completion: 4.4,
      image: 0.0008415,
      cacheRead: 0.275,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o3:openai": {
    modelId: "o3",
    provider: "openai",
    providerModelId: "o3-2025-04-16",
    pricing: {
      prompt: 2,
      completion: 8,
      image: 0.00153,
      cacheRead: 0.5,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o4-mini:openai": {
    modelId: "o4-mini",
    provider: "openai",
    providerModelId: "o4-mini",
    pricing: {
      prompt: 1.1,
      completion: 4.4,
      image: 0.0008415,
      cacheRead: 0.275,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "gpt-4.1:openai": {
    modelId: "gpt-4.1",
    provider: "openai",
    providerModelId: "gpt-4.1",
    pricing: {
      prompt: 2,
      completion: 8,
      cacheRead: 0.5,
    },
    contextLength: 1047576,
    maxCompletionTokens: 32768,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4.1-mini:openai": {
    modelId: "gpt-4.1-mini",
    provider: "openai",
    providerModelId: "gpt-4.1-mini",
    pricing: {
      prompt: 0.4,
      completion: 1.6,
      cacheRead: 0.1,
    },
    contextLength: 1047576,
    maxCompletionTokens: 32768,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4.1-nano:openai": {
    modelId: "gpt-4.1-nano",
    provider: "openai",
    providerModelId: "gpt-4.1-nano",
    pricing: {
      prompt: 0.1,
      completion: 0.4,
      cacheRead: 0.025,
    },
    contextLength: 1047576,
    maxCompletionTokens: 32768,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "o1-pro:openai": {
    modelId: "o1-pro",
    provider: "openai",
    providerModelId: "o1-pro",
    pricing: {
      prompt: 150,
      completion: 600,
      image: 0.21675,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: ["seed", "max_tokens", "response_format"],
    ptbEnabled: true,
  },
  "gpt-4o-mini-search-preview:openai": {
    modelId: "gpt-4o-mini-search-preview",
    provider: "openai",
    providerModelId: "gpt-4o-mini-search-preview",
    pricing: {
      prompt: 0.15,
      completion: 0.6,
      image: 0.000217,
    },
    contextLength: 128000,
    maxCompletionTokens: 16384,
    supportedParameters: ["max_tokens", "response_format"],
    ptbEnabled: true,
  },
  "gpt-4o-search-preview:openai": {
    modelId: "gpt-4o-search-preview",
    provider: "openai",
    providerModelId: "gpt-4o-search-preview",
    pricing: {
      prompt: 2.5,
      completion: 10,
      image: 0.003613,
    },
    contextLength: 128000,
    maxCompletionTokens: 16384,
    supportedParameters: ["max_tokens", "response_format"],
    ptbEnabled: true,
  },
  "o3-mini-high:openai": {
    modelId: "o3-mini-high",
    provider: "openai",
    providerModelId: "o3-mini-high",
    pricing: {
      prompt: 1.1,
      completion: 4.4,
      cacheRead: 0.55,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o3-mini:openai": {
    modelId: "o3-mini",
    provider: "openai",
    providerModelId: "o3-mini",
    pricing: {
      prompt: 1.1,
      completion: 4.4,
      cacheRead: 0.55,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o1:openai": {
    modelId: "o1",
    provider: "openai",
    providerModelId: "o1",
    pricing: {
      prompt: 15,
      completion: 60,
      image: 0.021675,
      cacheRead: 7.5,
    },
    contextLength: 200000,
    maxCompletionTokens: 100000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
    ],
    ptbEnabled: true,
  },
  "o1-mini:openai": {
    modelId: "o1-mini",
    provider: "openai",
    providerModelId: "o1-mini",
    pricing: {
      prompt: 1.1,
      completion: 4.4,
      cacheRead: 0.55,
    },
    contextLength: 128000,
    maxCompletionTokens: 65536,
    supportedParameters: ["seed", "max_tokens"],
    ptbEnabled: true,
  },
  "chatgpt-4o-latest:openai": {
    modelId: "chatgpt-4o-latest",
    provider: "openai",
    providerModelId: "chatgpt-4o-latest",
    pricing: {
      prompt: 5,
      completion: 20,
      image: 0.007225,
      cacheRead: 2.5,
    },
    contextLength: 128000,
    maxCompletionTokens: 16384,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4o-mini:openai": {
    modelId: "gpt-4o-mini",
    provider: "openai",
    providerModelId: "gpt-4o-mini",
    pricing: {
      prompt: 0.15,
      completion: 0.6,
      image: 0.000217,
      cacheRead: 0.075,
    },
    contextLength: 128000,
    maxCompletionTokens: 16384,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4o:openai": {
    modelId: "gpt-4o",
    provider: "openai",
    providerModelId: "gpt-4o",
    pricing: {
      prompt: 2.5,
      completion: 10,
      image: 0.003613,
      cacheRead: 1.25,
    },
    contextLength: 128000,
    maxCompletionTokens: 16384,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4o:extended:openai": {
    modelId: "gpt-4o:extended",
    provider: "openai",
    providerModelId: "gpt-4o",
    pricing: {
      prompt: 2.5,
      completion: 10,
      image: 0.003613,
      cacheRead: 1.25,
    },
    contextLength: 128000,
    maxCompletionTokens: 64000,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
  "gpt-4:openai": {
    modelId: "gpt-4",
    provider: "openai",
    providerModelId: "gpt-4",
    pricing: {
      prompt: 30,
      completion: 60,
    },
    contextLength: 8191,
    maxCompletionTokens: 4096,
    supportedParameters: [
      "tools",
      "tool_choice",
      "seed",
      "max_tokens",
      "response_format",
      "temperature",
      "top_p",
      "stop",
      "frequency_penalty",
      "presence_penalty",
    ],
    ptbEnabled: true,
  },
} satisfies Record<OpenAIEndpointId, Endpoint>;
