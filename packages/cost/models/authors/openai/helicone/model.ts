import type { ModelConfig } from "../../../types";

export const models = {
  "gpt-5-pro": {
    name: "OpenAI: GPT-5 Pro",
    author: "openai",
    description: "Most capable GPT-5 model with extended thinking capabilities",
    contextLength: 128000,
    maxOutputTokens: 32768,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-5-codex": {
    name: "OpenAI: GPT-5 Codex",
    author: "openai",
    description: "Specialized model for code generation and analysis",
    contextLength: 128000,
    maxOutputTokens: 32768,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-5": {
    name: "OpenAI: GPT-5",
    author: "openai",
    description: "Next generation GPT model with improved reasoning",
    contextLength: 128000,
    maxOutputTokens: 32768,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-5-mini": {
    name: "OpenAI: GPT-5 Mini",
    author: "openai",
    description: "Efficient GPT-5 variant optimized for speed",
    contextLength: 128000,
    maxOutputTokens: 16384,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-5-nano": {
    name: "OpenAI: GPT-5 Nano",
    author: "openai",
    description: "Lightweight GPT-5 model for fast inference",
    contextLength: 128000,
    maxOutputTokens: 8192,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-5-chat-latest": {
    name: "OpenAI: GPT-5 Chat Latest",
    author: "openai",
    description: "Latest GPT-5 chat model with continuous updates",
    contextLength: 128000,
    maxOutputTokens: 32768,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-4.1": {
    name: "OpenAI: GPT-4.1",
    author: "openai",
    description: "Enhanced GPT-4 with improved capabilities",
    contextLength: 128000,
    maxOutputTokens: 16384,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-4.1-nano": {
    name: "OpenAI: GPT-4.1 Nano",
    author: "openai",
    description: "Compact GPT-4.1 for efficient processing",
    contextLength: 128000,
    maxOutputTokens: 8192,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-4.1-mini": {
    name: "OpenAI: GPT-4.1 Mini",
    author: "openai",
    description: "Smaller GPT-4.1 optimized for speed",
    contextLength: 128000,
    maxOutputTokens: 16384,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-4o": {
    name: "OpenAI: GPT-4o",
    author: "openai",
    description: "GPT-4 Omni with multimodal capabilities",
    contextLength: 128000,
    maxOutputTokens: 16384,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text", "image"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "gpt-4o-mini": {
    name: "OpenAI: GPT-4o Mini",
    author: "openai",
    description: "Efficient GPT-4o variant",
    contextLength: 128000,
    maxOutputTokens: 16384,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text", "image"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "o1": {
    name: "OpenAI: o1",
    author: "openai",
    description: "Reasoning model with extended thinking capabilities",
    contextLength: 200000,
    maxOutputTokens: 100000,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "o1-mini": {
    name: "OpenAI: o1-mini",
    author: "openai",
    description: "Efficient reasoning model",
    contextLength: 128000,
    maxOutputTokens: 65536,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "o3": {
    name: "OpenAI: o3",
    author: "openai",
    description: "Advanced reasoning model",
    contextLength: 200000,
    maxOutputTokens: 100000,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "o3-mini": {
    name: "OpenAI: o3-mini",
    author: "openai",
    description: "Efficient o3 reasoning model",
    contextLength: 128000,
    maxOutputTokens: 65536,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
  "o4-mini": {
    name: "OpenAI: o4-mini",
    author: "openai",
    description: "Next generation efficient reasoning model",
    contextLength: 128000,
    maxOutputTokens: 65536,
    created: "2025-01-01T00:00:00.000Z",
    modality: { inputs: ["text"], outputs: ["text"] },
    tokenizer: "GPT",
  },
} satisfies Record<string, ModelConfig>;

export type HeliconeOpenAIModelName = keyof typeof models;
