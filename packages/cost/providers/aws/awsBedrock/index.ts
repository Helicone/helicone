/**
 *
 * DO NOT EDIT THIS FILE UNLESS IT IS IN /costs
 */
import { ModelRow } from "../../../interfaces/Cost";

export const costs: ModelRow[] = [
  {
    model: {
      operator: "equals",
      value: "meta.llama3-8b-instruct-v1%3A0",
    },
    cost: {
      prompt_token: 0.00022,
      completion_token: 0.00072,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-3-5-sonnet",
    },
    cost: {
      prompt_token: 0.000003,
      prompt_cache_write_token: 0.000003 * 1.25,
      prompt_cache_read_token: 0.000003 * 0.1,
      completion_token: 0.000015,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-3-7-sonnet",
    },
    cost: {
      prompt_token: 0.000003,
      prompt_cache_write_token: 0.000003 * 1.25,
      prompt_cache_read_token: 0.000003 * 0.1,
      completion_token: 0.000015,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-sonnet-4",
    },
    cost: {
      prompt_token: 0.000003,
      completion_token: 0.000015,
      prompt_cache_write_token: 0.00000375,
      prompt_cache_read_token: 0.0000003,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-opus-4",
    },
    cost: {
      prompt_token: 0.000015,
      completion_token: 0.000075,
      prompt_cache_write_token: 0.00001875,
      prompt_cache_read_token: 0.0000015,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-opus-4-1",
    },
    cost: {
      prompt_token: 0.000015,
      completion_token: 0.000075,
      prompt_cache_write_token: 0.00001875,
      prompt_cache_read_token: 0.0000015,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-3-haiku",
    },
    cost: {
      prompt_token: 0.00000025,
      prompt_cache_write_token: 0.00000025 * 1.25,
      prompt_cache_read_token: 0.00000025 * 0.1,
      completion_token: 0.00000125,
    },
  },
  {
    model: {
      operator: "includes",
      value: "claude-3-5-haiku",
    },
    cost: {
      prompt_token: 0.0000008,
      prompt_cache_write_token: 0.0000008 * 1.25,
      prompt_cache_read_token: 0.0000008 * 0.1,
      completion_token: 0.000004,
    },
  },
];
