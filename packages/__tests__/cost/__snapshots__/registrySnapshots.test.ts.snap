// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Registry Snapshots endpoint configurations snapshot 1`] = `
{
  "alibaba/qwen": {
    "qwen3-32b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 40960,
      "modelId": "Qwen/Qwen3-32B",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "anthropic/claude-3.5-haiku": {
    "claude-3.5-haiku:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-haiku:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "claude-3.5-sonnet-v2:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-sonnet-v2:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-v2@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-3.7-sonnet": {
    "claude-3.7-sonnet:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet-20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.7-sonnet:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet@20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4": {
    "claude-opus-4:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4-1": {
    "claude-opus-4-1:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-1-20250805-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4-1:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1@20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-sonnet-4": {
    "claude-sonnet-4:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-sonnet-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": false,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-sonnet-4:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "deepseek/r1": {
    "deepseek-r1-distill-llama-70b:groq": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "google/gemini-2.5-flash": {
    "gemini-2.5-flash:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-flash-lite": {
    "gemini-2.5-flash-lite:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash-lite:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-pro": {
    "gemini-2.5-pro:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-pro:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemma": {
    "gemma2-9b-it:groq": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "google/gemma-2-9b",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "meta/llama": {
    "llama-3.1-8b-instant:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "llama-3.1-8b-instant",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32678,
      "modelId": "llama-3.3-70b-versatile",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-guard-4:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 1024,
      "modelId": "meta-llama/Llama-Guard-4-12B",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-22m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-22m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-86m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-86m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "moonshotai/kimi-k2": {
    "kimi-k2-0905:groq": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/kimi-k2-instruct-0905",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/kimi-k2-instruct",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4.1": {
    "gpt-4.1-mini:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4o": {
    "chatgpt-4o-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "chatgpt-4o-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-5": {
    "gpt-5-chat-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-5-chat-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o3": {
    "o3-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "o3-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "o3-pro:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-pro-2025-06-10",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "o3:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-2025-04-16",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o4": {
    "o4-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "o4-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "openai/oss": {
    "gpt-oss-120b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "xai/endpoints.ts": {
    "grok-3-mini:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "grok-3:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "grok-4-0709:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "grok-4-0709",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
}
`;

exports[`Registry Snapshots model coverage snapshot 1`] = `
{
  "alibaba/qwen": [
    "groq",
  ],
  "anthropic/claude-3.5-haiku": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "anthropic/claude-3.5-sonnet-v2": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "anthropic/claude-3.7-sonnet": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "anthropic/claude-opus-4": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "anthropic/claude-opus-4-1": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "anthropic/claude-sonnet-4": [
    "anthropic",
    "bedrock",
    "vertex",
  ],
  "deepseek/r1": [
    "groq",
  ],
  "google/gemini-2.5-flash": [
    "google-ai-studio",
    "vertex",
  ],
  "google/gemini-2.5-flash-lite": [
    "google-ai-studio",
    "vertex",
  ],
  "google/gemini-2.5-pro": [
    "google-ai-studio",
    "vertex",
  ],
  "google/gemma": [
    "groq",
  ],
  "meta/llama": [
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
  ],
  "moonshotai/kimi-k2": [
    "groq",
    "groq",
  ],
  "openai/gpt-4.1": [
    "azure",
    "azure",
    "azure",
    "openai",
    "openai",
    "openai",
  ],
  "openai/gpt-4o": [
    "azure",
    "azure",
    "openai",
    "openai",
    "openai",
  ],
  "openai/gpt-5": [
    "openai",
    "openai",
    "openai",
    "openai",
  ],
  "openai/o3": [
    "azure",
    "openai",
    "openai",
    "openai",
  ],
  "openai/o4": [
    "azure",
    "openai",
  ],
  "openai/oss": [
    "groq",
    "groq",
  ],
  "xai/endpoints.ts": [
    "xai",
    "xai",
    "xai",
    "xai",
  ],
}
`;

exports[`Registry Snapshots pricing snapshot 1`] = `
{
  "alibaba/qwen": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 2.9e-7,
        "output": 5.9e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
  },
  "anthropic/claude-3.5-haiku": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.7-sonnet": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-opus-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-opus-4-1": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-sonnet-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
  },
  "deepseek/r1": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 7.5e-7,
        "output": 9.9e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
  },
  "google/gemini-2.5-flash": {
    "google-ai-studio": [
      {
        "audio": 0.000001,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "image": 0.001238,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": 0.000001,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "image": 0.001238,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-flash-lite": {
    "google-ai-studio": [
      {
        "audio": 3e-7,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": 3e-7,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-pro": {
    "google-ai-studio": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "image": 0.00516,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "image": 0.00516,
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "image": 0.00516,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "image": 0.00516,
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
  },
  "google/gemma": {
    "groq": [
      {
        "image": 0,
        "input": 2e-7,
        "output": 2e-7,
        "threshold": 0,
      },
    ],
  },
  "meta/llama": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 1e-8,
        "output": 1e-8,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
  },
  "moonshotai/kimi-k2": {
    "groq": [
      {
        "audio": 0,
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "image": 0,
        "input": 0.000001,
        "output": 0.000003,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
  },
  "openai/gpt-4.1": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.3,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-4o": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 1.5e-7,
        "output": 6e-7,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.000005,
        "output": 0.00002,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-5": {
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
    ],
  },
  "openai/o3": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
  },
  "openai/o4": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
  },
  "openai/oss": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 1e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
  },
  "xai/endpoints.ts": {
    "xai": [
      {
        "audio": 0,
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "image": 0,
        "input": 3e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0.025,
      },
    ],
  },
}
`;

exports[`Registry Snapshots registry builds correctly 1`] = `
{
  "modelToProviders": [
    {
      "model": "chatgpt-4o-latest",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "claude-3.5-haiku",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "claude-3.5-sonnet-v2",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "claude-3.7-sonnet",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4-1",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "claude-sonnet-4",
      "providers": [
        "anthropic",
        "bedrock",
        "vertex",
      ],
    },
    {
      "model": "deepseek-r1-distill-llama-70b",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "gemini-2.5-flash",
      "providers": [
        "google-ai-studio",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-flash-lite",
      "providers": [
        "google-ai-studio",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-pro",
      "providers": [
        "google-ai-studio",
        "vertex",
      ],
    },
    {
      "model": "gemma2-9b-it",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "gpt-4.1",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "gpt-4.1-mini",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "gpt-4.1-nano",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "gpt-4o",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "gpt-4o-mini",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "gpt-5",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "gpt-5-chat-latest",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "gpt-5-mini",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "gpt-5-nano",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "gpt-oss-120b",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "gpt-oss-20b",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "grok-3",
      "providers": [
        "xai",
      ],
    },
    {
      "model": "grok-3-mini",
      "providers": [
        "xai",
      ],
    },
    {
      "model": "grok-4-0709",
      "providers": [
        "xai",
      ],
    },
    {
      "model": "grok-code-fast-1",
      "providers": [
        "xai",
      ],
    },
    {
      "model": "kimi-k2",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "kimi-k2-0905",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-3.1-8b-instant",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-3.3-70b-instruct",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-4-maverick",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-4-scout",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-guard-4",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-prompt-guard-2-22m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-prompt-guard-2-86m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "o3",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "o3-mini",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "o3-pro",
      "providers": [
        "openai",
      ],
    },
    {
      "model": "o4-mini",
      "providers": [
        "azure",
        "openai",
      ],
    },
    {
      "model": "qwen3-32b",
      "providers": [
        "groq",
      ],
    },
  ],
  "providerBreakdown": [
    {
      "modelCount": 6,
      "provider": "anthropic",
    },
    {
      "modelCount": 7,
      "provider": "azure",
    },
    {
      "modelCount": 6,
      "provider": "bedrock",
    },
    {
      "modelCount": 3,
      "provider": "google-ai-studio",
    },
    {
      "modelCount": 14,
      "provider": "groq",
    },
    {
      "modelCount": 14,
      "provider": "openai",
    },
    {
      "modelCount": 9,
      "provider": "vertex",
    },
    {
      "modelCount": 4,
      "provider": "xai",
    },
  ],
  "ptbEnabledModels": [
    "deepseek-r1-distill-llama-70b",
    "gemma2-9b-it",
    "gpt-5-nano",
    "kimi-k2",
    "kimi-k2-0905",
    "llama-3.1-8b-instant",
    "llama-3.3-70b-instruct",
    "llama-4-maverick",
    "llama-4-scout",
    "llama-guard-4",
    "llama-prompt-guard-2-22m",
    "llama-prompt-guard-2-86m",
    "qwen3-32b",
  ],
  "sampleEndpointIds": [
    "chatgpt-4o-latest:openai:*",
    "claude-3.5-haiku:anthropic:*",
    "claude-3.5-haiku:bedrock:us-east-1",
    "claude-3.5-haiku:vertex:global",
    "claude-3.5-sonnet-v2:anthropic:*",
  ],
  "totalEndpoints": 63,
  "totalModelProviderConfigs": 63,
  "totalModelsWithPtb": 13,
  "totalProviders": 8,
}
`;
