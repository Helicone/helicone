// Jest Snapshot v1, https://jestjs.io/docs/snapshot-testing

exports[`Registry Snapshots archived endpoints snapshot 1`] = `{}`;

exports[`Registry Snapshots endpoint configurations snapshot 1`] = `
{
  "alibaba/qwen2.5": {
    "qwen2.5-coder-7b-fast:nebius": {
      "context": 32000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "Qwen/Qwen2.5-Coder-7B-fast",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "nebius",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "alibaba/qwen3": {
    "qwen3-235b-a22b-thinking:deepinfra": {
      "context": 262000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-235b-a22b-thinking:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "qwen/qwen3-235b-a22b-thinking-2507",
      "parameters": [
        "frequency_penalty",
        "functions",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-30b-a3b:deepinfra": {
      "context": 32768,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "Qwen/Qwen3-30B-A3B",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-32b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 40960,
      "modelId": "Qwen/Qwen3-32B",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-32b:openrouter": {
      "context": 40960,
      "crossRegion": false,
      "maxTokens": 40960,
      "modelId": "qwen/qwen3-32b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-coder-30b-a3b-instruct:nebius": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "nebius",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-coder:canopywave": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "qwen/qwen3-coder",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "canopywave",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-coder:deepinfra": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-next-80b-a3b-instruct:deepinfra": {
      "context": 262000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-vl-235b-a22b-instruct:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "qwen/qwen3-vl-235b-a22b-instruct",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "anthropic/claude-3-haiku-20240307": {
    "claude-3-haiku-20240307:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "claude-3-haiku-20240307",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3-haiku-20240307:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "pa/cd-3-hk-20240307",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "anthropic/claude-3.5-haiku": {
    "claude-3.5-haiku:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-haiku:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/cd-3-5-hk-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-3.5-haiku",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "us-east5",
      ],
    },
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "claude-3.5-sonnet-v2:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-sonnet-v2:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/cd-3-5-st-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-3.5-sonnet",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-v2@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-3.7-sonnet": {
    "claude-3.7-sonnet:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet-20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.7-sonnet:deepinfra": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "anthropic/claude-3-7-sonnet-latest",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "pa/cd-3-7-st-20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-3.7-sonnet",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet@20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-4.5-haiku": {
    "claude-4.5-haiku:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-haiku-4-5-20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-haiku:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-4.5-haiku:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/claude-haiku-4-5-20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-haiku:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-haiku-4.5",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-haiku:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-haiku-4-5@20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "us-east5",
      ],
    },
  },
  "anthropic/claude-4.5-opus": {
    "claude-4.5-opus:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-opus-4-5-20251101",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-opus:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-opus-4-5-20251101-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-4.5-opus:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-opus-4.5",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-opus:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "claude-opus-4-5@20251101",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-4.5-sonnet": {
    "claude-4.5-sonnet:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-5-20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-sonnet:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-4.5-sonnet:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "pa/claude-sonnet-4-5-20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-sonnet:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-sonnet-4.5",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-4.5-sonnet:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-5@20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-haiku-4-5-20251001": {
    "claude-haiku-4-5-20251001:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-haiku-4-5-20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-haiku-4-5-20251001:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-haiku-4-5-20251001:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/claude-haiku-4-5-20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-haiku-4-5-20251001:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-haiku-4.5",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-haiku-4-5-20251001:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-haiku-4-5@20251001",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "us-east5",
      ],
    },
  },
  "anthropic/claude-opus-4": {
    "claude-opus-4:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "pa/cd-op-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "anthropic/claude-opus-4",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "claude-opus-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4-1": {
    "claude-opus-4-1:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-1-20250805-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4-1:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "pa/claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "anthropic/claude-opus-4.1",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1@20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4-1-20250805": {
    "claude-opus-4-1-20250805:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1-20250805:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-1-20250805-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4-1-20250805:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "pa/claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1-20250805:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "anthropic/claude-opus-4.1",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1-20250805:vertex": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1@20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-sonnet-4": {
    "claude-sonnet-4:anthropic": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:bedrock": {
      "context": 1000000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-sonnet-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-sonnet-4:helicone": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "pa/cd-st-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:openrouter": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-sonnet-4",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:vertex": {
      "context": 1000000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-sonnet-4-5-20250929": {
    "claude-sonnet-4-5-20250929:anthropic": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-5-20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4-5-20250929:bedrock": {
      "context": 1000000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-sonnet-4-5-20250929:helicone": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "pa/claude-sonnet-4-5-20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4-5-20250929:openrouter": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-sonnet-4.5",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4-5-20250929:vertex": {
      "context": 1000000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-5@20250929",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "baidu/ernie": {
    "ernie-4.5-21b-a3b-thinking:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "baidu/ernie-4.5-21B-A3B-Thinking",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "deepseek/deepseek-reasoner": {
    "deepseek-reasoner:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek-ai/DeepSeek-R1-0528",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-reasoner:deepseek": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "deepseek-reasoner",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "top_logprobs",
        "top_p",
      ],
      "provider": "deepseek",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-reasoner:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "deepseek/deepseek-r1",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-tng-r1t2-chimera:chutes": {
      "context": 130000,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "chutes",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "deepseek/deepseek-v3": {
    "deepseek-v3.1-terminus:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3.1-terminus:novita": {
      "context": 98304,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "deepseek/deepseek-v3.1-terminus",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3.2:novita": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek/deepseek-v3.2-exp",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek-ai/DeepSeek-V3.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3:deepseek": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "deepseek-chat",
      "parameters": [
        "frequency_penalty",
        "function_call",
        "functions",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "deepseek",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "deepseek/deepseek-chat-v3.1",
      "parameters": [
        "frequency_penalty",
        "function_call",
        "functions",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "deepseek/r1-distill": {
    "deepseek-r1-distill-llama-70b:chutes": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "parameters": [
        "max_tokens",
        "min_p",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "chutes",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-r1-distill-llama-70b:deepinfra": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-r1-distill-llama-70b:groq": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "deepseek-r1-distill-llama-70b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-r1-distill-llama-70b:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "deepseek/deepseek-r1-distill-llama-70b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "google/gemini-2.5-flash": {
    "gemini-2.5-flash:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "google/gemini-2.5-flash",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash:vertex": {
      "context": 1048576,
      "crossRegion": true,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-flash-lite": {
    "gemini-2.5-flash-lite:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash-lite:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "google/gemini-2.5-flash-lite",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash-lite:vertex": {
      "context": 1048576,
      "crossRegion": true,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-pro": {
    "gemini-2.5-pro:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-pro:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "google/gemini-2.5-pro",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-pro:vertex": {
      "context": 1048576,
      "crossRegion": true,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-3": {
    "gemini-3-pro-preview:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-3-pro-preview",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-3-pro-preview:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "google/gemini-3-pro-preview",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-3-pro-preview:vertex": {
      "context": 1048576,
      "crossRegion": true,
      "maxTokens": 65536,
      "modelId": "gemini-3-pro-preview",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-3-pro-image": {
    "gemini-3-pro-image-preview:google-ai-studio": {
      "context": 65536,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gemini-3-pro-image-preview",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-3-pro-image-preview:openrouter": {
      "context": 65536,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "google/gemini-3-pro-image-preview",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-3-pro-image-preview:vertex": {
      "context": 65536,
      "crossRegion": true,
      "maxTokens": 32768,
      "modelId": "gemini-3-pro-image-preview",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemma": {
    "gemma2-9b-it:chutes": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "unsloth/gemma-2-9b-it",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "chutes",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemma2-9b-it:openrouter": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "google/gemma-2-9b-it",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "google/gemma-3": {
    "gemma-3-12b-it:deepinfra": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "google/gemma-3-12b-it",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "meta/hermes": {
    "hermes-2-pro-llama-3-8b:novita": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "nousresearch/hermes-2-pro-llama-3-8b",
      "parameters": [
        "functions",
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "meta/llama": {
    "llama-3.1-8b-instant:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "llama-3.1-8b-instant",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instant:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/llama-3.1-8b-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instruct-turbo:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instruct-turbo:nebius": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-fast",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "nebius",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instruct:deepinfra": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instruct:novita": {
      "context": 16384,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/llama-3.1-8b-instruct",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:nebius": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "meta-llama/Llama-3.3-70B-Instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "nebius",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 120000,
      "modelId": "meta-llama/llama-3.3-70b-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/llama-3.3-70b-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-versatile:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32678,
      "modelId": "llama-3.3-70b-versatile",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:deepinfra": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:novita": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 1048576,
      "modelId": "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/llama-4-maverick",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:deepinfra": {
      "context": 10000000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "parameters": [
        "frequency_penalty",
        "functions",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "meta-llama/llama-4-scout-17b-16e-instruct",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 1048576,
      "modelId": "meta-llama/llama-4-scout",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-guard-4:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 1024,
      "modelId": "meta-llama/Llama-Guard-4-12B",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-guard-4:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "meta-llama/llama-guard-4-12b",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-22m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-22m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-86m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-86m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "mistral/mistral-large": {
    "mistral-large-2411:mistral": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "mistral-large-2411",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "mistral",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "mistral/mistral-nemo": {
    "mistral-nemo:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "mistralai/Mistral-Nemo-Instruct-2407",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "mistral/mistral-small": {
    "mistral-small:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "moonshotai/kimi-k2": {
    "kimi-k2-0711:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "moonshotai/kimi-k2-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0711:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "moonshotai/kimi-k2",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:baseten": {
      "context": 262000,
      "crossRegion": false,
      "maxTokens": 163800,
      "modelId": "moonshotai/Kimi-K2-Instruct-0905",
      "parameters": [
        "max_tokens",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "baseten",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:deepinfra": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/Kimi-K2-Instruct-0905",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:fireworks": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "accounts/fireworks/models/kimi-k2-instruct-0905",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "fireworks",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:groq": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/kimi-k2-instruct-0905",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:novita": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "moonshotai/kimi-k2-0905",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:openrouter": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "moonshotai/kimi-k2-0905",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-thinking:canopywave": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "moonshotai/kimi-k2-thinking",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "canopywave",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-thinking:deepinfra": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 8000,
      "modelId": "moonshotai/Kimi-K2-Thinking",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-thinking:fireworks": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "fireworks/kimi-k2-thinking",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "fireworks",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-thinking:novita": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "moonshotai/kimi-k2-thinking",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4.1": {
    "gpt-4.1-mini-2025-04-14:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini-2025-04-14",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini-2025-04-14:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini-2025-04-14",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini-2025-04-14:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1-mini-2025-04-14",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "pa/gt-4.1-m",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/gt-4.1-n",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "pa/gt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4o": {
    "chatgpt-4o-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "chatgpt-4o-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "chatgpt-4o-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/chatgpt-4o-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "pa/gt-4p-m",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "pa/gt-4p",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-5": {
    "gpt-5-chat-latest:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "pa/gpt-5-chat-latest",
      "parameters": [
        "max_completion_tokens",
        "stop",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-chat-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-5-chat-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-chat-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-5-chat",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-codex:helicone": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "pa/gpt-5-codex",
      "parameters": [
        "max_completion_tokens",
        "stop",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-codex:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-codex",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-codex:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5-codex",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:azure": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "pa/gpt-5-mini",
      "parameters": [
        "max_completion_tokens",
        "stop",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "pa/gpt-5-nano",
      "parameters": [
        "max_completion_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-nano",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5-nano",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-pro:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "pa/gpt-5-pro",
      "parameters": [
        "max_completion_tokens",
        "stop",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:azure": {
      "context": 272000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "pa/gpt-5",
      "parameters": [
        "max_completion_tokens",
        "stop",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-5.1": {
    "codex-mini-latest:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "codex-mini-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "codex-mini-latest:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/codex-mini-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-chat-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-5.1-chat-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-chat-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-5.1-chat-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-codex-mini:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5.1-codex-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-codex-mini:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5.1-codex-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-codex:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5.1-codex",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1-codex:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5.1-codex",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5.1",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.1:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5.1",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-5.2": {
    "gpt-5.2-chat-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-5.2-chat-latest",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.2-chat-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-5.2-chat-latest",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "verbosity",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.2-pro:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5.2-pro",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "tool_choice",
        "tools",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.2-pro:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5.2-pro",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "verbosity",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.2:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5.2",
      "parameters": [
        "logprobs",
        "max_completion_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5.2:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5.2",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
        "verbosity",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o1": {
    "o1-mini:helicone": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "pa/p1-m",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o1:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "pa/p1",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o3": {
    "o3-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-mini:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "pa/p3-m",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-mini:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-pro:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "pa/p3-pro",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-pro:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-pro-2025-06-10",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-pro:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3-pro",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "pa/p3",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-2025-04-16",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o4": {
    "o4-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o4-mini:helicone": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "pa/o4-mini",
      "parameters": [
        "max_tokens",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o4-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o4-mini:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/oss": {
    "gpt-oss-120b:baseten": {
      "context": 128072,
      "crossRegion": false,
      "maxTokens": 128072,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "max_tokens",
        "response_format",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "baseten",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-120b:cerebras": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 40000,
      "modelId": "gpt-oss-120b",
      "parameters": [
        "logprobs",
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "cerebras",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-120b:deepinfra": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-120b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-120b:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:novita": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:openrouter": {
      "context": 131000,
      "crossRegion": false,
      "maxTokens": 131000,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "perplexity/sonar": {
    "sonar-deep-research:perplexity": {
      "context": 127000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "sonar-deep-research",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "perplexity",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "sonar-pro:perplexity": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "sonar-pro",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "response_format",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "perplexity",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "sonar-reasoning-pro:perplexity": {
      "context": 127000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "sonar-reasoning-pro",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "perplexity",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "sonar-reasoning:perplexity": {
      "context": 127000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "sonar-reasoning",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "reasoning",
        "response_format",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "perplexity",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "sonar:perplexity": {
      "context": 127000,
      "crossRegion": false,
      "maxTokens": 4096,
      "modelId": "sonar",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "response_format",
        "stop",
        "temperature",
        "top_p",
      ],
      "provider": "perplexity",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "xai/endpoints.ts": {
    "grok-3-mini:helicone": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "pa/grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3-mini:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "x-ai/grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3-mini:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3:helicone": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "pa/grk-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "x-ai/grok-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-1-fast-non-reasoning:helicone": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "pa/grok-4-1-fast-non-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-1-fast-non-reasoning:xai": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "grok-4-1-fast-non-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-1-fast-reasoning:helicone": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "pa/grok-4-1-fast-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-1-fast-reasoning:xai": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "grok-4-1-fast-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-fast-non-reasoning:helicone": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "pa/grok-4-fast-non-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-fast-non-reasoning:xai": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "grok-4-fast-non-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-fast-reasoning:helicone": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "pa/grok-4-fast-reasoning",
      "parameters": [
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4-fast-reasoning:xai": {
      "context": 2000000,
      "crossRegion": false,
      "maxTokens": 2000000,
      "modelId": "grok-4-fast",
      "parameters": [
        "logprobs",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4:helicone": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "pa/grk-4",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4:openrouter": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "x-ai/grok-4",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "grok-4",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:helicone": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 10000,
      "modelId": "pa/grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "helicone",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:openrouter": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 10000,
      "modelId": "x-ai/grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 10000,
      "modelId": "grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "zai/glm-4": {
    "glm-4.6:canopywave": {
      "context": 204800,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "zai/glm-4.6",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "canopywave",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "glm-4.6:novita": {
      "context": 204800,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "zai-org/glm-4.6",
      "parameters": [
        "frequency_penalty",
        "functions",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "novita",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
}
`;

exports[`Registry Snapshots model coverage snapshot 1`] = `
{
  "alibaba/qwen2.5": [
    "nebius",
  ],
  "alibaba/qwen3": [
    "canopywave",
    "deepinfra",
    "deepinfra",
    "deepinfra",
    "deepinfra",
    "groq",
    "nebius",
    "novita",
    "novita",
    "openrouter",
  ],
  "anthropic/claude-3-haiku-20240307": [
    "anthropic",
    "helicone",
  ],
  "anthropic/claude-3.5-haiku": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-3.5-sonnet-v2": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-3.7-sonnet": [
    "anthropic",
    "bedrock",
    "deepinfra",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-4.5-haiku": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-4.5-opus": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-4.5-sonnet": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-haiku-4-5-20251001": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-opus-4": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-opus-4-1": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-opus-4-1-20250805": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-sonnet-4": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-sonnet-4-5-20250929": [
    "anthropic",
    "bedrock",
    "helicone",
    "openrouter",
    "vertex",
  ],
  "baidu/ernie": [
    "novita",
  ],
  "deepseek/deepseek-reasoner": [
    "chutes",
    "deepinfra",
    "deepseek",
    "openrouter",
  ],
  "deepseek/deepseek-v3": [
    "deepinfra",
    "deepinfra",
    "deepseek",
    "novita",
    "novita",
    "openrouter",
  ],
  "deepseek/r1-distill": [
    "chutes",
    "deepinfra",
    "groq",
    "openrouter",
  ],
  "google/gemini-2.5-flash": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-2.5-flash-lite": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-2.5-pro": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-3": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-3-pro-image": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemma": [
    "chutes",
    "openrouter",
  ],
  "google/gemma-3": [
    "deepinfra",
  ],
  "meta/hermes": [
    "novita",
  ],
  "meta/llama": [
    "deepinfra",
    "deepinfra",
    "deepinfra",
    "deepinfra",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "nebius",
    "nebius",
    "novita",
    "novita",
    "novita",
    "novita",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "mistral/mistral-large": [
    "mistral",
  ],
  "mistral/mistral-nemo": [
    "deepinfra",
  ],
  "mistral/mistral-small": [
    "deepinfra",
  ],
  "moonshotai/kimi-k2": [
    "baseten",
    "canopywave",
    "deepinfra",
    "deepinfra",
    "fireworks",
    "fireworks",
    "groq",
    "novita",
    "novita",
    "novita",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-4.1": [
    "azure",
    "azure",
    "azure",
    "azure",
    "helicone",
    "helicone",
    "helicone",
    "openai",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-4o": [
    "azure",
    "azure",
    "helicone",
    "helicone",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-5": [
    "azure",
    "azure",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "openai",
    "openai",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-5.1": [
    "openai",
    "openai",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-5.2": [
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/o1": [
    "helicone",
    "helicone",
  ],
  "openai/o3": [
    "azure",
    "helicone",
    "helicone",
    "helicone",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/o4": [
    "azure",
    "helicone",
    "openai",
    "openrouter",
  ],
  "openai/oss": [
    "baseten",
    "cerebras",
    "deepinfra",
    "groq",
    "groq",
    "novita",
    "openrouter",
    "openrouter",
  ],
  "perplexity/sonar": [
    "perplexity",
    "perplexity",
    "perplexity",
    "perplexity",
    "perplexity",
  ],
  "xai/endpoints.ts": [
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "helicone",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "xai",
    "xai",
    "xai",
    "xai",
    "xai",
    "xai",
    "xai",
    "xai",
  ],
  "zai/glm-4": [
    "canopywave",
    "novita",
  ],
}
`;

exports[`Registry Snapshots pricing snapshot 1`] = `
{
  "alibaba/qwen2.5": {
    "nebius": [
      {
        "input": 3e-8,
        "output": 9e-8,
        "threshold": 0,
      },
    ],
  },
  "alibaba/qwen3": {
    "canopywave": [
      {
        "input": 2.2e-7,
        "output": 9.5e-7,
        "threshold": 0,
      },
    ],
    "deepinfra": [
      {
        "input": 3e-7,
        "output": 0.0000029,
        "threshold": 0,
      },
    ],
    "groq": [
      {
        "input": 2.9e-7,
        "output": 5.9e-7,
        "threshold": 0,
      },
    ],
    "nebius": [
      {
        "input": 1e-7,
        "output": 3e-7,
        "threshold": 0,
      },
    ],
    "novita": [
      {
        "input": 3e-7,
        "output": 0.0000015,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 4.22e-7,
        "output": 8.44e-7,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3-haiku-20240307": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.12,
          "write1h": 2,
          "write5m": 1.2,
        },
        "input": 2.5e-7,
        "output": 0.00000125,
        "threshold": 0,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.12,
          "write1h": 2,
          "write5m": 1.2,
        },
        "input": 2.5e-7,
        "output": 0.00000125,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.5-haiku": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 8.44e-7,
        "output": 0.00000422,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.000003165,
        "output": 0.00001583,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-3.7-sonnet": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "deepinfra": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.0000033,
        "output": 0.0000165,
        "threshold": 0,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.000003165,
        "output": 0.00001583,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-4.5-haiku": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000105,
        "output": 0.00000527,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-4.5-opus": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000005,
        "output": 0.000025,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000005,
        "output": 0.000025,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.000005275,
        "output": 0.000026375,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000005,
        "output": 0.000025,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-4.5-sonnet": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000633,
        "output": 0.00002374,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
  },
  "anthropic/claude-haiku-4-5-20251001": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000105,
        "output": 0.00000527,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000001,
        "output": 0.000005,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-opus-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00001583,
        "output": 0.00007913,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-opus-4-1": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00001583,
        "output": 0.00007913,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-opus-4-1-20250805": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00001583,
        "output": 0.00007913,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "anthropic/claude-sonnet-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000633,
        "output": 0.00002374,
        "threshold": 0,
        "web_search": 0.01,
      },
      {
        "input": 0.00000633,
        "output": 0.0000237375,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
        "web_search": 0.01,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
  },
  "anthropic/claude-sonnet-4-5-20250929": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000633,
        "output": 0.00002374,
        "threshold": 0,
      },
      {
        "input": 0.00000633,
        "output": 0.0000237375,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
  },
  "baidu/ernie": {
    "novita": [
      {
        "input": 7e-8,
        "output": 2.8e-7,
        "threshold": 0,
      },
    ],
  },
  "deepseek/deepseek-reasoner": {
    "chutes": [
      {
        "input": 3e-7,
        "output": 0.0000012,
        "threshold": 0,
      },
    ],
    "deepinfra": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.8,
        },
        "input": 5e-7,
        "output": 0.00000215,
        "threshold": 0,
      },
    ],
    "deepseek": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.125,
        },
        "input": 5.6e-7,
        "output": 0.00000168,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000316,
        "output": 0.00000844,
        "threshold": 0,
      },
    ],
  },
  "deepseek/deepseek-v3": {
    "deepinfra": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.8,
        },
        "input": 2.7e-7,
        "output": 0.000001,
        "threshold": 0,
      },
    ],
    "deepseek": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.125,
        },
        "input": 5.6e-7,
        "output": 0.00000168,
        "threshold": 0,
      },
    ],
    "novita": [
      {
        "input": 2.7e-7,
        "output": 4.1e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000316,
        "output": 0.00000475,
        "threshold": 0,
      },
    ],
  },
  "deepseek/r1-distill": {
    "chutes": [
      {
        "input": 3e-8,
        "output": 1.3e-7,
        "threshold": 0,
      },
    ],
    "deepinfra": [
      {
        "input": 6e-7,
        "output": 0.0000012,
        "threshold": 0,
      },
    ],
    "groq": [
      {
        "input": 7.5e-7,
        "output": 9.9e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000211,
        "output": 0.00000211,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-flash": {
    "google-ai-studio": [
      {
        "audio": {
          "cachedInputMultiplier": 0.1,
          "input": 0.000001,
        },
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 3.2e-7,
        "output": 0.00000264,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": {
          "cachedInputMultiplier": 0.1,
          "input": 0.000001,
        },
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-flash-lite": {
    "google-ai-studio": [
      {
        "audio": {
          "cachedInputMultiplier": 0.0833333,
          "input": 3e-7,
        },
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 1.1e-7,
        "output": 4.2e-7,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": {
          "cachedInputMultiplier": 0.0833333,
          "input": 3e-7,
        },
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-pro": {
    "google-ai-studio": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000264,
        "output": 0.00001582,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
  },
  "google/gemini-3": {
    "google-ai-studio": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "cacheStoragePerHour": 0.0000045,
        "input": 0.000002,
        "output": 0.000012,
        "threshold": 0,
      },
      {
        "input": 0.000004,
        "output": 0.000018,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000211,
        "output": 0.00001266,
        "threshold": 0,
      },
      {
        "input": 0.00000422,
        "output": 0.00001899,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "cacheStoragePerHour": 0.0000045,
        "input": 0.000002,
        "output": 0.000012,
        "threshold": 0,
      },
      {
        "input": 0.000004,
        "output": 0.000018,
        "threshold": 200000,
      },
    ],
  },
  "google/gemini-3-pro-image": {
    "google-ai-studio": [
      {
        "input": 0.000002,
        "output": 0.000012,
        "threshold": 0,
      },
      {
        "input": 0.000004,
        "output": 0.000018,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000211,
        "output": 0.00001266,
        "threshold": 0,
      },
      {
        "input": 0.00000422,
        "output": 0.00001899,
        "threshold": 200000,
      },
    ],
    "vertex": [
      {
        "input": 0.000002,
        "output": 0.000012,
        "threshold": 0,
      },
      {
        "input": 0.000004,
        "output": 0.000018,
        "threshold": 200000,
      },
    ],
  },
  "google/gemma": {
    "chutes": [
      {
        "input": 1e-8,
        "output": 3e-8,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 2.1e-7,
        "threshold": 0,
      },
    ],
  },
  "google/gemma-3": {
    "deepinfra": [
      {
        "input": 5e-8,
        "output": 1e-7,
        "threshold": 0,
      },
    ],
  },
  "meta/hermes": {
    "novita": [
      {
        "input": 1.4e-7,
        "output": 1.4e-7,
        "threshold": 0,
      },
    ],
  },
  "meta/llama": {
    "deepinfra": [
      {
        "input": 3e-8,
        "output": 5e-8,
        "threshold": 0,
      },
    ],
    "groq": [
      {
        "input": 1e-8,
        "output": 1e-8,
        "threshold": 0,
      },
    ],
    "nebius": [
      {
        "input": 3e-8,
        "output": 9e-8,
        "threshold": 0,
      },
    ],
    "novita": [
      {
        "input": 1.3e-7,
        "output": 3.9e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 3.1e-7,
        "threshold": 0,
      },
    ],
  },
  "mistral/mistral-large": {
    "mistral": [
      {
        "input": 0.000002,
        "output": 0.000006,
        "threshold": 0,
      },
    ],
  },
  "mistral/mistral-nemo": {
    "deepinfra": [
      {
        "input": 0.00002,
        "output": 0.00004,
        "threshold": 0,
      },
    ],
  },
  "mistral/mistral-small": {
    "deepinfra": [
      {
        "input": 0.000075,
        "output": 0.0002,
        "threshold": 0,
      },
    ],
  },
  "moonshotai/kimi-k2": {
    "baseten": [
      {
        "input": 6e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "canopywave": [
      {
        "input": 4.8e-7,
        "output": 0.000002,
        "threshold": 0,
      },
    ],
    "deepinfra": [
      {
        "input": 5.5e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "fireworks": [
      {
        "input": 6e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "groq": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.000001,
        "output": 0.000003,
        "threshold": 0,
      },
    ],
    "novita": [
      {
        "input": 6e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000142,
        "output": 0.00000528,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-4.1": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.3,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 4e-7,
        "output": 0.0000016,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 1.1e-7,
        "output": 4.2e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/gpt-4o": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 1.5e-7,
        "output": 6e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 1.5e-7,
        "output": 6e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.000005,
        "output": 0.00002,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000528,
        "output": 0.00001582,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/gpt-5": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.104,
        },
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000132,
        "output": 0.00001055,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/gpt-5.1": {
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000015,
        "output": 0.000006,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000158,
        "output": 0.00000633,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/gpt-5.2": {
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.00000175,
        "output": 0.000014,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000185,
        "output": 0.00001477,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/o1": {
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/o3": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "input": 0.00002,
        "output": 0.00008,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.0000211,
        "output": 0.0000844,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/o4": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000116,
        "output": 0.00000464,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "openai/oss": {
    "baseten": [
      {
        "input": 1e-7,
        "output": 5e-7,
        "threshold": 0,
      },
    ],
    "cerebras": [
      {
        "input": 3.5e-7,
        "output": 7.5e-7,
        "threshold": 0,
      },
    ],
    "deepinfra": [
      {
        "input": 4e-8,
        "output": 1.6e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "groq": [
      {
        "input": 1e-7,
        "output": 5e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "novita": [
      {
        "input": 5e-8,
        "output": 2e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
    "openrouter": [
      {
        "input": 3.7e-7,
        "output": 7.9e-7,
        "threshold": 0,
        "web_search": 0.01,
      },
    ],
  },
  "perplexity/sonar": {
    "perplexity": [
      {
        "input": 0.000002,
        "output": 0.000008,
        "request": 0,
        "threshold": 0,
        "web_search": 0.005,
      },
    ],
  },
  "xai/endpoints.ts": {
    "helicone": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 3e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0.025,
      },
    ],
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 0.00000158,
        "threshold": 0,
      },
    ],
    "xai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 3e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0.025,
      },
    ],
  },
  "zai/glm-4": {
    "canopywave": [
      {
        "input": 4.5e-7,
        "output": 0.0000015,
        "threshold": 0,
      },
    ],
    "novita": [
      {
        "input": 6e-7,
        "output": 0.0000022,
        "threshold": 0,
      },
    ],
  },
}
`;

exports[`Registry Snapshots verify registry state 1`] = `
{
  "modelToProviders": [
    {
      "model": "chatgpt-4o-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "claude-3-haiku-20240307",
      "providers": [
        "anthropic",
        "helicone",
      ],
    },
    {
      "model": "claude-3.5-haiku",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-3.5-sonnet-v2",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-3.7-sonnet",
      "providers": [
        "anthropic",
        "bedrock",
        "deepinfra",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-4.5-haiku",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-4.5-opus",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-4.5-sonnet",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-haiku-4-5-20251001",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4-1",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4-1-20250805",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-sonnet-4",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-sonnet-4-5-20250929",
      "providers": [
        "anthropic",
        "bedrock",
        "helicone",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "codex-mini-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-r1-distill-llama-70b",
      "providers": [
        "chutes",
        "deepinfra",
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-reasoner",
      "providers": [
        "deepinfra",
        "deepseek",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-tng-r1t2-chimera",
      "providers": [
        "chutes",
      ],
    },
    {
      "model": "deepseek-v3",
      "providers": [
        "deepinfra",
        "deepseek",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-v3.1-terminus",
      "providers": [
        "deepinfra",
        "novita",
      ],
    },
    {
      "model": "deepseek-v3.2",
      "providers": [
        "novita",
      ],
    },
    {
      "model": "ernie-4.5-21b-a3b-thinking",
      "providers": [
        "novita",
      ],
    },
    {
      "model": "gemini-2.5-flash",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-flash-lite",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-pro",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-3-pro-image-preview",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-3-pro-preview",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemma-3-12b-it",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "gemma2-9b-it",
      "providers": [
        "chutes",
        "openrouter",
      ],
    },
    {
      "model": "glm-4.6",
      "providers": [
        "canopywave",
        "novita",
      ],
    },
    {
      "model": "gpt-4.1",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1-mini",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1-mini-2025-04-14",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1-nano",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4o",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4o-mini",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-chat-latest",
      "providers": [
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-codex",
      "providers": [
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-mini",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-nano",
      "providers": [
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-pro",
      "providers": [
        "helicone",
      ],
    },
    {
      "model": "gpt-5.1",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.1-chat-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.1-codex",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.1-codex-mini",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.2",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.2-chat-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5.2-pro",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-oss-120b",
      "providers": [
        "baseten",
        "cerebras",
        "deepinfra",
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "gpt-oss-20b",
      "providers": [
        "groq",
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "grok-3",
      "providers": [
        "helicone",
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-3-mini",
      "providers": [
        "helicone",
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-4",
      "providers": [
        "helicone",
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-4-1-fast-non-reasoning",
      "providers": [
        "helicone",
        "xai",
      ],
    },
    {
      "model": "grok-4-1-fast-reasoning",
      "providers": [
        "helicone",
        "xai",
      ],
    },
    {
      "model": "grok-4-fast-non-reasoning",
      "providers": [
        "helicone",
        "xai",
      ],
    },
    {
      "model": "grok-4-fast-reasoning",
      "providers": [
        "helicone",
        "xai",
      ],
    },
    {
      "model": "grok-code-fast-1",
      "providers": [
        "helicone",
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "hermes-2-pro-llama-3-8b",
      "providers": [
        "novita",
      ],
    },
    {
      "model": "kimi-k2-0711",
      "providers": [
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "kimi-k2-0905",
      "providers": [
        "baseten",
        "deepinfra",
        "fireworks",
        "groq",
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "kimi-k2-thinking",
      "providers": [
        "canopywave",
        "deepinfra",
        "fireworks",
        "novita",
      ],
    },
    {
      "model": "llama-3.1-8b-instant",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-3.1-8b-instruct",
      "providers": [
        "deepinfra",
        "novita",
      ],
    },
    {
      "model": "llama-3.1-8b-instruct-turbo",
      "providers": [
        "deepinfra",
        "nebius",
      ],
    },
    {
      "model": "llama-3.3-70b-instruct",
      "providers": [
        "nebius",
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "llama-3.3-70b-versatile",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-4-maverick",
      "providers": [
        "deepinfra",
        "groq",
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "llama-4-scout",
      "providers": [
        "deepinfra",
        "groq",
        "novita",
        "openrouter",
      ],
    },
    {
      "model": "llama-guard-4",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-prompt-guard-2-22m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-prompt-guard-2-86m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "mistral-large-2411",
      "providers": [
        "mistral",
      ],
    },
    {
      "model": "mistral-nemo",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "mistral-small",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "o1",
      "providers": [
        "helicone",
      ],
    },
    {
      "model": "o1-mini",
      "providers": [
        "helicone",
      ],
    },
    {
      "model": "o3",
      "providers": [
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o3-mini",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o3-pro",
      "providers": [
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o4-mini",
      "providers": [
        "azure",
        "helicone",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "qwen2.5-coder-7b-fast",
      "providers": [
        "nebius",
      ],
    },
    {
      "model": "qwen3-235b-a22b-thinking",
      "providers": [
        "deepinfra",
        "novita",
      ],
    },
    {
      "model": "qwen3-30b-a3b",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "qwen3-32b",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "qwen3-coder",
      "providers": [
        "canopywave",
        "deepinfra",
      ],
    },
    {
      "model": "qwen3-coder-30b-a3b-instruct",
      "providers": [
        "nebius",
      ],
    },
    {
      "model": "qwen3-next-80b-a3b-instruct",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "qwen3-vl-235b-a22b-instruct",
      "providers": [
        "novita",
      ],
    },
    {
      "model": "sonar",
      "providers": [
        "perplexity",
      ],
    },
    {
      "model": "sonar-deep-research",
      "providers": [
        "perplexity",
      ],
    },
    {
      "model": "sonar-pro",
      "providers": [
        "perplexity",
      ],
    },
    {
      "model": "sonar-reasoning",
      "providers": [
        "perplexity",
      ],
    },
    {
      "model": "sonar-reasoning-pro",
      "providers": [
        "perplexity",
      ],
    },
  ],
  "providerBreakdown": [
    {
      "modelCount": 13,
      "provider": "anthropic",
    },
    {
      "modelCount": 10,
      "provider": "azure",
    },
    {
      "modelCount": 2,
      "provider": "baseten",
    },
    {
      "modelCount": 12,
      "provider": "bedrock",
    },
    {
      "modelCount": 3,
      "provider": "canopywave",
    },
    {
      "modelCount": 1,
      "provider": "cerebras",
    },
    {
      "modelCount": 3,
      "provider": "chutes",
    },
    {
      "modelCount": 19,
      "provider": "deepinfra",
    },
    {
      "modelCount": 2,
      "provider": "deepseek",
    },
    {
      "modelCount": 2,
      "provider": "fireworks",
    },
    {
      "modelCount": 5,
      "provider": "google-ai-studio",
    },
    {
      "modelCount": 12,
      "provider": "groq",
    },
    {
      "modelCount": 37,
      "provider": "helicone",
    },
    {
      "modelCount": 1,
      "provider": "mistral",
    },
    {
      "modelCount": 4,
      "provider": "nebius",
    },
    {
      "modelCount": 15,
      "provider": "novita",
    },
    {
      "modelCount": 24,
      "provider": "openai",
    },
    {
      "modelCount": 59,
      "provider": "openrouter",
    },
    {
      "modelCount": 5,
      "provider": "perplexity",
    },
    {
      "modelCount": 17,
      "provider": "vertex",
    },
    {
      "modelCount": 8,
      "provider": "xai",
    },
  ],
  "ptbEnabledModels": [
    "chatgpt-4o-latest",
    "claude-3-haiku-20240307",
    "claude-3.5-haiku",
    "claude-3.5-sonnet-v2",
    "claude-3.7-sonnet",
    "claude-4.5-haiku",
    "claude-4.5-opus",
    "claude-4.5-sonnet",
    "claude-haiku-4-5-20251001",
    "claude-opus-4",
    "claude-opus-4-1",
    "claude-opus-4-1-20250805",
    "claude-sonnet-4",
    "claude-sonnet-4-5-20250929",
    "codex-mini-latest",
    "deepseek-r1-distill-llama-70b",
    "deepseek-reasoner",
    "deepseek-tng-r1t2-chimera",
    "deepseek-v3",
    "deepseek-v3.1-terminus",
    "deepseek-v3.2",
    "ernie-4.5-21b-a3b-thinking",
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.5-pro",
    "gemini-3-pro-image-preview",
    "gemini-3-pro-preview",
    "gemma-3-12b-it",
    "gemma2-9b-it",
    "glm-4.6",
    "gpt-4.1",
    "gpt-4.1-mini",
    "gpt-4.1-mini-2025-04-14",
    "gpt-4.1-nano",
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-5",
    "gpt-5-chat-latest",
    "gpt-5-codex",
    "gpt-5-mini",
    "gpt-5-nano",
    "gpt-5-pro",
    "gpt-5.1",
    "gpt-5.1-chat-latest",
    "gpt-5.1-codex",
    "gpt-5.1-codex-mini",
    "gpt-5.2",
    "gpt-5.2-chat-latest",
    "gpt-5.2-pro",
    "gpt-oss-120b",
    "gpt-oss-20b",
    "grok-3",
    "grok-3-mini",
    "grok-4",
    "grok-4-1-fast-non-reasoning",
    "grok-4-1-fast-reasoning",
    "grok-4-fast-non-reasoning",
    "grok-4-fast-reasoning",
    "grok-code-fast-1",
    "hermes-2-pro-llama-3-8b",
    "kimi-k2-0711",
    "kimi-k2-0905",
    "kimi-k2-thinking",
    "llama-3.1-8b-instant",
    "llama-3.1-8b-instruct",
    "llama-3.1-8b-instruct-turbo",
    "llama-3.3-70b-instruct",
    "llama-3.3-70b-versatile",
    "llama-4-maverick",
    "llama-4-scout",
    "llama-guard-4",
    "llama-prompt-guard-2-22m",
    "llama-prompt-guard-2-86m",
    "mistral-large-2411",
    "mistral-nemo",
    "mistral-small",
    "o1",
    "o1-mini",
    "o3",
    "o3-mini",
    "o3-pro",
    "o4-mini",
    "qwen2.5-coder-7b-fast",
    "qwen3-235b-a22b-thinking",
    "qwen3-30b-a3b",
    "qwen3-32b",
    "qwen3-coder",
    "qwen3-coder-30b-a3b-instruct",
    "qwen3-next-80b-a3b-instruct",
    "qwen3-vl-235b-a22b-instruct",
    "sonar",
    "sonar-deep-research",
    "sonar-pro",
    "sonar-reasoning",
    "sonar-reasoning-pro",
  ],
  "sampleArchivedKeys": [],
  "sampleEndpointIds": [
    "chatgpt-4o-latest:openai:*",
    "chatgpt-4o-latest:openrouter:*",
    "claude-3-haiku-20240307:anthropic:*",
    "claude-3-haiku-20240307:helicone:*",
    "claude-3.5-haiku:anthropic:*",
  ],
  "totalArchivedConfigs": 0,
  "totalEndpoints": 254,
  "totalModelProviderConfigs": 254,
  "totalModelsWithPtb": 95,
  "totalProviders": 21,
}
`;
