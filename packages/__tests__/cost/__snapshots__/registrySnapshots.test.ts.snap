// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Registry Snapshots endpoint configurations snapshot 1`] = `
{
  "alibaba/qwen": {
    "qwen3-30b-a3b:deepinfra": {
      "context": 32768,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "Qwen/Qwen3-30B-A3B",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-32b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 40960,
      "modelId": "Qwen/Qwen3-32B",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "qwen3-32b:openrouter": {
      "context": 40960,
      "crossRegion": false,
      "maxTokens": 40960,
      "modelId": "qwen/qwen3-32b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "anthropic/claude-3.5-haiku": {
    "claude-3.5-haiku:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-haiku:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-3.5-haiku",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-haiku:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-haiku@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "claude-3.5-sonnet-v2:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 8192,
      "modelId": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.5-sonnet-v2:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "anthropic/claude-3.5-sonnet",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.5-sonnet-v2:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "claude-3-5-sonnet-v2@20241022",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-3.7-sonnet": {
    "claude-3.7-sonnet:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet-20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-3.7-sonnet:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-3.7-sonnet",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-3.7-sonnet:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-3-7-sonnet@20250219",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4": {
    "claude-opus-4:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "anthropic/claude-opus-4",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-opus-4-1": {
    "claude-opus-4-1:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1-20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 32000,
      "modelId": "anthropic.claude-opus-4-1-20250805-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-opus-4-1:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "anthropic/claude-opus-4.1",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-opus-4-1:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 32000,
      "modelId": "claude-opus-4-1@20250805",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "anthropic/claude-sonnet-4": {
    "claude-sonnet-4:anthropic": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4-20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "anthropic",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:bedrock": {
      "context": 200000,
      "crossRegion": true,
      "maxTokens": 64000,
      "modelId": "anthropic.claude-sonnet-4-20250514-v1:0",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "bedrock",
      "ptbEnabled": true,
      "regions": [
        "us-east-1",
      ],
    },
    "claude-sonnet-4:openrouter": {
      "context": 1000000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "anthropic/claude-sonnet-4",
      "parameters": [
        "max_tokens",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "claude-sonnet-4:vertex": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "claude-sonnet-4@20250514",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
      ],
      "provider": "vertex",
      "ptbEnabled": true,
      "regions": [
        "global",
      ],
    },
  },
  "deepseek/deepseek-reasoner": {
    "deepseek-reasoner:deepseek": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 64000,
      "modelId": "deepseek-reasoner",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "top_logprobs",
        "top_p",
      ],
      "provider": "deepseek",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-reasoner:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "deepseek/deepseek-r1",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "deepseek/deepseek-v3": {
    "deepseek-v3:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "deepseek-ai/DeepSeek-V3.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3:deepseek": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "deepseek-chat",
      "parameters": [
        "frequency_penalty",
        "function_call",
        "functions",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "deepseek",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-v3:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "deepseek/deepseek-chat-v3.1",
      "parameters": [
        "frequency_penalty",
        "function_call",
        "functions",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "stream",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "deepseek/r1-distill": {
    "deepseek-r1-distill-llama-70b:groq": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "deepseek-r1-distill-llama-70b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "deepseek-r1-distill-llama-70b:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "deepseek/deepseek-r1-distill-llama-70b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "google/gemini-2.5-flash": {
    "gemini-2.5-flash:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "google/gemini-2.5-flash",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-flash-lite": {
    "gemini-2.5-flash-lite:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash-lite:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "google/gemini-2.5-flash-lite",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-flash-lite:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65535,
      "modelId": "gemini-2.5-flash-lite",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemini-2.5-pro": {
    "gemini-2.5-pro:google-ai-studio": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "google-ai-studio",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-pro:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "google/gemini-2.5-pro",
      "parameters": [
        "max_tokens",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemini-2.5-pro:vertex": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "gemini-2.5-pro",
      "parameters": [
        "include_reasoning",
        "max_tokens",
        "reasoning",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "vertex",
      "ptbEnabled": false,
      "regions": [
        "global",
      ],
    },
  },
  "google/gemma": {
    "gemma2-9b-it:groq": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "gemma2-9b-it",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gemma2-9b-it:openrouter": {
      "context": 8192,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "google/gemma-2-9b-it",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "meta/llama": {
    "llama-3.1-8b-instant:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "llama-3.1-8b-instant",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.1-8b-instant:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/llama-3.1-8b-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 32678,
      "modelId": "llama-3.3-70b-versatile",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-3.3-70b-instruct:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/llama-3.3-70b-instruct",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-maverick:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "meta-llama/llama-4-maverick",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 8192,
      "modelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-4-scout:openrouter": {
      "context": 1048576,
      "crossRegion": false,
      "maxTokens": 1048576,
      "modelId": "meta-llama/llama-4-scout",
      "parameters": [
        "max_tokens",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-guard-4:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 1024,
      "modelId": "meta-llama/Llama-Guard-4-12B",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-guard-4:openrouter": {
      "context": 163840,
      "crossRegion": false,
      "maxTokens": 163840,
      "modelId": "meta-llama/llama-guard-4-12b",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-22m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-22m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "llama-prompt-guard-2-86m:groq": {
      "context": 512,
      "crossRegion": false,
      "maxTokens": 2,
      "modelId": "meta-llama/llama-prompt-guard-2-86m",
      "parameters": [
        "max_tokens",
        "temperature",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "mistralai/mistral-nemo": {
    "mistral-nemo:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16400,
      "modelId": "mistralai/Mistral-Nemo-Instruct-2407",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "mistralai/mistral-small": {
    "mistral-small:deepinfra": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "top_k",
        "top_p",
      ],
      "provider": "deepinfra",
      "ptbEnabled": false,
      "regions": [
        "*",
      ],
    },
  },
  "moonshotai/kimi-k2": {
    "kimi-k2-0905:groq": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/kimi-k2-instruct-0905",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2-0905:openrouter": {
      "context": 262144,
      "crossRegion": false,
      "maxTokens": 262144,
      "modelId": "moonshotai/kimi-k2-0905",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "moonshotai/kimi-k2-instruct",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "kimi-k2:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "moonshotai/kimi-k2",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4.1": {
    "gpt-4.1-mini:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-mini:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1-nano:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1-nano",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:azure": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:openai": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4.1:openrouter": {
      "context": 1047576,
      "crossRegion": false,
      "maxTokens": 32768,
      "modelId": "openai/gpt-4.1",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-4o": {
    "chatgpt-4o-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "chatgpt-4o-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "chatgpt-4o-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/chatgpt-4o-latest",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o-mini:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-4o-mini",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:azure": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-4o:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-4o",
      "parameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/gpt-5": {
    "gpt-5-chat-latest:openai": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "gpt-5-chat-latest",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-chat-latest:openrouter": {
      "context": 128000,
      "crossRegion": false,
      "maxTokens": 16384,
      "modelId": "openai/gpt-5-chat",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-mini",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-mini:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5-mini",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5-nano",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5-nano:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5-nano",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:openai": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "gpt-5",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
        "verbosity",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-5:openrouter": {
      "context": 400000,
      "crossRegion": false,
      "maxTokens": 128000,
      "modelId": "openai/gpt-5",
      "parameters": [
        "frequency_penalty",
        "max_completion_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o3": {
    "o3-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-mini:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-pro:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-pro-2025-06-10",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3-pro:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3-pro",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o3-2025-04-16",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o3:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o3",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/o4": {
    "o4-mini:azure": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "azure",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o4-mini:openai": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "o4-mini:openrouter": {
      "context": 200000,
      "crossRegion": false,
      "maxTokens": 100000,
      "modelId": "openai/o4-mini",
      "parameters": [
        "max_completion_tokens",
        "response_format",
        "seed",
        "tool_choice",
        "tools",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "openai/oss": {
    "gpt-oss-120b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-120b:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "openai/gpt-oss-120b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:groq": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 65536,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "include_reasoning",
        "logit_bias",
        "logprobs",
        "max_completion_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "groq",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "gpt-oss-20b:openrouter": {
      "context": 131000,
      "crossRegion": false,
      "maxTokens": 131000,
      "modelId": "openai/gpt-oss-20b",
      "parameters": [
        "frequency_penalty",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
  "xai/endpoints.ts": {
    "grok-3-mini:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "x-ai/grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3-mini:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3-mini",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3:openrouter": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "x-ai/grok-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-3:xai": {
      "context": 131072,
      "crossRegion": false,
      "maxTokens": 131072,
      "modelId": "grok-3",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4:openrouter": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "x-ai/grok-4",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-4:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 256000,
      "modelId": "grok-4",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:openrouter": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 10000,
      "modelId": "x-ai/grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "openrouter",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
    "grok-code-fast-1:xai": {
      "context": 256000,
      "crossRegion": false,
      "maxTokens": 10000,
      "modelId": "grok-code-fast-1",
      "parameters": [
        "frequency_penalty",
        "logit_bias",
        "logprobs",
        "max_tokens",
        "presence_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_logprobs",
        "top_p",
      ],
      "provider": "xai",
      "ptbEnabled": true,
      "regions": [
        "*",
      ],
    },
  },
}
`;

exports[`Registry Snapshots model coverage snapshot 1`] = `
{
  "alibaba/qwen": [
    "deepinfra",
    "groq",
    "openrouter",
  ],
  "anthropic/claude-3.5-haiku": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-3.5-sonnet-v2": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-3.7-sonnet": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-opus-4": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-opus-4-1": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "anthropic/claude-sonnet-4": [
    "anthropic",
    "bedrock",
    "openrouter",
    "vertex",
  ],
  "deepseek/deepseek-reasoner": [
    "deepseek",
    "openrouter",
  ],
  "deepseek/deepseek-v3": [
    "deepinfra",
    "deepseek",
    "openrouter",
  ],
  "deepseek/r1-distill": [
    "groq",
    "openrouter",
  ],
  "google/gemini-2.5-flash": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-2.5-flash-lite": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemini-2.5-pro": [
    "google-ai-studio",
    "openrouter",
    "vertex",
  ],
  "google/gemma": [
    "groq",
    "openrouter",
  ],
  "meta/llama": [
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "groq",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "mistralai/mistral-nemo": [
    "deepinfra",
  ],
  "mistralai/mistral-small": [
    "deepinfra",
  ],
  "moonshotai/kimi-k2": [
    "groq",
    "groq",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-4.1": [
    "azure",
    "azure",
    "azure",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-4o": [
    "azure",
    "azure",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/gpt-5": [
    "openai",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/o3": [
    "azure",
    "openai",
    "openai",
    "openai",
    "openrouter",
    "openrouter",
    "openrouter",
  ],
  "openai/o4": [
    "azure",
    "openai",
    "openrouter",
  ],
  "openai/oss": [
    "groq",
    "groq",
    "openrouter",
    "openrouter",
  ],
  "xai/endpoints.ts": [
    "openrouter",
    "openrouter",
    "openrouter",
    "openrouter",
    "xai",
    "xai",
    "xai",
    "xai",
  ],
}
`;

exports[`Registry Snapshots pricing snapshot 1`] = `
{
  "alibaba/qwen": {
    "deepinfra": [
      {
        "input": 8e-8,
        "output": 2.9e-7,
        "threshold": 0,
      },
    ],
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 2.9e-7,
        "output": 5.9e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
    "openrouter": [
      {
        "input": 4.22e-7,
        "output": 8.44e-7,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.5-haiku": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 8.44e-7,
        "output": 0.00000422,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 8e-7,
        "output": 0.000004,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.5-sonnet-v2": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.000003165,
        "output": 0.00001583,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-3.7-sonnet": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.000003165,
        "output": 0.00001583,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-opus-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00001583,
        "output": 0.00007913,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-opus-4-1": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00001583,
        "output": 0.00007913,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000015,
        "output": 0.000075,
        "threshold": 0,
      },
    ],
  },
  "anthropic/claude-sonnet-4": {
    "anthropic": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write1h": 2,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "bedrock": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000633,
        "output": 0.00002374,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
          "write5m": 1.25,
        },
        "input": 0.000003,
        "output": 0.000015,
        "threshold": 0,
      },
      {
        "input": 0.000006,
        "output": 0.0000225,
        "threshold": 200000,
      },
    ],
  },
  "deepseek/deepseek-reasoner": {
    "deepseek": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.125,
        },
        "input": 5.6e-7,
        "output": 0.00000168,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000316,
        "output": 0.00000844,
        "threshold": 0,
      },
    ],
  },
  "deepseek/deepseek-v3": {
    "deepinfra": [
      {
        "input": 2.7e-7,
        "output": 0.000001,
        "threshold": 0,
      },
    ],
    "deepseek": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.125,
        },
        "input": 5.6e-7,
        "output": 0.00000168,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000316,
        "output": 0.00000475,
        "threshold": 0,
      },
    ],
  },
  "deepseek/r1-distill": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 7.5e-7,
        "output": 9.9e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000211,
        "output": 0.00000211,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-flash": {
    "google-ai-studio": [
      {
        "audio": 0.000001,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "image": 0.001238,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 3.2e-7,
        "output": 0.00000264,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": 0.000001,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "image": 0.001238,
        "input": 3e-7,
        "output": 0.0000025,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-flash-lite": {
    "google-ai-studio": [
      {
        "audio": 3e-7,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 1.1e-7,
        "output": 4.2e-7,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "audio": 3e-7,
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.000001,
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
  },
  "google/gemini-2.5-pro": {
    "google-ai-studio": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "image": 0.00516,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "image": 0.00516,
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000264,
        "output": 0.00001582,
        "threshold": 0,
      },
    ],
    "vertex": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
          "write5m": 1,
        },
        "cacheStoragePerHour": 0.0000045,
        "image": 0.00516,
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
      {
        "image": 0.00516,
        "input": 0.0000025,
        "output": 0.000015,
        "threshold": 200000,
      },
    ],
  },
  "google/gemma": {
    "groq": [
      {
        "image": 0,
        "input": 2e-7,
        "output": 2e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 2.1e-7,
        "threshold": 0,
      },
    ],
  },
  "meta/llama": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 1e-8,
        "output": 1e-8,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 3.1e-7,
        "threshold": 0,
      },
    ],
  },
  "mistralai/mistral-nemo": {
    "deepinfra": [
      {
        "input": 0.02,
        "output": 0.04,
        "threshold": 0,
      },
    ],
  },
  "mistralai/mistral-small": {
    "deepinfra": [
      {
        "input": 0.05,
        "output": 0.1,
        "threshold": 0,
      },
    ],
  },
  "moonshotai/kimi-k2": {
    "groq": [
      {
        "audio": 0,
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "image": 0,
        "input": 0.000001,
        "output": 0.000003,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000142,
        "output": 0.00000528,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-4.1": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.3,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 1e-7,
        "output": 4e-7,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 1.1e-7,
        "output": 4.2e-7,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-4o": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 1.5e-7,
        "output": 6e-7,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.000005,
        "output": 0.00002,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000528,
        "output": 0.00001582,
        "threshold": 0,
      },
    ],
  },
  "openai/gpt-5": {
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.1,
        },
        "input": 0.00000125,
        "output": 0.00001,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000132,
        "output": 0.00001055,
        "threshold": 0,
      },
    ],
  },
  "openai/o3": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.5,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.0000211,
        "output": 0.0000844,
        "threshold": 0,
      },
    ],
  },
  "openai/o4": {
    "azure": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openai": [
      {
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "input": 0.0000011,
        "output": 0.0000044,
        "threshold": 0,
      },
    ],
    "openrouter": [
      {
        "input": 0.00000116,
        "output": 0.00000464,
        "threshold": 0,
      },
    ],
  },
  "openai/oss": {
    "groq": [
      {
        "audio": 0,
        "image": 0,
        "input": 1e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0,
      },
    ],
    "openrouter": [
      {
        "input": 3.7e-7,
        "output": 7.9e-7,
        "threshold": 0,
      },
    ],
  },
  "xai/endpoints.ts": {
    "openrouter": [
      {
        "input": 2.1e-7,
        "output": 0.00000158,
        "threshold": 0,
      },
    ],
    "xai": [
      {
        "audio": 0,
        "cacheMultipliers": {
          "cachedInput": 0.25,
        },
        "image": 0,
        "input": 3e-7,
        "output": 5e-7,
        "request": 0,
        "threshold": 0,
        "web_search": 0.025,
      },
    ],
  },
}
`;

exports[`Registry Snapshots registry builds correctly 1`] = `
{
  "modelToProviders": [
    {
      "model": "chatgpt-4o-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "claude-3.5-haiku",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-3.5-sonnet-v2",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-3.7-sonnet",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-opus-4-1",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "claude-sonnet-4",
      "providers": [
        "anthropic",
        "bedrock",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "deepseek-r1-distill-llama-70b",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-reasoner",
      "providers": [
        "deepseek",
        "openrouter",
      ],
    },
    {
      "model": "deepseek-v3",
      "providers": [
        "deepinfra",
        "deepseek",
        "openrouter",
      ],
    },
    {
      "model": "gemini-2.5-flash",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-flash-lite",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemini-2.5-pro",
      "providers": [
        "google-ai-studio",
        "openrouter",
        "vertex",
      ],
    },
    {
      "model": "gemma2-9b-it",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1-mini",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4.1-nano",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4o",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-4o-mini",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-chat-latest",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-mini",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-5-nano",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "gpt-oss-120b",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "gpt-oss-20b",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "grok-3",
      "providers": [
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-3-mini",
      "providers": [
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-4",
      "providers": [
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "grok-code-fast-1",
      "providers": [
        "openrouter",
        "xai",
      ],
    },
    {
      "model": "kimi-k2",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "kimi-k2-0905",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-3.1-8b-instant",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-3.3-70b-instruct",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-4-maverick",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-4-scout",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-guard-4",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
    {
      "model": "llama-prompt-guard-2-22m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "llama-prompt-guard-2-86m",
      "providers": [
        "groq",
      ],
    },
    {
      "model": "mistral-nemo",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "mistral-small",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "o3",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o3-mini",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o3-pro",
      "providers": [
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "o4-mini",
      "providers": [
        "azure",
        "openai",
        "openrouter",
      ],
    },
    {
      "model": "qwen3-30b-a3b",
      "providers": [
        "deepinfra",
      ],
    },
    {
      "model": "qwen3-32b",
      "providers": [
        "groq",
        "openrouter",
      ],
    },
  ],
  "providerBreakdown": [
    {
      "modelCount": 6,
      "provider": "anthropic",
    },
    {
      "modelCount": 7,
      "provider": "azure",
    },
    {
      "modelCount": 6,
      "provider": "bedrock",
    },
    {
      "modelCount": 4,
      "provider": "deepinfra",
    },
    {
      "modelCount": 2,
      "provider": "deepseek",
    },
    {
      "modelCount": 3,
      "provider": "google-ai-studio",
    },
    {
      "modelCount": 14,
      "provider": "groq",
    },
    {
      "modelCount": 14,
      "provider": "openai",
    },
    {
      "modelCount": 41,
      "provider": "openrouter",
    },
    {
      "modelCount": 9,
      "provider": "vertex",
    },
    {
      "modelCount": 4,
      "provider": "xai",
    },
  ],
  "ptbEnabledModels": [
    "chatgpt-4o-latest",
    "claude-3.5-haiku",
    "claude-3.5-sonnet-v2",
    "claude-3.7-sonnet",
    "claude-opus-4",
    "claude-opus-4-1",
    "claude-sonnet-4",
    "deepseek-r1-distill-llama-70b",
    "deepseek-reasoner",
    "deepseek-v3",
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.5-pro",
    "gemma2-9b-it",
    "gpt-4.1",
    "gpt-4.1-mini",
    "gpt-4.1-nano",
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-5",
    "gpt-5-chat-latest",
    "gpt-5-mini",
    "gpt-5-nano",
    "gpt-oss-120b",
    "gpt-oss-20b",
    "grok-3",
    "grok-3-mini",
    "grok-4",
    "grok-code-fast-1",
    "kimi-k2",
    "kimi-k2-0905",
    "llama-3.1-8b-instant",
    "llama-3.3-70b-instruct",
    "llama-4-maverick",
    "llama-4-scout",
    "llama-guard-4",
    "llama-prompt-guard-2-22m",
    "llama-prompt-guard-2-86m",
    "o3",
    "o3-mini",
    "o3-pro",
    "o4-mini",
    "qwen3-30b-a3b",
    "qwen3-32b",
  ],
  "sampleEndpointIds": [
    "chatgpt-4o-latest:openai:*",
    "chatgpt-4o-latest:openrouter:*",
    "claude-3.5-haiku:anthropic:*",
    "claude-3.5-haiku:bedrock:us-east-1",
    "claude-3.5-haiku:openrouter:*",
  ],
  "totalEndpoints": 110,
  "totalModelProviderConfigs": 110,
  "totalModelsWithPtb": 44,
  "totalProviders": 11,
}
`;
