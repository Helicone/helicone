import { expect, test } from "@jest/globals";

import { clickhousePriceCalc } from "../../cost";
import { openAIProvider } from "../../cost/providers/openai";

test("check that there are no two models that are the same", () => {
  openAIProvider.costs.forEach((cost) => {
    const model = cost.model.value;
    const modelCount = openAIProvider.costs.filter(
      (c) => c.model.value === model
    ).length;
    expect(modelCount).toBe(1);
  });
});

/**
 * If this test is failing please run `yarn test -- -u` to update the snapshot
 */
test("cost calc snapshot test", () => {
  expect(clickhousePriceCalc("request_response_rmt")).toMatchInlineSnapshot(`
"
sum(
  CASE
  WHEN (request_response_rmt.provider = 'ANTHROPIC') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'claude-instant-1') THEN 1630 * request_response_rmt.prompt_tokens + 55100 * request_response_rmt.completion_tokens + 1630 * request_response_rmt.prompt_audio_tokens + 55100 * request_response_rmt.completion_audio_tokens + 1630 * request_response_rmt.prompt_cache_write_tokens + 1630 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-v1') THEN 8000 * request_response_rmt.prompt_tokens + 24000 * request_response_rmt.completion_tokens + 8000 * request_response_rmt.prompt_audio_tokens + 24000 * request_response_rmt.completion_audio_tokens + 8000 * request_response_rmt.prompt_cache_write_tokens + 8000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-2') THEN 8000 * request_response_rmt.prompt_tokens + 24000 * request_response_rmt.completion_tokens + 8000 * request_response_rmt.prompt_audio_tokens + 24000 * request_response_rmt.completion_audio_tokens + 8000 * request_response_rmt.prompt_cache_write_tokens + 8000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-instant-1.2') THEN 1630 * request_response_rmt.prompt_tokens + 5510 * request_response_rmt.completion_tokens + 1630 * request_response_rmt.prompt_audio_tokens + 5510 * request_response_rmt.completion_audio_tokens + 1630 * request_response_rmt.prompt_cache_write_tokens + 1630 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-2.0') THEN 11020 * request_response_rmt.prompt_tokens + 32680 * request_response_rmt.completion_tokens + 11020 * request_response_rmt.prompt_audio_tokens + 32680 * request_response_rmt.completion_audio_tokens + 11020 * request_response_rmt.prompt_cache_write_tokens + 11020 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-opus-20240229') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 18750 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-sonnet-20240229') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-5-sonnet-20240620') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-5-sonnet-20241022') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-7-sonnet-20250219') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-haiku-20240307') THEN 250 * request_response_rmt.prompt_tokens + 1250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1250 * request_response_rmt.completion_audio_tokens + 313 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-3-5-haiku-20241022') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 80 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-sonnet-4-20250514') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-opus-4-20250514') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 18750 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'claude-opus-4-1-20250805') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 18750 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'LLAMA') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'Llama-4-Maverick-17B-128E-Instruct-FP8') THEN 0
WHEN (request_response_rmt.model ILIKE 'Llama-4-Scout-17B-16E-Instruct-FP8') THEN 0
WHEN (request_response_rmt.model ILIKE 'Llama-3.3-70B-Instruct') THEN 0
WHEN (request_response_rmt.model ILIKE 'Llama-3.3-8B-Instruct') THEN 0
WHEN (request_response_rmt.model ILIKE 'Cerebras-Llama-4-Maverick-17B-128E-Instruct') THEN 0
WHEN (request_response_rmt.model ILIKE 'Cerebras-Llama-4-Scout-17B-16E-Instruct') THEN 0
WHEN (request_response_rmt.model ILIKE 'Groq-Llama-4-Maverick-17B-128E-Instruct') THEN 0
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'NVIDIA') THEN (
  CASE
  
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'AZURE') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-45-turbo') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt4-turbo-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-preview-1106') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-1106') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt35') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-0613') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-16k') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-vision') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-realtime%') THEN 5000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 40000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-mini-realtime%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'ada') THEN 400 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-ada-001') THEN 400 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'babbage') THEN 500 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'curie') THEN 2000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-curie-001') THEN 2000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'davinci') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-001') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-002') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-003') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0301') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-1106') THEN 1000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-0914') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0314') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0613') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0314') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0613') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0125-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-vision-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-05-13') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-2024-07-18') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0613') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-16k-0613') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0125') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-2024-04-09') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-0125-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-v2') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-small') THEN 20 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-large') THEN 130 * request_response_rmt.prompt_tokens + 130 * request_response_rmt.prompt_audio_tokens + 130 * request_response_rmt.prompt_cache_write_tokens + 130 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-vision-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-0613') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-08-06') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-11-20') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-2024-09-12') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini') THEN 3000 * request_response_rmt.prompt_tokens + 12000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 12000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-2024-09-12') THEN 3000 * request_response_rmt.prompt_tokens + 12000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 12000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-2024-12-17') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o1-pro%') THEN 150000 * request_response_rmt.prompt_tokens + 600000 * request_response_rmt.completion_tokens + 150000 * request_response_rmt.prompt_audio_tokens + 600000 * request_response_rmt.completion_audio_tokens + 150000 * request_response_rmt.prompt_cache_write_tokens + 150000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-2025-01-31') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-2025-04-16') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o3-pro%') THEN 20000 * request_response_rmt.prompt_tokens + 80000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-2025-04-14') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-2025-04-14') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-2025-04-14') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-realtime%') THEN 5000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 40000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-mini-realtime%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o4-mini%') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o4-mini-2025-04-16%') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%openai/gpt-4o-mini-search-preview%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-search-preview%') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'chatgpt-4o-latest') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-2025-08-07') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-2025-08-07') THEN 250 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-2025-08-07') THEN 50 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 5 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini') THEN 250 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano') THEN 50 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 5 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-chat-latest') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'ada-batch') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-ada-001-batch') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'babbage-batch') THEN 250 * request_response_rmt.prompt_tokens + 250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'curie-batch') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-curie-001-batch') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'davinci-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-001-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-002-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-003-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0301-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-1106-batch') THEN 500 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-0914-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0314-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0613-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0314-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0613-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0125-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-vision-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-05-13-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-2024-07-18-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0613-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-16k-0613-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0125-batch') THEN 250 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-2024-04-09-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-0125-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-v2-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-small-batch') THEN 10 * request_response_rmt.prompt_tokens + 10 * request_response_rmt.prompt_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-large-batch') THEN 65 * request_response_rmt.prompt_tokens + 65 * request_response_rmt.prompt_audio_tokens + 65 * request_response_rmt.prompt_cache_write_tokens + 65 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-vision-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-0613-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-08-06-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-11-20-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-2024-09-12-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-batch') THEN 1500 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-2024-09-12-batch') THEN 1500 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-2024-12-17-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-pro-batch') THEN 75000 * request_response_rmt.prompt_tokens + 300000 * request_response_rmt.completion_tokens + 75000 * request_response_rmt.prompt_audio_tokens + 300000 * request_response_rmt.completion_audio_tokens + 75000 * request_response_rmt.prompt_cache_write_tokens + 75000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-2025-01-31-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-2025-04-16-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-pro-batch') THEN 10000 * request_response_rmt.prompt_tokens + 40000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 40000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-2025-04-14-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-batch') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-2025-04-14-batch') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-batch') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-2025-04-14-batch') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-realtime-batch') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 40000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-realtime-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o4-mini-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o4-mini-2025-04-16-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini-search-preview-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-search-preview-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'chatgpt-4o-latest-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-2025-08-07-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-2025-08-07-batch') THEN 125 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-2025-08-07-batch') THEN 25 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-batch') THEN 125 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-batch') THEN 25 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-chat-latest-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'NEBIUS') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'black-forest-labs/flux-schnell') THEN 1300000
WHEN (request_response_rmt.model ILIKE 'black-forest-labs/flux-dev') THEN 7000000
WHEN (request_response_rmt.model ILIKE 'stability-ai/sdxl') THEN 3000000
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'X') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'grok-beta') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-vision-beta') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-2-1212') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-2-vision-1212') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-3') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-3-fast') THEN 3000 * request_response_rmt.prompt_tokens + 25000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 25000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-3-mini') THEN 300 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'grok-3-mini-fast') THEN 600 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%grok-4%') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'TOGETHER') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'allenai/OLMo-7B-Instruct') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'allenai/OLMo-7B-Twin-2T') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'allenai/OLMo-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Austism/chronos-hermes-13b') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek-ai/deepseek-coder-33b-instruct') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'garage-bAInd/Platypus2-70B-instruct') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2b-it') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-7b-it') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Gryphe/MythoMax-L2-13b') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'lmsys/vicuna-13b-v1.5') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'lmsys/vicuna-7b-v1.5') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mistral-7B-Instruct-v0.1') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mistral-7B-Instruct-v0.2') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mixtral-8x7B-Instruct-v0.1') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Capybara-7B-V1p9') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Hermes-2-Yi-34B') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openchat/openchat-3.5-1210') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Open-Orca/Mistral-7B-OpenOrca') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-0.5B-Chat') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-1.8B-Chat') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-4B-Chat') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-7B-Chat') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-14B-Chat') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'snorkelai/Snorkel-Mistral-PairRM-DPO') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/alpaca-7b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'teknium/OpenHermes-2-Mistral-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'teknium/OpenHermes-2p5-Mistral-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-Chat-3B-v1') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-7B-Chat') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/StripedHyena-Nous-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Undi95/ReMM-SLERP-L2-13B') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Undi95/Toppy-M-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'WizardLM/WizardLM-13B-V1.2') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'upstage/SOLAR-10.7B-Instruct-v1.0') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo') THEN 3500 * request_response_rmt.prompt_tokens + 3500 * request_response_rmt.completion_tokens + 3500 * request_response_rmt.prompt_audio_tokens + 3500 * request_response_rmt.completion_audio_tokens + 3500 * request_response_rmt.prompt_cache_write_tokens + 3500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-8B-Instruct-Turbo') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-8B-Instruct-Lite') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-70B-Instruct-Lite') THEN 540 * request_response_rmt.prompt_tokens + 540 * request_response_rmt.completion_tokens + 540 * request_response_rmt.prompt_audio_tokens + 540 * request_response_rmt.completion_audio_tokens + 540 * request_response_rmt.prompt_cache_write_tokens + 540 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/WizardLM-2-8x22B') THEN 1200 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 1200 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 1200 * request_response_rmt.prompt_cache_write_tokens + 1200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mixtral-8x22B-Instruct-v0.1') THEN 2400 * request_response_rmt.prompt_tokens + 2400 * request_response_rmt.completion_tokens + 2400 * request_response_rmt.prompt_audio_tokens + 2400 * request_response_rmt.completion_audio_tokens + 2400 * request_response_rmt.prompt_cache_write_tokens + 2400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8') THEN 270000 * request_response_rmt.prompt_tokens + 850000 * request_response_rmt.completion_tokens + 270000 * request_response_rmt.prompt_audio_tokens + 850000 * request_response_rmt.completion_audio_tokens + 270000 * request_response_rmt.prompt_cache_write_tokens + 270000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-4-Scout-17B-16E-Instruct') THEN 180000 * request_response_rmt.prompt_tokens + 590000 * request_response_rmt.completion_tokens + 180000 * request_response_rmt.prompt_audio_tokens + 590000 * request_response_rmt.completion_audio_tokens + 180000 * request_response_rmt.prompt_cache_write_tokens + 180000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek-ai/DeepSeek-V3') THEN 1250000 * request_response_rmt.prompt_tokens + 1250000 * request_response_rmt.completion_tokens + 1250000 * request_response_rmt.prompt_audio_tokens + 1250000 * request_response_rmt.completion_audio_tokens + 1250000 * request_response_rmt.prompt_cache_write_tokens + 1250000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek-ai/DeepSeek-R1') THEN 3000000 * request_response_rmt.prompt_tokens + 7000000 * request_response_rmt.completion_tokens + 3000000 * request_response_rmt.prompt_audio_tokens + 7000000 * request_response_rmt.completion_audio_tokens + 3000000 * request_response_rmt.prompt_cache_write_tokens + 3000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek-ai/DeepSeek-R1-0528-tput') THEN 550000 * request_response_rmt.prompt_tokens + 2190000 * request_response_rmt.completion_tokens + 550000 * request_response_rmt.prompt_audio_tokens + 2190000 * request_response_rmt.completion_audio_tokens + 550000 * request_response_rmt.prompt_cache_write_tokens + 550000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen2.5-7B-Instruct-Turbo') THEN 300000 * request_response_rmt.prompt_tokens + 300000 * request_response_rmt.completion_tokens + 300000 * request_response_rmt.prompt_audio_tokens + 300000 * request_response_rmt.completion_audio_tokens + 300000 * request_response_rmt.prompt_cache_write_tokens + 300000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen2.5-72B-Instruct-Turbo') THEN 1200000 * request_response_rmt.prompt_tokens + 1200000 * request_response_rmt.completion_tokens + 1200000 * request_response_rmt.prompt_audio_tokens + 1200000 * request_response_rmt.completion_audio_tokens + 1200000 * request_response_rmt.prompt_cache_write_tokens + 1200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen2.5-VL-72B-Instruct') THEN 1200000 * request_response_rmt.prompt_tokens + 1200000 * request_response_rmt.completion_tokens + 1200000 * request_response_rmt.prompt_audio_tokens + 1200000 * request_response_rmt.completion_audio_tokens + 1200000 * request_response_rmt.prompt_cache_write_tokens + 1200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen2.5-Coder-32B-Instruct') THEN 800000 * request_response_rmt.prompt_tokens + 800000 * request_response_rmt.completion_tokens + 800000 * request_response_rmt.prompt_audio_tokens + 800000 * request_response_rmt.completion_audio_tokens + 800000 * request_response_rmt.prompt_cache_write_tokens + 800000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-3.3-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'codellama/CodeLlama-13b-Instruct-hf') THEN 225 * request_response_rmt.prompt_tokens + 225 * request_response_rmt.completion_tokens + 225 * request_response_rmt.prompt_audio_tokens + 225 * request_response_rmt.completion_audio_tokens + 225 * request_response_rmt.prompt_cache_write_tokens + 225 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'codellama/CodeLlama-34b-Instruct-hf') THEN 776 * request_response_rmt.prompt_tokens + 776 * request_response_rmt.completion_tokens + 776 * request_response_rmt.prompt_audio_tokens + 776 * request_response_rmt.completion_audio_tokens + 776 * request_response_rmt.prompt_cache_write_tokens + 776 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'codellama/CodeLlama-70b-Instruct-hf') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'codellama/CodeLlama-7b-Instruct-hf') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-2-70b-chat-hf') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-2-13b-chat-hf') THEN 225 * request_response_rmt.prompt_tokens + 225 * request_response_rmt.completion_tokens + 225 * request_response_rmt.prompt_audio_tokens + 225 * request_response_rmt.completion_audio_tokens + 225 * request_response_rmt.prompt_cache_write_tokens + 225 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-2-7b-chat-hf') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-3-70b-chat-hf') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-3-8b-chat-hf') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Hermes-llama-2-7b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'NousResearch/Nous-Hermes-Llama2-13b') THEN 225 * request_response_rmt.prompt_tokens + 225 * request_response_rmt.completion_tokens + 225 * request_response_rmt.prompt_audio_tokens + 225 * request_response_rmt.completion_audio_tokens + 225 * request_response_rmt.prompt_cache_write_tokens + 225 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/Llama-2-7B-32K-Instruct') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Llama-3.3-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo') THEN 5000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-70B-Instruct-Turbo') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-8B-Instruct-Turbo') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-70B-Instruct-Lite') THEN 540 * request_response_rmt.prompt_tokens + 540 * request_response_rmt.completion_tokens + 540 * request_response_rmt.prompt_audio_tokens + 540 * request_response_rmt.completion_audio_tokens + 540 * request_response_rmt.prompt_cache_write_tokens + 540 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/Meta-Llama-3-8B-Instruct-Lite') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'zero-one-ai/Yi-34B') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'zero-one-ai/Yi-6B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-7b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-2') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Nexusflow/NexusRaven-V2-13B') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-0.5B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-1.8B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-4B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-14B') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-72B') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/GPT-JT-Moderation-6B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-Base-3B-v1') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-7B-Base') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-7B-Instruct') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/StripedHyena-Hessian-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mistral-7B-v0.1') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mixtral-8x7B-v0.1') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'zero-one-ai/Yi-34B') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'zero-one-ai/Yi-6B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-7b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-2') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Nexusflow/NexusRaven-V2-13B') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-0.5B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-1.8B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-4B') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-14B') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Qwen/Qwen1.5-72B') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/GPT-JT-Moderation-6B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-Base-3B-v1') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-7B-Base') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/RedPajama-INCITE-7B-Instruct') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'togethercomputer/StripedHyena-Hessian-7B') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mistral-7B-v0.1') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/Mixtral-8x7B-v0.1') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'FIREWORKS') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/mixtral-8x7b-instruct') THEN 500 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/mixtral-8x22b-instruct') THEN 1200 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 1200 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 1200 * request_response_rmt.prompt_cache_write_tokens + 1200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/yi-large') THEN 3000 * request_response_rmt.prompt_tokens + 3000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 3000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3-medium') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/stable-diffusion-xl-1024-v1-0') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/playground-v2-1024px-aesthetic') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/playground-v2-5-1024px-aesthetic') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/SSD-1B') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/japanese-stable-diffusion-xl') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3-turbo') THEN 130000 * request_response_rmt.prompt_tokens + 130000 * request_response_rmt.completion_tokens + 130000 * request_response_rmt.prompt_audio_tokens + 130000 * request_response_rmt.completion_audio_tokens + 130000 * request_response_rmt.prompt_cache_write_tokens + 130000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3-medium-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/stable-diffusion-xl-1024-v1-0-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/playground-v2-1024px-aesthetic-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/playground-v2-5-1024px-aesthetic-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/SSD-1B-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/japanese-stable-diffusion-xl-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/sd3-turbo-ControlNet') THEN 200000 * request_response_rmt.prompt_tokens + 200000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 200000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/llama-v3p1-405b-instruct') THEN 3000 * request_response_rmt.prompt_tokens + 3000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 3000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/deepseek-v3') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/gpt-oss-20b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'accounts/fireworks/models/gpt-oss-120b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'PERPLEXITY') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'sonar-reasoning') THEN 10000 * request_response_rmt.prompt_tokens + 50000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 50000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens + 50
WHEN (request_response_rmt.model ILIKE 'sonar') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens + 50
WHEN (request_response_rmt.model ILIKE 'sonar-pro') THEN 30000 * request_response_rmt.prompt_tokens + 150000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 150000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens + 50
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'GOOGLE') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE '%gemini-pro%') THEN 125 * request_response_rmt.prompt_tokens + 375 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 375 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-1.0-pro-vision-001') THEN 125 * request_response_rmt.prompt_tokens + 375 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 375 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-1.0-pro') THEN 125 * request_response_rmt.prompt_tokens + 375 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 375 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-1.5-flash%') THEN 350 * request_response_rmt.prompt_tokens + 1050 * request_response_rmt.completion_tokens + 350 * request_response_rmt.prompt_audio_tokens + 1050 * request_response_rmt.completion_audio_tokens + 350 * request_response_rmt.prompt_cache_write_tokens + 350 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-flash-1.5-8b') THEN 38 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 38 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 38 * request_response_rmt.prompt_cache_write_tokens + 38 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-1.5-pro%') THEN 3500 * request_response_rmt.prompt_tokens + 10500 * request_response_rmt.completion_tokens + 3500 * request_response_rmt.prompt_audio_tokens + 10500 * request_response_rmt.completion_audio_tokens + 3500 * request_response_rmt.prompt_cache_write_tokens + 3500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.0-flash%') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-2.5-flash') THEN 300 * request_response_rmt.prompt_tokens + 2500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 2500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-2.5-pro') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 310 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%claude-3-opus%') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%claude-3-5-haiku%') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%claude-3-5-sonnet%') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%claude-3-7-sonnet%') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemini-2.5-pro-exp-03-25') THEN 0
WHEN (request_response_rmt.model ILIKE '%gemini-2.0-flash%') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.0-flash-lite%') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.5-pro-preview%') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.5-flash-preview%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.5-flash-lite-preview-06-17%') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gemini-2.5-flash-lite%') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'OPENROUTER') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'openai/gpt-oss-120b') THEN 100 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-oss-20b') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-opus-4.1') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openrouter/horizon-beta') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/codestral-2508') THEN 300 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-30b-a3b-instruct-2507') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'z-ai/glm-4.5') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'z-ai/glm-4.5-air:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'z-ai/glm-4.5-air') THEN 200 * request_response_rmt.prompt_tokens + 1100 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 1100 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-235b-a22b-thinking-2507') THEN 78 * request_response_rmt.prompt_tokens + 312 * request_response_rmt.completion_tokens + 78 * request_response_rmt.prompt_audio_tokens + 312 * request_response_rmt.completion_audio_tokens + 78 * request_response_rmt.prompt_cache_write_tokens + 78 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'z-ai/glm-4-32b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-coder') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'bytedance/ui-tars-1.5-7b') THEN 100 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-flash-lite') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-235b-a22b-2507') THEN 78 * request_response_rmt.prompt_tokens + 312 * request_response_rmt.completion_tokens + 78 * request_response_rmt.prompt_audio_tokens + 312 * request_response_rmt.completion_audio_tokens + 78 * request_response_rmt.prompt_cache_write_tokens + 78 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'switchpoint/router') THEN 850 * request_response_rmt.prompt_tokens + 3400 * request_response_rmt.completion_tokens + 850 * request_response_rmt.prompt_audio_tokens + 3400 * request_response_rmt.completion_audio_tokens + 850 * request_response_rmt.prompt_cache_write_tokens + 850 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-k2:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-k2') THEN 140 * request_response_rmt.prompt_tokens + 2490 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 2490 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thudm/glm-4.1v-9b-thinking') THEN 35 * request_response_rmt.prompt_tokens + 138 * request_response_rmt.completion_tokens + 35 * request_response_rmt.prompt_audio_tokens + 138 * request_response_rmt.completion_audio_tokens + 35 * request_response_rmt.prompt_cache_write_tokens + 35 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/devstral-medium') THEN 400 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/devstral-small') THEN 70 * request_response_rmt.prompt_tokens + 280 * request_response_rmt.completion_tokens + 70 * request_response_rmt.prompt_audio_tokens + 280 * request_response_rmt.completion_audio_tokens + 70 * request_response_rmt.prompt_cache_write_tokens + 70 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin-mistral-24b-venice-edition:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-4') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-3n-e2b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'tencent/hunyuan-a13b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'tencent/hunyuan-a13b-instruct') THEN 30 * request_response_rmt.prompt_tokens + 30 * request_response_rmt.completion_tokens + 30 * request_response_rmt.prompt_audio_tokens + 30 * request_response_rmt.completion_audio_tokens + 30 * request_response_rmt.prompt_cache_write_tokens + 30 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'tngtech/deepseek-r1t2-chimera:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'morph/morph-v3-large') THEN 900 * request_response_rmt.prompt_tokens + 1900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 1900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'morph/morph-v3-fast') THEN 900 * request_response_rmt.prompt_tokens + 1900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 1900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'baidu/ernie-4.5-300b-a47b') THEN 280 * request_response_rmt.prompt_tokens + 1100 * request_response_rmt.completion_tokens + 280 * request_response_rmt.prompt_audio_tokens + 1100 * request_response_rmt.completion_audio_tokens + 280 * request_response_rmt.prompt_cache_write_tokens + 280 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thedrummer/anubis-70b-v1.1') THEN 400 * request_response_rmt.prompt_tokens + 700 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 700 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'inception/mercury') THEN 250 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-3.2-24b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-3.2-24b-instruct') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'minimax/minimax-m1') THEN 300 * request_response_rmt.prompt_tokens + 1650 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 1650 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-flash-lite-preview-06-17') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-flash') THEN 300 * request_response_rmt.prompt_tokens + 2500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 2500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-pro') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-dev-72b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'openai/o3-pro') THEN 20000 * request_response_rmt.prompt_tokens + 80000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-3-mini') THEN 300 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-3') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/magistral-small-2506') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/magistral-medium-2506') THEN 2000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/magistral-medium-2506:thinking') THEN 2000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-pro-preview') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-7b') THEN 100 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-0528-qwen3-8b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-0528-qwen3-8b') THEN 10 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.completion_tokens + 10 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.completion_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-0528:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-0528') THEN 180 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sarvamai/sarvam-m:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'thedrummer/valkyrie-49b-v1') THEN 650 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 650 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 650 * request_response_rmt.prompt_cache_write_tokens + 650 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-opus-4') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-sonnet-4') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/devstral-small-2505:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/devstral-small-2505') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-3n-e4b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-3n-e4b-it') THEN 20 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/codex-mini') THEN 1500 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/deephermes-3-mistral-24b-preview') THEN 93 * request_response_rmt.prompt_tokens + 373 * request_response_rmt.completion_tokens + 93 * request_response_rmt.prompt_audio_tokens + 373 * request_response_rmt.completion_audio_tokens + 93 * request_response_rmt.prompt_cache_write_tokens + 93 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-medium-3') THEN 400 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-pro-preview-05-06') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'arcee-ai/spotlight') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'arcee-ai/maestro-reasoning') THEN 900 * request_response_rmt.prompt_tokens + 3300 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 3300 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'arcee-ai/virtuoso-large') THEN 750 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'arcee-ai/coder-large') THEN 500 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-4-reasoning-plus') THEN 70 * request_response_rmt.prompt_tokens + 350 * request_response_rmt.completion_tokens + 70 * request_response_rmt.prompt_audio_tokens + 350 * request_response_rmt.completion_audio_tokens + 70 * request_response_rmt.prompt_cache_write_tokens + 70 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'inception/mercury-coder') THEN 250 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-4b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'opengvlab/internvl3-14b') THEN 200 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-prover-v2') THEN 500 * request_response_rmt.prompt_tokens + 2180 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 2180 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-guard-4-12b') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-30b-a3b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-30b-a3b') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-8b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-8b') THEN 35 * request_response_rmt.prompt_tokens + 138 * request_response_rmt.completion_tokens + 35 * request_response_rmt.prompt_audio_tokens + 138 * request_response_rmt.completion_audio_tokens + 35 * request_response_rmt.prompt_cache_write_tokens + 35 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-14b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-14b') THEN 60 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-32b') THEN 18 * request_response_rmt.prompt_tokens + 72 * request_response_rmt.completion_tokens + 18 * request_response_rmt.prompt_audio_tokens + 72 * request_response_rmt.completion_audio_tokens + 18 * request_response_rmt.prompt_cache_write_tokens + 18 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-235b-a22b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-235b-a22b') THEN 130 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 130 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 130 * request_response_rmt.prompt_cache_write_tokens + 130 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'tngtech/deepseek-r1t-chimera:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'tngtech/deepseek-r1t-chimera') THEN 180 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/mai-ds-r1:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'microsoft/mai-ds-r1') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thudm/glm-z1-32b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'thudm/glm-4-32b') THEN 240 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 240 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 240 * request_response_rmt.prompt_cache_write_tokens + 240 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o4-mini-high') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o3') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o4-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'shisa-ai/shisa-v2-llama3.3-70b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'shisa-ai/shisa-v2-llama3.3-70b') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1-mini') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1-nano') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'eleutherai/llemma_7b') THEN 800 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alfredpros/codellama-7b-instruct-solidity') THEN 600 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'arliai/qwq-32b-arliai-rpr-v1:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'arliai/qwq-32b-arliai-rpr-v1') THEN 10 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 10 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'agentica-org/deepcoder-14b-preview:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'agentica-org/deepcoder-14b-preview') THEN 15 * request_response_rmt.prompt_tokens + 15 * request_response_rmt.completion_tokens + 15 * request_response_rmt.prompt_audio_tokens + 15 * request_response_rmt.completion_audio_tokens + 15 * request_response_rmt.prompt_cache_write_tokens + 15 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-vl-a3b-thinking:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-vl-a3b-thinking') THEN 25 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-3-mini-beta') THEN 300 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-3-beta') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nvidia/llama-3.3-nemotron-super-49b-v1') THEN 130 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 130 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 130 * request_response_rmt.prompt_cache_write_tokens + 130 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nvidia/llama-3.1-nemotron-ultra-253b-v1:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'nvidia/llama-3.1-nemotron-ultra-253b-v1') THEN 600 * request_response_rmt.prompt_tokens + 1800 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 1800 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-4-maverick') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-4-scout') THEN 80 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 80 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 80 * request_response_rmt.prompt_cache_write_tokens + 80 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-v3-base') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'scb10x/llama3.1-typhoon2-70b-instruct') THEN 880 * request_response_rmt.prompt_tokens + 880 * request_response_rmt.completion_tokens + 880 * request_response_rmt.prompt_audio_tokens + 880 * request_response_rmt.completion_audio_tokens + 880 * request_response_rmt.prompt_cache_write_tokens + 880 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-pro-exp-03-25') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen2.5-vl-32b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen2.5-vl-32b-instruct') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-chat-v3-0324:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-chat-v3-0324') THEN 180 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'featherless/qwerky-72b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'openai/o1-pro') THEN 150000 * request_response_rmt.prompt_tokens + 600000 * request_response_rmt.completion_tokens + 150000 * request_response_rmt.prompt_audio_tokens + 600000 * request_response_rmt.completion_audio_tokens + 150000 * request_response_rmt.prompt_cache_write_tokens + 150000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-3.1-24b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-3.1-24b-instruct') THEN 18 * request_response_rmt.prompt_tokens + 72 * request_response_rmt.completion_tokens + 18 * request_response_rmt.prompt_audio_tokens + 72 * request_response_rmt.completion_audio_tokens + 18 * request_response_rmt.prompt_cache_write_tokens + 18 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-4b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-4b-it') THEN 20 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-12b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-12b-it') THEN 48 * request_response_rmt.prompt_tokens + 193 * request_response_rmt.completion_tokens + 48 * request_response_rmt.prompt_audio_tokens + 193 * request_response_rmt.completion_audio_tokens + 48 * request_response_rmt.prompt_cache_write_tokens + 48 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-a') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini-search-preview') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-search-preview') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'rekaai/reka-flash-3:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-27b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-3-27b-it') THEN 67 * request_response_rmt.prompt_tokens + 267 * request_response_rmt.completion_tokens + 67 * request_response_rmt.prompt_audio_tokens + 267 * request_response_rmt.completion_audio_tokens + 67 * request_response_rmt.prompt_cache_write_tokens + 67 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thedrummer/anubis-pro-105b-v1') THEN 500 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thedrummer/skyfall-36b-v2') THEN 48 * request_response_rmt.prompt_tokens + 193 * request_response_rmt.completion_tokens + 48 * request_response_rmt.prompt_audio_tokens + 193 * request_response_rmt.completion_audio_tokens + 48 * request_response_rmt.prompt_cache_write_tokens + 48 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-4-multimodal-instruct') THEN 50 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-reasoning-pro') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-pro') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-deep-research') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwq-32b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwq-32b') THEN 75 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/deephermes-3-llama-3-8b-preview:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.0-flash-lite-001') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.7-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.7-sonnet:thinking') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.7-sonnet:beta') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/r1-1776') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-saba') THEN 200 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin3.0-r1-mistral-24b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin3.0-r1-mistral-24b') THEN 10 * request_response_rmt.prompt_tokens + 34 * request_response_rmt.completion_tokens + 10 * request_response_rmt.prompt_audio_tokens + 34 * request_response_rmt.completion_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin3.0-mistral-24b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin3.0-mistral-24b') THEN 37 * request_response_rmt.prompt_tokens + 148 * request_response_rmt.completion_tokens + 37 * request_response_rmt.prompt_audio_tokens + 148 * request_response_rmt.completion_audio_tokens + 37 * request_response_rmt.prompt_cache_write_tokens + 37 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-guard-3-8b') THEN 20 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o3-mini-high') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-8b') THEN 40 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.0-flash-001') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-vl-plus') THEN 210 * request_response_rmt.prompt_tokens + 630 * request_response_rmt.completion_tokens + 210 * request_response_rmt.prompt_audio_tokens + 630 * request_response_rmt.completion_audio_tokens + 210 * request_response_rmt.prompt_cache_write_tokens + 210 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'aion-labs/aion-1.0') THEN 4000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 4000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 4000 * request_response_rmt.prompt_cache_write_tokens + 4000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'aion-labs/aion-1.0-mini') THEN 700 * request_response_rmt.prompt_tokens + 1400 * request_response_rmt.completion_tokens + 700 * request_response_rmt.prompt_audio_tokens + 1400 * request_response_rmt.completion_audio_tokens + 700 * request_response_rmt.prompt_cache_write_tokens + 700 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'aion-labs/aion-rp-llama-3.1-8b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-vl-max') THEN 800 * request_response_rmt.prompt_tokens + 3200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 3200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-turbo') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen2.5-vl-72b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen2.5-vl-72b-instruct') THEN 250 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-plus') THEN 400 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-max') THEN 1600 * request_response_rmt.prompt_tokens + 6400 * request_response_rmt.completion_tokens + 1600 * request_response_rmt.prompt_audio_tokens + 6400 * request_response_rmt.completion_audio_tokens + 1600 * request_response_rmt.prompt_cache_write_tokens + 1600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o3-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-1.5b') THEN 180 * request_response_rmt.prompt_tokens + 180 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 180 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-24b-instruct-2501:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small-24b-instruct-2501') THEN 20 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-32b') THEN 75 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-14b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-14b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-reasoning') THEN 1000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'liquid/lfm-7b') THEN 10 * request_response_rmt.prompt_tokens + 10 * request_response_rmt.completion_tokens + 10 * request_response_rmt.prompt_audio_tokens + 10 * request_response_rmt.completion_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'liquid/lfm-3b') THEN 20 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-70b:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-70b') THEN 33 * request_response_rmt.prompt_tokens + 133 * request_response_rmt.completion_tokens + 33 * request_response_rmt.prompt_audio_tokens + 133 * request_response_rmt.completion_audio_tokens + 33 * request_response_rmt.prompt_cache_write_tokens + 33 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1') THEN 400 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'minimax/minimax-01') THEN 200 * request_response_rmt.prompt_tokens + 1100 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 1100 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/codestral-2501') THEN 300 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-4') THEN 60 * request_response_rmt.prompt_tokens + 140 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 140 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-chat') THEN 180 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 180 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 180 * request_response_rmt.prompt_cache_write_tokens + 180 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3.3-euryale-70b') THEN 650 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 650 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 650 * request_response_rmt.prompt_cache_write_tokens + 650 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o1') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-2-vision-1212') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-2-1212') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r7b-12-2024') THEN 38 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 38 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 38 * request_response_rmt.prompt_cache_write_tokens + 38 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.0-flash-exp:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.3-70b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.3-70b-instruct') THEN 38 * request_response_rmt.prompt_tokens + 120 * request_response_rmt.completion_tokens + 38 * request_response_rmt.prompt_audio_tokens + 120 * request_response_rmt.completion_audio_tokens + 38 * request_response_rmt.prompt_cache_write_tokens + 38 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-lite-v1') THEN 60 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-micro-v1') THEN 35 * request_response_rmt.prompt_tokens + 140 * request_response_rmt.completion_tokens + 35 * request_response_rmt.prompt_audio_tokens + 140 * request_response_rmt.completion_audio_tokens + 35 * request_response_rmt.prompt_cache_write_tokens + 35 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-pro-v1') THEN 800 * request_response_rmt.prompt_tokens + 3200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 3200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwq-32b-preview') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-2024-11-20') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-large-2411') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-large-2407') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/pixtral-large-2411') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'x-ai/grok-vision-beta') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'infermatic/mn-inferor-12b') THEN 600 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-coder-32b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-coder-32b-instruct') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'raifle/sorcererlm-8x22b') THEN 4500 * request_response_rmt.prompt_tokens + 4500 * request_response_rmt.completion_tokens + 4500 * request_response_rmt.prompt_audio_tokens + 4500 * request_response_rmt.completion_audio_tokens + 4500 * request_response_rmt.prompt_cache_write_tokens + 4500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thedrummer/unslopnemo-12b') THEN 400 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-haiku:beta') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-haiku') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-haiku-20241022') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthracite-org/magnum-v4-72b') THEN 2500 * request_response_rmt.prompt_tokens + 3000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 3000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-sonnet:beta') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/ministral-8b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/ministral-3b') THEN 40 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-7b-instruct') THEN 40 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nvidia/llama-3.1-nemotron-70b-instruct') THEN 120 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 120 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 120 * request_response_rmt.prompt_cache_write_tokens + 120 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'inflection/inflection-3-productivity') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'inflection/inflection-3-pi') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-flash-1.5-8b') THEN 38 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 38 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 38 * request_response_rmt.prompt_cache_write_tokens + 38 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'thedrummer/rocinante-12b') THEN 190 * request_response_rmt.prompt_tokens + 450 * request_response_rmt.completion_tokens + 190 * request_response_rmt.prompt_audio_tokens + 450 * request_response_rmt.completion_audio_tokens + 190 * request_response_rmt.prompt_cache_write_tokens + 190 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthracite-org/magnum-v2-72b') THEN 3000 * request_response_rmt.prompt_tokens + 3000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 3000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'liquid/lfm-40b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-3b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-3b-instruct') THEN 3 * request_response_rmt.prompt_tokens + 6 * request_response_rmt.completion_tokens + 3 * request_response_rmt.prompt_audio_tokens + 6 * request_response_rmt.completion_audio_tokens + 3 * request_response_rmt.prompt_cache_write_tokens + 3 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-1b-instruct') THEN 5 * request_response_rmt.prompt_tokens + 10 * request_response_rmt.completion_tokens + 5 * request_response_rmt.prompt_audio_tokens + 10 * request_response_rmt.completion_audio_tokens + 5 * request_response_rmt.prompt_cache_write_tokens + 5 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-90b-vision-instruct') THEN 1200 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 1200 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 1200 * request_response_rmt.prompt_cache_write_tokens + 1200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-11b-vision-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-11b-vision-instruct') THEN 49 * request_response_rmt.prompt_tokens + 49 * request_response_rmt.completion_tokens + 49 * request_response_rmt.prompt_audio_tokens + 49 * request_response_rmt.completion_audio_tokens + 49 * request_response_rmt.prompt_cache_write_tokens + 49 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-72b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-72b-instruct') THEN 67 * request_response_rmt.prompt_tokens + 267 * request_response_rmt.completion_tokens + 67 * request_response_rmt.prompt_audio_tokens + 267 * request_response_rmt.completion_audio_tokens + 67 * request_response_rmt.prompt_cache_write_tokens + 67 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'neversleep/llama-3.1-lumimaid-8b') THEN 100 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o1-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o1-mini-2024-09-12') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/pixtral-12b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-plus-08-2024') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-08-2024') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-vl-7b-instruct') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3.1-euryale-70b') THEN 650 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 650 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 650 * request_response_rmt.prompt_cache_write_tokens + 650 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-3.5-mini-128k-instruct') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/hermes-3-llama-3.1-70b') THEN 100 * request_response_rmt.prompt_tokens + 280 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 280 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/hermes-3-llama-3.1-405b') THEN 700 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 700 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 700 * request_response_rmt.prompt_cache_write_tokens + 700 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/chatgpt-4o-latest') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3-lunaris-8b') THEN 20 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-2024-08-06') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-405b') THEN 2000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-8b-instruct') THEN 15 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.completion_tokens + 15 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.completion_audio_tokens + 15 * request_response_rmt.prompt_cache_write_tokens + 15 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-405b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-405b-instruct') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-70b-instruct') THEN 100 * request_response_rmt.prompt_tokens + 280 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 280 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-nemo:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-nemo') THEN 7 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 7 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 7 * request_response_rmt.prompt_cache_write_tokens + 7 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini-2024-07-18') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2-27b-it') THEN 650 * request_response_rmt.prompt_tokens + 650 * request_response_rmt.completion_tokens + 650 * request_response_rmt.prompt_audio_tokens + 650 * request_response_rmt.completion_audio_tokens + 650 * request_response_rmt.prompt_cache_write_tokens + 650 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2-9b-it:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'google/gemma-2-9b-it') THEN 10 * request_response_rmt.prompt_tokens + 10 * request_response_rmt.completion_tokens + 10 * request_response_rmt.prompt_audio_tokens + 10 * request_response_rmt.completion_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-sonnet-20240620:beta') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-sonnet-20240620') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3-euryale-70b') THEN 1480 * request_response_rmt.prompt_tokens + 1480 * request_response_rmt.completion_tokens + 1480 * request_response_rmt.prompt_audio_tokens + 1480 * request_response_rmt.completion_audio_tokens + 1480 * request_response_rmt.prompt_cache_write_tokens + 1480 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin-mixtral-8x22b') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2-72b-instruct') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct:free') THEN 0
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct') THEN 28 * request_response_rmt.prompt_tokens + 54 * request_response_rmt.completion_tokens + 28 * request_response_rmt.prompt_audio_tokens + 54 * request_response_rmt.completion_audio_tokens + 28 * request_response_rmt.prompt_cache_write_tokens + 28 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/hermes-2-pro-llama-3-8b') THEN 25 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct-v0.3') THEN 28 * request_response_rmt.prompt_tokens + 54 * request_response_rmt.completion_tokens + 28 * request_response_rmt.prompt_audio_tokens + 54 * request_response_rmt.completion_audio_tokens + 28 * request_response_rmt.prompt_cache_write_tokens + 28 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-3-mini-128k-instruct') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/phi-3-medium-128k-instruct') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'neversleep/llama-3-lumimaid-70b') THEN 4000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 4000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 4000 * request_response_rmt.prompt_cache_write_tokens + 4000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-flash-1.5') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o:extended') THEN 6000 * request_response_rmt.prompt_tokens + 18000 * request_response_rmt.completion_tokens + 6000 * request_response_rmt.prompt_audio_tokens + 18000 * request_response_rmt.completion_audio_tokens + 6000 * request_response_rmt.prompt_cache_write_tokens + 6000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-guard-2-8b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-2024-05-13') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/fimbulvetr-11b-v2') THEN 800 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3-8b-instruct') THEN 30 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 30 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 30 * request_response_rmt.prompt_cache_write_tokens + 30 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3-70b-instruct') THEN 300 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mixtral-8x22b-instruct') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/wizardlm-2-8x22b') THEN 480 * request_response_rmt.prompt_tokens + 480 * request_response_rmt.completion_tokens + 480 * request_response_rmt.prompt_audio_tokens + 480 * request_response_rmt.completion_audio_tokens + 480 * request_response_rmt.prompt_cache_write_tokens + 480 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-pro-1.5') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-turbo') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-plus') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-plus-04-2024') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sophosympatheia/midnight-rose-70b') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command') THEN 1000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-haiku:beta') THEN 250 * request_response_rmt.prompt_tokens + 1250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-haiku') THEN 250 * request_response_rmt.prompt_tokens + 1250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-opus:beta') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-opus') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-03-2024') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-large') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo-0613') THEN 1000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-turbo-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/nous-hermes-2-mixtral-8x7b-dpo') THEN 600 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-small') THEN 200 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-tiny') THEN 250 * request_response_rmt.prompt_tokens + 250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct-v0.2') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mixtral-8x7b-instruct') THEN 80 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 80 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 80 * request_response_rmt.prompt_cache_write_tokens + 80 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'neversleep/noromaid-20b') THEN 1000 * request_response_rmt.prompt_tokens + 1750 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1750 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'undi95/toppy-m-7b') THEN 800 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alpindale/goliath-120b') THEN 9000 * request_response_rmt.prompt_tokens + 11000 * request_response_rmt.completion_tokens + 9000 * request_response_rmt.prompt_audio_tokens + 11000 * request_response_rmt.completion_audio_tokens + 9000 * request_response_rmt.prompt_cache_write_tokens + 9000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openrouter/auto') THEN 0
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-1106-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo-instruct') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct-v0.1') THEN 110 * request_response_rmt.prompt_tokens + 190 * request_response_rmt.completion_tokens + 110 * request_response_rmt.prompt_audio_tokens + 190 * request_response_rmt.completion_audio_tokens + 110 * request_response_rmt.prompt_cache_write_tokens + 110 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'pygmalionai/mythalion-13b') THEN 600 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo-16k') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mancer/weaver') THEN 1500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'undi95/remm-slerp-l2-13b') THEN 700 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 700 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 700 * request_response_rmt.prompt_cache_write_tokens + 700 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gryphe/mythomax-l2-13b') THEN 60 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-0314') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-5') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-5-mini') THEN 250 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-5-nano') THEN 50 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-5-chat') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'GROQ') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'gemma2-9b-it') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama-3.1-8b-instant') THEN 50 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama-3.3-70b-versatile') THEN 590 * request_response_rmt.prompt_tokens + 790 * request_response_rmt.completion_tokens + 590 * request_response_rmt.prompt_audio_tokens + 790 * request_response_rmt.completion_audio_tokens + 590 * request_response_rmt.prompt_cache_write_tokens + 590 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-guard-4-12b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek-r1-distill-llama-70b') THEN 750 * request_response_rmt.prompt_tokens + 990 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 990 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-4-scout-17b-16e-instruct') THEN 110 * request_response_rmt.prompt_tokens + 340 * request_response_rmt.completion_tokens + 110 * request_response_rmt.prompt_audio_tokens + 340 * request_response_rmt.completion_audio_tokens + 110 * request_response_rmt.prompt_cache_write_tokens + 110 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-4-maverick-17b-128e-instruct') THEN 200 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-saba-24b') THEN 790 * request_response_rmt.prompt_tokens + 790 * request_response_rmt.completion_tokens + 790 * request_response_rmt.prompt_audio_tokens + 790 * request_response_rmt.completion_audio_tokens + 790 * request_response_rmt.prompt_cache_write_tokens + 790 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-k2-instruct') THEN 1000 * request_response_rmt.prompt_tokens + 3000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 3000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen3-32b') THEN 290 * request_response_rmt.prompt_tokens + 590 * request_response_rmt.completion_tokens + 290 * request_response_rmt.prompt_audio_tokens + 590 * request_response_rmt.completion_audio_tokens + 290 * request_response_rmt.prompt_cache_write_tokens + 290 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama3-70b-8192') THEN 590 * request_response_rmt.prompt_tokens + 790 * request_response_rmt.completion_tokens + 590 * request_response_rmt.prompt_audio_tokens + 790 * request_response_rmt.completion_audio_tokens + 590 * request_response_rmt.prompt_cache_write_tokens + 590 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama3-8b-8192') THEN 50 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama-guard-3-8b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama2-70b-4096') THEN 700 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 700 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 700 * request_response_rmt.prompt_cache_write_tokens + 700 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mixtral-8x7b-32768') THEN 240 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 240 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 240 * request_response_rmt.prompt_cache_write_tokens + 240 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gemma-7b-it') THEN 70 * request_response_rmt.prompt_tokens + 70 * request_response_rmt.completion_tokens + 70 * request_response_rmt.prompt_audio_tokens + 70 * request_response_rmt.completion_audio_tokens + 70 * request_response_rmt.prompt_cache_write_tokens + 70 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama3-groq-70b-8192-tool-use-preview') THEN 890 * request_response_rmt.prompt_tokens + 890 * request_response_rmt.completion_tokens + 890 * request_response_rmt.prompt_audio_tokens + 890 * request_response_rmt.completion_audio_tokens + 890 * request_response_rmt.prompt_cache_write_tokens + 890 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'llama3-groq-8b-8192-tool-use-preview') THEN 190 * request_response_rmt.prompt_tokens + 190 * request_response_rmt.completion_tokens + 190 * request_response_rmt.prompt_audio_tokens + 190 * request_response_rmt.completion_audio_tokens + 190 * request_response_rmt.prompt_cache_write_tokens + 190 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-oss-20b') THEN 100 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-oss-120b') THEN 150 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'COHERE') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'cohere/command-r') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'MISTRAL') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'open-mistral-7b') THEN 250 * request_response_rmt.prompt_tokens + 250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'open-mixtral-8x7b') THEN 700 * request_response_rmt.prompt_tokens + 700 * request_response_rmt.completion_tokens + 700 * request_response_rmt.prompt_audio_tokens + 700 * request_response_rmt.completion_audio_tokens + 700 * request_response_rmt.prompt_cache_write_tokens + 700 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-tiny') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-small') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-small-latest') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-medium') THEN 2390 * request_response_rmt.prompt_tokens + 7170 * request_response_rmt.completion_tokens + 2390 * request_response_rmt.prompt_audio_tokens + 7170 * request_response_rmt.completion_audio_tokens + 2390 * request_response_rmt.prompt_cache_write_tokens + 2390 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-medium-latest') THEN 2390 * request_response_rmt.prompt_tokens + 7170 * request_response_rmt.completion_tokens + 2390 * request_response_rmt.prompt_audio_tokens + 7170 * request_response_rmt.completion_audio_tokens + 2390 * request_response_rmt.prompt_cache_write_tokens + 2390 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-large') THEN 2000000 * request_response_rmt.prompt_tokens + 6000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 6000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-large-latest') THEN 2000000 * request_response_rmt.prompt_tokens + 6000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 6000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-embed') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-7b-instruct') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-7b-instruct-v0.1') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-7b-instruct-v0.2') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-7b-instruct-v0.3') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mixtral-8x7b-instruct') THEN 140 * request_response_rmt.prompt_tokens + 420 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 420 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mixtral-8x22b-instruct') THEN 2000000 * request_response_rmt.prompt_tokens + 6000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 6000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-medium-3') THEN 400000 * request_response_rmt.prompt_tokens + 2000000 * request_response_rmt.completion_tokens + 400000 * request_response_rmt.prompt_audio_tokens + 2000000 * request_response_rmt.completion_audio_tokens + 400000 * request_response_rmt.prompt_cache_write_tokens + 400000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'magistral-medium') THEN 2000000 * request_response_rmt.prompt_tokens + 5000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 5000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'codestral') THEN 300000 * request_response_rmt.prompt_tokens + 900000 * request_response_rmt.completion_tokens + 300000 * request_response_rmt.prompt_audio_tokens + 900000 * request_response_rmt.completion_audio_tokens + 300000 * request_response_rmt.prompt_cache_write_tokens + 300000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'devstral-medium') THEN 400000 * request_response_rmt.prompt_tokens + 2000000 * request_response_rmt.completion_tokens + 400000 * request_response_rmt.prompt_audio_tokens + 2000000 * request_response_rmt.completion_audio_tokens + 400000 * request_response_rmt.prompt_cache_write_tokens + 400000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-saba') THEN 200000 * request_response_rmt.prompt_tokens + 600000 * request_response_rmt.completion_tokens + 200000 * request_response_rmt.prompt_audio_tokens + 600000 * request_response_rmt.completion_audio_tokens + 200000 * request_response_rmt.prompt_cache_write_tokens + 200000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'pixtral-large') THEN 2000000 * request_response_rmt.prompt_tokens + 6000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 6000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral-small-3.2') THEN 100000 * request_response_rmt.prompt_tokens + 300000 * request_response_rmt.completion_tokens + 100000 * request_response_rmt.prompt_audio_tokens + 300000 * request_response_rmt.completion_audio_tokens + 100000 * request_response_rmt.prompt_cache_write_tokens + 100000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mixtral-8x22b') THEN 2000000 * request_response_rmt.prompt_tokens + 6000000 * request_response_rmt.completion_tokens + 2000000 * request_response_rmt.prompt_audio_tokens + 6000000 * request_response_rmt.completion_audio_tokens + 2000000 * request_response_rmt.prompt_cache_write_tokens + 2000000 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'QSTASH') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE '%llama%') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%mistral%') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'AWS') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'meta.llama3-8b-instruct-v1%3A0') THEN 220000 * request_response_rmt.prompt_tokens + 720000 * request_response_rmt.completion_tokens + 220000 * request_response_rmt.prompt_audio_tokens + 720000 * request_response_rmt.completion_audio_tokens + 220000 * request_response_rmt.prompt_cache_write_tokens + 220000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon.nova-micro-v1%3A0') THEN 46000 * request_response_rmt.prompt_tokens + 184000 * request_response_rmt.completion_tokens + 46000 * request_response_rmt.prompt_audio_tokens + 184000 * request_response_rmt.completion_audio_tokens + 46000 * request_response_rmt.prompt_cache_write_tokens + 46000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon.nova-lite-v1%3A0') THEN 78000 * request_response_rmt.prompt_tokens + 312000 * request_response_rmt.completion_tokens + 78000 * request_response_rmt.prompt_audio_tokens + 312000 * request_response_rmt.completion_audio_tokens + 78000 * request_response_rmt.prompt_cache_write_tokens + 78000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon.nova-pro-v1%3A0') THEN 1050000 * request_response_rmt.prompt_tokens + 4200000 * request_response_rmt.completion_tokens + 1050000 * request_response_rmt.prompt_audio_tokens + 4200000 * request_response_rmt.completion_audio_tokens + 1050000 * request_response_rmt.prompt_cache_write_tokens + 1050000 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'BEDROCK') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'meta.llama3-8b-instruct-v1%3A0') THEN 220000 * request_response_rmt.prompt_tokens + 720000 * request_response_rmt.completion_tokens + 220000 * request_response_rmt.prompt_audio_tokens + 720000 * request_response_rmt.completion_audio_tokens + 220000 * request_response_rmt.prompt_cache_write_tokens + 220000 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'DEEPSEEK') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'deepseek-chat') THEN 14 * request_response_rmt.prompt_tokens + 28 * request_response_rmt.completion_tokens + 14 * request_response_rmt.prompt_audio_tokens + 28 * request_response_rmt.completion_audio_tokens + 14 * request_response_rmt.prompt_cache_write_tokens + 14 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'AVIAN') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'Meta-Llama-3.1-405B-Instruct') THEN 1500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Meta-Llama-3.3-70B-Instruct') THEN 450 * request_response_rmt.prompt_tokens + 450 * request_response_rmt.completion_tokens + 450 * request_response_rmt.prompt_audio_tokens + 450 * request_response_rmt.completion_audio_tokens + 450 * request_response_rmt.prompt_cache_write_tokens + 450 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Meta-Llama-3.1-70B-Instruct') THEN 450 * request_response_rmt.prompt_tokens + 450 * request_response_rmt.completion_tokens + 450 * request_response_rmt.prompt_audio_tokens + 450 * request_response_rmt.completion_audio_tokens + 450 * request_response_rmt.prompt_cache_write_tokens + 450 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Meta-Llama-3.1-8B-Instruct') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'NOVITA') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1') THEN 4000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 4000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 4000 * request_response_rmt.prompt_cache_write_tokens + 4000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek_v3') THEN 890 * request_response_rmt.prompt_tokens + 890 * request_response_rmt.completion_tokens + 890 * request_response_rmt.prompt_audio_tokens + 890 * request_response_rmt.completion_audio_tokens + 890 * request_response_rmt.prompt_cache_write_tokens + 890 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.3-70b-instruct') THEN 390 * request_response_rmt.prompt_tokens + 390 * request_response_rmt.completion_tokens + 390 * request_response_rmt.prompt_audio_tokens + 390 * request_response_rmt.completion_audio_tokens + 390 * request_response_rmt.prompt_cache_write_tokens + 390 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-70b') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-8b-instruct') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-70b-instruct') THEN 340 * request_response_rmt.prompt_tokens + 390 * request_response_rmt.completion_tokens + 340 * request_response_rmt.prompt_audio_tokens + 390 * request_response_rmt.completion_audio_tokens + 340 * request_response_rmt.prompt_cache_write_tokens + 340 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-nemo') THEN 170 * request_response_rmt.prompt_tokens + 170 * request_response_rmt.completion_tokens + 170 * request_response_rmt.prompt_audio_tokens + 170 * request_response_rmt.completion_audio_tokens + 170 * request_response_rmt.prompt_cache_write_tokens + 170 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-14b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-qwen-32b') THEN 300 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'Sao10K/L3-8B-Stheno-v3.2') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gryphe/mythomax-l2-13b') THEN 90 * request_response_rmt.prompt_tokens + 90 * request_response_rmt.completion_tokens + 90 * request_response_rmt.prompt_audio_tokens + 90 * request_response_rmt.completion_audio_tokens + 90 * request_response_rmt.prompt_cache_write_tokens + 90 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-8b') THEN 40 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2.5-72b-instruct') THEN 380 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 380 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 380 * request_response_rmt.prompt_cache_write_tokens + 380 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3-8b-instruct') THEN 40 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'microsoft/wizardlm-2-8x22b') THEN 620 * request_response_rmt.prompt_tokens + 620 * request_response_rmt.completion_tokens + 620 * request_response_rmt.prompt_audio_tokens + 620 * request_response_rmt.completion_audio_tokens + 620 * request_response_rmt.prompt_cache_write_tokens + 620 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2-9b-it') THEN 80 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 80 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 80 * request_response_rmt.prompt_cache_write_tokens + 80 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistralai/mistral-7b-instruct') THEN 59 * request_response_rmt.prompt_tokens + 59 * request_response_rmt.completion_tokens + 59 * request_response_rmt.prompt_audio_tokens + 59 * request_response_rmt.completion_audio_tokens + 59 * request_response_rmt.prompt_cache_write_tokens + 59 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3-70b-instruct') THEN 510 * request_response_rmt.prompt_tokens + 740 * request_response_rmt.completion_tokens + 510 * request_response_rmt.prompt_audio_tokens + 740 * request_response_rmt.completion_audio_tokens + 510 * request_response_rmt.prompt_cache_write_tokens + 510 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openchat/openchat-7b') THEN 60 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/hermes-2-pro-llama-3-8b') THEN 140 * request_response_rmt.prompt_tokens + 140 * request_response_rmt.completion_tokens + 140 * request_response_rmt.prompt_audio_tokens + 140 * request_response_rmt.completion_audio_tokens + 140 * request_response_rmt.prompt_cache_write_tokens + 140 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3-70b-euryale-v2.1') THEN 1480 * request_response_rmt.prompt_tokens + 1480 * request_response_rmt.completion_tokens + 1480 * request_response_rmt.prompt_audio_tokens + 1480 * request_response_rmt.completion_audio_tokens + 1480 * request_response_rmt.prompt_cache_write_tokens + 1480 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cognitivecomputations/dolphin-mixtral-8x22b') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'jondurbin/airoboros-l2-70b') THEN 500 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'nousresearch/nous-hermes-llama2-13b') THEN 170 * request_response_rmt.prompt_tokens + 170 * request_response_rmt.completion_tokens + 170 * request_response_rmt.prompt_audio_tokens + 170 * request_response_rmt.completion_audio_tokens + 170 * request_response_rmt.prompt_cache_write_tokens + 170 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'teknium/openhermes-2.5-mistral-7b') THEN 170 * request_response_rmt.prompt_tokens + 170 * request_response_rmt.completion_tokens + 170 * request_response_rmt.prompt_audio_tokens + 170 * request_response_rmt.completion_audio_tokens + 170 * request_response_rmt.prompt_cache_write_tokens + 170 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sophosympatheia/midnight-rose-70b') THEN 800 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-8b-instruct-max') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l3-8b-lunaris') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2-vl-72b-instruct') THEN 450 * request_response_rmt.prompt_tokens + 450 * request_response_rmt.completion_tokens + 450 * request_response_rmt.prompt_audio_tokens + 450 * request_response_rmt.completion_audio_tokens + 450 * request_response_rmt.prompt_cache_write_tokens + 450 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-1b-instruct') THEN 20 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.completion_tokens + 20 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.completion_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-11b-vision-instruct') THEN 60 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.2-3b-instruct') THEN 30 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.completion_tokens + 30 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.completion_audio_tokens + 30 * request_response_rmt.prompt_cache_write_tokens + 30 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta-llama/llama-3.1-8b-instruct-bf16') THEN 60 * request_response_rmt.prompt_tokens + 60 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 60 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'sao10k/l31-70b-euryale-v2.2') THEN 1480 * request_response_rmt.prompt_tokens + 1480 * request_response_rmt.completion_tokens + 1480 * request_response_rmt.prompt_audio_tokens + 1480 * request_response_rmt.completion_audio_tokens + 1480 * request_response_rmt.prompt_cache_write_tokens + 1480 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'qwen/qwen-2-7b-instruct') THEN 54 * request_response_rmt.prompt_tokens + 54 * request_response_rmt.completion_tokens + 54 * request_response_rmt.prompt_audio_tokens + 54 * request_response_rmt.completion_audio_tokens + 54 * request_response_rmt.prompt_cache_write_tokens + 54 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'OPENPIPE') THEN (
  CASE
  
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'CHUTES') THEN (
  CASE
  
  ELSE toInt64(0)
END
)
WHEN (request_response_rmt.provider = 'VERCEL') THEN (
  CASE
  WHEN (request_response_rmt.model ILIKE 'alibaba/qwen-3-14b') THEN 80 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 80 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 80 * request_response_rmt.prompt_cache_write_tokens + 80 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alibaba/qwen-3-235b') THEN 200 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alibaba/qwen-3-30b') THEN 100 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alibaba/qwen-3-32b') THEN 100 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'alibaba/qwen3-coder') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-lite') THEN 60 * request_response_rmt.prompt_tokens + 240 * request_response_rmt.completion_tokens + 60 * request_response_rmt.prompt_audio_tokens + 240 * request_response_rmt.completion_audio_tokens + 60 * request_response_rmt.prompt_cache_write_tokens + 60 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-micro') THEN 35 * request_response_rmt.prompt_tokens + 140 * request_response_rmt.completion_tokens + 35 * request_response_rmt.prompt_audio_tokens + 140 * request_response_rmt.completion_audio_tokens + 35 * request_response_rmt.prompt_cache_write_tokens + 35 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'amazon/nova-pro') THEN 800 * request_response_rmt.prompt_tokens + 3200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 3200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-haiku') THEN 250 * request_response_rmt.prompt_tokens + 1250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-opus') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-haiku') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-5-haiku') THEN 800 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.5-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-5-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3.7-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-3-7-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-4-opus') THEN 15000 * request_response_rmt.prompt_tokens + 75000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 75000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'anthropic/claude-4-sonnet') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-a') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'cohere/command-r-plus') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1') THEN 550 * request_response_rmt.prompt_tokens + 2190 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2190 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-r1-distill-llama-70b') THEN 750 * request_response_rmt.prompt_tokens + 990 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 990 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'deepseek/deepseek-v3') THEN 900 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.0-flash') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2-0-flash') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.0-flash-lite') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2-0-flash-lite') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-flash') THEN 300 * request_response_rmt.prompt_tokens + 2500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 2500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2-5-flash') THEN 300 * request_response_rmt.prompt_tokens + 2500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 2500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2.5-pro') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemini-2-5-pro') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'google/gemma-2-9b') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'inception/mercury-coder-small') THEN 250 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-70b') THEN 590 * request_response_rmt.prompt_tokens + 790 * request_response_rmt.completion_tokens + 590 * request_response_rmt.prompt_audio_tokens + 790 * request_response_rmt.completion_audio_tokens + 590 * request_response_rmt.prompt_cache_write_tokens + 590 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-8b') THEN 50 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.1-70b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-1-70b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.1-8b') THEN 50 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-1-8b') THEN 50 * request_response_rmt.prompt_tokens + 80 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 80 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.2-11b') THEN 160 * request_response_rmt.prompt_tokens + 160 * request_response_rmt.completion_tokens + 160 * request_response_rmt.prompt_audio_tokens + 160 * request_response_rmt.completion_audio_tokens + 160 * request_response_rmt.prompt_cache_write_tokens + 160 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-2-11b') THEN 160 * request_response_rmt.prompt_tokens + 160 * request_response_rmt.completion_tokens + 160 * request_response_rmt.prompt_audio_tokens + 160 * request_response_rmt.completion_audio_tokens + 160 * request_response_rmt.prompt_cache_write_tokens + 160 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.2-1b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-2-1b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.2-3b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-2-3b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.2-90b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-2-90b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3.3-70b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-3-3-70b') THEN 720 * request_response_rmt.prompt_tokens + 720 * request_response_rmt.completion_tokens + 720 * request_response_rmt.prompt_audio_tokens + 720 * request_response_rmt.completion_audio_tokens + 720 * request_response_rmt.prompt_cache_write_tokens + 720 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-4-maverick') THEN 200 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'meta/llama-4-scout') THEN 100 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/codestral') THEN 300 * request_response_rmt.prompt_tokens + 900 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 900 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/devstral-small') THEN 70 * request_response_rmt.prompt_tokens + 280 * request_response_rmt.completion_tokens + 70 * request_response_rmt.prompt_audio_tokens + 280 * request_response_rmt.completion_audio_tokens + 70 * request_response_rmt.prompt_cache_write_tokens + 70 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/magistral-medium') THEN 2000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/magistral-small') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/ministral-3b') THEN 40 * request_response_rmt.prompt_tokens + 40 * request_response_rmt.completion_tokens + 40 * request_response_rmt.prompt_audio_tokens + 40 * request_response_rmt.completion_audio_tokens + 40 * request_response_rmt.prompt_cache_write_tokens + 40 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/ministral-8b') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/mistral-large') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/mistral-saba-24b') THEN 790 * request_response_rmt.prompt_tokens + 790 * request_response_rmt.completion_tokens + 790 * request_response_rmt.prompt_audio_tokens + 790 * request_response_rmt.completion_audio_tokens + 790 * request_response_rmt.prompt_cache_write_tokens + 790 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/mistral-small') THEN 100 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/mixtral-8x22b-instruct') THEN 1200 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 1200 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 1200 * request_response_rmt.prompt_cache_write_tokens + 1200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/pixtral-12b') THEN 150 * request_response_rmt.prompt_tokens + 150 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 150 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'mistral/pixtral-large') THEN 2000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'moonshotai/kimi-k2') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'morph/morph-v3-fast') THEN 800 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 800 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 800 * request_response_rmt.prompt_cache_write_tokens + 800 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'morph/morph-v3-large') THEN 900 * request_response_rmt.prompt_tokens + 1900 * request_response_rmt.completion_tokens + 900 * request_response_rmt.prompt_audio_tokens + 1900 * request_response_rmt.completion_audio_tokens + 900 * request_response_rmt.prompt_cache_write_tokens + 900 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3-5-turbo') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3.5-turbo-instruct') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-3-5-turbo-instruct') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-turbo') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-1') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1-mini') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-1-mini') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4.1-nano') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4-1-nano') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o1') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o3') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o3-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/o4-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-pro') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-reasoning') THEN 1000 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'perplexity/sonar-reasoning-pro') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'vercel/v0-1.0-md') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'vercel/v0-1-0-md') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'vercel/v0-1.5-md') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'vercel/v0-1-5-md') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-2') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-2-vision') THEN 2000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-3') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-3-fast') THEN 5000 * request_response_rmt.prompt_tokens + 25000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 25000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-3-mini') THEN 300 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-3-mini-fast') THEN 600 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 600 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 600 * request_response_rmt.prompt_cache_write_tokens + 600 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'xai/grok-4') THEN 3000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END
)
    ELSE 
  CASE
  WHEN (request_response_rmt.model ILIKE 'ada') THEN 400 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-ada-001') THEN 400 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 400 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'babbage') THEN 500 * request_response_rmt.prompt_tokens + 500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'curie') THEN 2000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-curie-001') THEN 2000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 2000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'davinci') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-001') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-002') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-003') THEN 20000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0301') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-1106') THEN 1000 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-0914') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0314') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0613') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0314') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0613') THEN 60000 * request_response_rmt.prompt_tokens + 120000 * request_response_rmt.completion_tokens + 60000 * request_response_rmt.prompt_audio_tokens + 120000 * request_response_rmt.completion_audio_tokens + 60000 * request_response_rmt.prompt_cache_write_tokens + 60000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0125-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-vision-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-05-13') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-2024-07-18') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0613') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-16k-0613') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0125') THEN 500 * request_response_rmt.prompt_tokens + 1500 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1500 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-2024-04-09') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-0125-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-v2') THEN 100 * request_response_rmt.prompt_tokens + 100 * request_response_rmt.prompt_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-small') THEN 20 * request_response_rmt.prompt_tokens + 20 * request_response_rmt.prompt_audio_tokens + 20 * request_response_rmt.prompt_cache_write_tokens + 20 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-large') THEN 130 * request_response_rmt.prompt_tokens + 130 * request_response_rmt.prompt_audio_tokens + 130 * request_response_rmt.prompt_cache_write_tokens + 130 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-vision-preview') THEN 10000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-0613') THEN 3000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-08-06') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-11-20') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-2024-09-12') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini') THEN 3000 * request_response_rmt.prompt_tokens + 12000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 12000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-2024-09-12') THEN 3000 * request_response_rmt.prompt_tokens + 12000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 12000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-2024-12-17') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1') THEN 15000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o1-pro%') THEN 150000 * request_response_rmt.prompt_tokens + 600000 * request_response_rmt.completion_tokens + 150000 * request_response_rmt.prompt_audio_tokens + 600000 * request_response_rmt.completion_audio_tokens + 150000 * request_response_rmt.prompt_cache_write_tokens + 150000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-2025-01-31') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-2025-04-16') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o3-pro%') THEN 20000 * request_response_rmt.prompt_tokens + 80000 * request_response_rmt.completion_tokens + 20000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 20000 * request_response_rmt.prompt_cache_write_tokens + 20000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-2025-04-14') THEN 2000 * request_response_rmt.prompt_tokens + 8000 * request_response_rmt.completion_tokens + 2000 * request_response_rmt.prompt_audio_tokens + 8000 * request_response_rmt.completion_audio_tokens + 2000 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-2025-04-14') THEN 400 * request_response_rmt.prompt_tokens + 1600 * request_response_rmt.completion_tokens + 400 * request_response_rmt.prompt_audio_tokens + 1600 * request_response_rmt.completion_audio_tokens + 400 * request_response_rmt.prompt_cache_write_tokens + 100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-2025-04-14') THEN 100 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 100 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 100 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-realtime%') THEN 5000 * request_response_rmt.prompt_tokens + 20000 * request_response_rmt.completion_tokens + 40000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-mini-realtime%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o4-mini%') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%o4-mini-2025-04-16%') THEN 1100 * request_response_rmt.prompt_tokens + 4400 * request_response_rmt.completion_tokens + 1100 * request_response_rmt.prompt_audio_tokens + 4400 * request_response_rmt.completion_audio_tokens + 1100 * request_response_rmt.prompt_cache_write_tokens + 1100 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%openai/gpt-4o-mini-search-preview%') THEN 150 * request_response_rmt.prompt_tokens + 600 * request_response_rmt.completion_tokens + 150 * request_response_rmt.prompt_audio_tokens + 600 * request_response_rmt.completion_audio_tokens + 150 * request_response_rmt.prompt_cache_write_tokens + 150 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE '%gpt-4o-search-preview%') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'chatgpt-4o-latest') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-2025-08-07') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-2025-08-07') THEN 250 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-2025-08-07') THEN 50 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 5 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini') THEN 250 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano') THEN 50 * request_response_rmt.prompt_tokens + 400 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 400 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 5 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-chat-latest') THEN 1250 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'ada-batch') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-ada-001-batch') THEN 200 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'babbage-batch') THEN 250 * request_response_rmt.prompt_tokens + 250 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 250 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'curie-batch') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-curie-001-batch') THEN 1000 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'davinci-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-001-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-002-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-davinci-003-batch') THEN 10000 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 10000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0301-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-1106-batch') THEN 500 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 500 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 500 * request_response_rmt.prompt_cache_write_tokens + 500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-instruct-0914-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0314-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0613-batch') THEN 15000 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 15000 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 15000 * request_response_rmt.prompt_cache_write_tokens + 15000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0314-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-32k-0613-batch') THEN 30000 * request_response_rmt.prompt_tokens + 60000 * request_response_rmt.completion_tokens + 30000 * request_response_rmt.prompt_audio_tokens + 60000 * request_response_rmt.completion_audio_tokens + 30000 * request_response_rmt.prompt_cache_write_tokens + 30000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-0125-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-1106-vision-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-05-13-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-2024-07-18-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0613-batch') THEN 750 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 750 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 750 * request_response_rmt.prompt_cache_write_tokens + 750 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-16k-0613-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-3.5-turbo-0125-batch') THEN 250 * request_response_rmt.prompt_tokens + 750 * request_response_rmt.completion_tokens + 250 * request_response_rmt.prompt_audio_tokens + 750 * request_response_rmt.completion_audio_tokens + 250 * request_response_rmt.prompt_cache_write_tokens + 250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-2024-04-09-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-turbo-0125-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-ada-002-v2-batch') THEN 50 * request_response_rmt.prompt_tokens + 50 * request_response_rmt.prompt_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-small-batch') THEN 10 * request_response_rmt.prompt_tokens + 10 * request_response_rmt.prompt_audio_tokens + 10 * request_response_rmt.prompt_cache_write_tokens + 10 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'text-embedding-3-large-batch') THEN 65 * request_response_rmt.prompt_tokens + 65 * request_response_rmt.prompt_audio_tokens + 65 * request_response_rmt.prompt_cache_write_tokens + 65 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4-vision-preview-batch') THEN 5000 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 5000 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 5000 * request_response_rmt.prompt_cache_write_tokens + 5000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-35-turbo-16k-0613-batch') THEN 1500 * request_response_rmt.prompt_tokens + 2000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 2000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-08-06-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-2024-11-20-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-preview-2024-09-12-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-batch') THEN 1500 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-mini-2024-09-12-batch') THEN 1500 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 1500 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 1500 * request_response_rmt.prompt_cache_write_tokens + 1500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-2024-12-17-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-batch') THEN 7500 * request_response_rmt.prompt_tokens + 30000 * request_response_rmt.completion_tokens + 7500 * request_response_rmt.prompt_audio_tokens + 30000 * request_response_rmt.completion_audio_tokens + 7500 * request_response_rmt.prompt_cache_write_tokens + 7500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o1-pro-batch') THEN 75000 * request_response_rmt.prompt_tokens + 300000 * request_response_rmt.completion_tokens + 75000 * request_response_rmt.prompt_audio_tokens + 300000 * request_response_rmt.completion_audio_tokens + 75000 * request_response_rmt.prompt_cache_write_tokens + 75000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-mini-2025-01-31-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-2025-04-16-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o3-pro-batch') THEN 10000 * request_response_rmt.prompt_tokens + 40000 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 40000 * request_response_rmt.completion_audio_tokens + 10000 * request_response_rmt.prompt_cache_write_tokens + 10000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-2025-04-14-batch') THEN 1000 * request_response_rmt.prompt_tokens + 4000 * request_response_rmt.completion_tokens + 1000 * request_response_rmt.prompt_audio_tokens + 4000 * request_response_rmt.completion_audio_tokens + 1000 * request_response_rmt.prompt_cache_write_tokens + 1000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-batch') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-mini-2025-04-14-batch') THEN 200 * request_response_rmt.prompt_tokens + 800 * request_response_rmt.completion_tokens + 200 * request_response_rmt.prompt_audio_tokens + 800 * request_response_rmt.completion_audio_tokens + 200 * request_response_rmt.prompt_cache_write_tokens + 200 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-batch') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4.1-nano-2025-04-14-batch') THEN 50 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 50 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 50 * request_response_rmt.prompt_cache_write_tokens + 50 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-realtime-batch') THEN 2500 * request_response_rmt.prompt_tokens + 10000 * request_response_rmt.completion_tokens + 40000 * request_response_rmt.prompt_audio_tokens + 80000 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-mini-realtime-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 10000 * request_response_rmt.prompt_audio_tokens + 20000 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o4-mini-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'o4-mini-2025-04-16-batch') THEN 550 * request_response_rmt.prompt_tokens + 2200 * request_response_rmt.completion_tokens + 550 * request_response_rmt.prompt_audio_tokens + 2200 * request_response_rmt.completion_audio_tokens + 550 * request_response_rmt.prompt_cache_write_tokens + 550 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'openai/gpt-4o-mini-search-preview-batch') THEN 75 * request_response_rmt.prompt_tokens + 300 * request_response_rmt.completion_tokens + 75 * request_response_rmt.prompt_audio_tokens + 300 * request_response_rmt.completion_audio_tokens + 75 * request_response_rmt.prompt_cache_write_tokens + 75 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-4o-search-preview-batch') THEN 1250 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 1250 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 1250 * request_response_rmt.prompt_cache_write_tokens + 1250 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'chatgpt-4o-latest-batch') THEN 2500 * request_response_rmt.prompt_tokens + 7500 * request_response_rmt.completion_tokens + 2500 * request_response_rmt.prompt_audio_tokens + 7500 * request_response_rmt.completion_audio_tokens + 2500 * request_response_rmt.prompt_cache_write_tokens + 2500 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-2025-08-07-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-2025-08-07-batch') THEN 125 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-2025-08-07-batch') THEN 25 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-mini-batch') THEN 125 * request_response_rmt.prompt_tokens + 1000 * request_response_rmt.completion_tokens + 125 * request_response_rmt.prompt_audio_tokens + 1000 * request_response_rmt.completion_audio_tokens + 125 * request_response_rmt.prompt_cache_write_tokens + 125 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-nano-batch') THEN 25 * request_response_rmt.prompt_tokens + 200 * request_response_rmt.completion_tokens + 25 * request_response_rmt.prompt_audio_tokens + 200 * request_response_rmt.completion_audio_tokens + 25 * request_response_rmt.prompt_cache_write_tokens + 25 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model ILIKE 'gpt-5-chat-latest-batch') THEN 625 * request_response_rmt.prompt_tokens + 5000 * request_response_rmt.completion_tokens + 625 * request_response_rmt.prompt_audio_tokens + 5000 * request_response_rmt.completion_audio_tokens + 625 * request_response_rmt.prompt_cache_write_tokens + 625 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model LIKE 'ft:gpt-3.5-turbo-%') THEN 3000 * request_response_rmt.prompt_tokens + 6000 * request_response_rmt.completion_tokens + 3000 * request_response_rmt.prompt_audio_tokens + 6000 * request_response_rmt.completion_audio_tokens + 3000 * request_response_rmt.prompt_cache_write_tokens + 3000 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model LIKE 'ft:gpt-4o-mini-2024-07-18:%') THEN 300 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model LIKE 'gpt-4o-mini-2024-07-18.ft-%') THEN 300 * request_response_rmt.prompt_tokens + 1200 * request_response_rmt.completion_tokens + 300 * request_response_rmt.prompt_audio_tokens + 1200 * request_response_rmt.completion_audio_tokens + 300 * request_response_rmt.prompt_cache_write_tokens + 300 * request_response_rmt.prompt_cache_read_tokens
WHEN (request_response_rmt.model LIKE 'ft:gpt-4o-2024-08-06:%') THEN 3750 * request_response_rmt.prompt_tokens + 15000 * request_response_rmt.completion_tokens + 3750 * request_response_rmt.prompt_audio_tokens + 15000 * request_response_rmt.completion_audio_tokens + 3750 * request_response_rmt.prompt_cache_write_tokens + 3750 * request_response_rmt.prompt_cache_read_tokens
  ELSE toInt64(0)
END

  END
  ) / 1000000000
"
`);
});
