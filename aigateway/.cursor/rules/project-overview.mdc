---
description: 
globs: 
alwaysApply: false
---
# LLM Proxy Project Overview

This project is a Rust-based LLM (Large Language Model) proxy/router service that handles API requests to various LLM providers like OpenAI and Anthropic.

## Key Files and Directories

- [llm-proxy/src/main.rs](mdc:llm-proxy/src/main.rs) - Main entry point for the application
- [llm-proxy/src/lib.rs](mdc:llm-proxy/src/lib.rs) - Exposes the main modules of the application
- [llm-proxy/src/app.rs](mdc:llm-proxy/src/app.rs) - Core application setup and HTTP server
- [llm-proxy/src/router/](mdc:llm-proxy/src/router) - Contains routing logic for API requests
- [llm-proxy/src/config/](mdc:llm-proxy/src/config) - Configuration handling
- [crates/](mdc:crates) - Contains smaller crates for specific functionality

## Specialized Crates

- [crates/telemetry/](mdc:crates/telemetry) - Telemetry and logging infrastructure
- [crates/metrics/](mdc:crates/metrics) - Metrics collection and reporting
- [crates/weighted-balance/](mdc:crates/weighted-balance) - Load balancing logic for LLM providers
